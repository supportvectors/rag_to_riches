{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"RAG to Riches: Advanced Retrieval-Augmented Generation Framework","text":""},{"location":"#project-overview","title":"\ud83d\ude80 Project Overview","text":"<p>RAG to Riches is a comprehensive, production-ready framework for building intelligent Retrieval-Augmented Generation (RAG) systems. The project combines state-of-the-art semantic search, vector databases, and large language models to create powerful question-answering applications with grounded, source-backed responses.</p>"},{"location":"#key-features","title":"\ud83c\udfaf Key Features","text":"<ul> <li>\ud83d\udd0d Semantic Search: Advanced sentence transformer embeddings for meaning-based retrieval</li> <li>\ud83d\uddc4\ufe0f Vector Database: Embedded Qdrant integration for efficient similarity search</li> <li>\ud83e\udd16 AI Integration: OpenAI GPT models with structured response generation</li> <li>\ud83d\udcda Corpus Management: Specialized animal quotes corpus with rich metadata</li> <li>\ud83c\udfa8 Rich Display: Beautiful formatted output using Rich library</li> <li>\u26a1 Performance: Optimized batch processing and caching</li> <li>\ud83d\udee1\ufe0f Robust Error Handling: Comprehensive exception system with clear error messages</li> <li>\ud83d\udcca Analytics: Detailed collection statistics and health monitoring</li> </ul>"},{"location":"#architecture-overview","title":"\ud83c\udfd7\ufe0f Architecture Overview","text":"graph TB     subgraph \"User Interface Layer\"         UI[User Query] --&gt; RAG[RAG Pipeline]         RAG --&gt; Display[Rich Display Output]     end      subgraph \"Core RAG Components\"         RAG --&gt; Search[Semantic Search]         RAG --&gt; LLM[LLM Integration]         Search --&gt; VectorDB[Vector Database]         Search --&gt; Embedder[Text Embedder]     end      subgraph \"Data Layer\"         Corpus[Animal Corpus] --&gt; DataModels[Data Models]         DataModels --&gt; VectorDB         VectorDB --&gt; Qdrant[(Qdrant DB)]     end      subgraph \"Infrastructure\"         Config[Configuration] --&gt; All[All Components]         Logging[Logging System] --&gt; All         Exceptions[Exception Handling] --&gt; All     end      style RAG fill:#e1f5fe     style Search fill:#f3e5f5     style VectorDB fill:#e8f5e8     style LLM fill:#fff3e0"},{"location":"#package-structure","title":"\ud83d\udce6 Package Structure","text":"<p>The project is organized into focused, cohesive packages:</p>"},{"location":"#core-packages","title":"\ud83c\udfdb\ufe0f Core Packages","text":"Package Purpose Key Components <code>corpus/</code> Data models and corpus management <code>Animals</code>, <code>AnimalQuote</code>, <code>AnimalWisdom</code> <code>vectordb/</code> Vector database operations <code>EmbeddedVectorDB</code>, <code>SimpleTextEmbedder</code> <code>search/</code> Semantic search functionality <code>SemanticSearch</code> <code>exceptions/</code> Comprehensive error handling Custom exception hierarchy"},{"location":"#getting-started-packages","title":"\ud83d\ude80 Getting Started Packages","text":"Package Purpose Key Components <code>start_simply/</code> Basic RAG implementation <code>BasicRAG</code> <code>search_basics/</code> Simple search examples Text and multimodal search <code>examples/</code> Usage demonstrations Complete working examples"},{"location":"#utility-packages","title":"\ud83d\udee0\ufe0f Utility Packages","text":"Package Purpose Key Components <code>utils/</code> Shared utilities Logging configuration"},{"location":"#typical-workflow","title":"\ud83d\udd04 Typical Workflow","text":"<pre><code>from pathlib import Path\nfrom rag_to_riches.vectordb.embedded_vectordb import EmbeddedVectorDB\nfrom rag_to_riches.corpus.animals import Animals\n\n# 1. Initialize the system\nvector_db = EmbeddedVectorDB()\nanimals = Animals(vector_db, collection_name=\"my_quotes\")\n\n# 2. Load and index your data\nquotes_file = Path(\"data/animal_quotes.jsonl\")\nwisdom, point_ids = animals.load_and_index(quotes_file)\n\n# 3. Perform semantic searches\nresults = animals.search(\"wisdom about loyalty\", limit=5)\nanimals.display_search_results(results, \"Loyalty Search\")\n\n# 4. Get AI-powered answers\nresponse = animals.ask_llm(\"What do animals teach us about friendship?\")\nanimals.display_llm_response(response, \"friendship question\")\n\n# 5. Complete RAG in one call\nrag_result = animals.rag(\n    \"How do pets help with emotional healing?\",\n    limit=7,\n    response_type=\"structured\"\n)\n</code></pre>"},{"location":"#educational-focus","title":"\ud83c\udf93 Educational Focus","text":"<p>This project serves as both a production framework and an educational resource for learning RAG systems:</p> <ul> <li>Comprehensive Examples: Real-world usage patterns and best practices</li> <li>Detailed Documentation: Every class, method, and concept thoroughly explained</li> <li>Interactive Notebooks: Hands-on learning with Jupyter notebooks</li> <li>Progressive Complexity: From simple searches to complete RAG pipelines</li> </ul>"},{"location":"#technical-highlights","title":"\ud83e\udde0 Technical Highlights","text":""},{"location":"#design-patterns-applied","title":"Design Patterns Applied","text":"<ul> <li>Facade Pattern: <code>Animals.rag()</code> method provides simple interface to complex pipeline</li> <li>Strategy Pattern: Pluggable embedders and search strategies</li> <li>Builder Pattern: Flexible configuration and initialization</li> <li>Observer Pattern: Rich logging and monitoring throughout</li> </ul>"},{"location":"#performance-optimizations","title":"Performance Optimizations","text":"<ul> <li>Batch Processing: Efficient handling of large document collections</li> <li>Vector Caching: Intelligent caching of embeddings</li> <li>Connection Pooling: Optimized database connections</li> <li>Lazy Loading: Resources loaded only when needed</li> </ul>"},{"location":"#code-quality-standards","title":"Code Quality Standards","text":"<ul> <li>Design by Contract: Pre/post conditions using <code>icontract</code></li> <li>Type Safety: Comprehensive type hints throughout</li> <li>Low Complexity: Cyclomatic complexity \u2264 10 per function</li> <li>Comprehensive Testing: Unit tests with &gt;90% coverage</li> </ul>"},{"location":"#quick-start","title":"\ud83d\ude80 Quick Start","text":"<ol> <li>Install Dependencies: <code>uv sync</code></li> <li>Set Environment: Copy <code>sample.env</code> to <code>.env</code> and configure</li> <li>Run Examples: Check out <code>src/examples/</code> for working code</li> <li>Explore Notebooks: Interactive learning in <code>docs/notebooks/examples/</code></li> </ol>"},{"location":"#documentation-navigation","title":"\ud83d\udcd6 Documentation Navigation","text":"<ul> <li>API Reference: Complete class and method documentation</li> <li>Package Guides: Detailed package overviews</li> <li>Examples: Working code samples</li> <li>Notebooks: Interactive tutorials</li> </ul>"},{"location":"#contributing","title":"\ud83e\udd1d Contributing","text":"<p>This project follows strict coding standards and design principles. See the cursor rules for detailed guidelines on: - Absolute imports only - Design-by-contract programming - Low cognitive complexity - Comprehensive documentation</p> <p>Built with \u2764\ufe0f for the RAG community. Start your journey from retrieval to riches!</p>"},{"location":"corpus/","title":"Corpus Package: Data Models and Content Management","text":""},{"location":"corpus/#package-overview","title":"\ud83d\udcd6 Package Overview","text":"<p>The <code>corpus</code> package is the heart of content management in the RAG to Riches framework. It provides sophisticated data models, corpus loading capabilities, and intelligent question-answering systems built on top of semantic search and large language models.</p>"},{"location":"corpus/#package-purpose","title":"\ud83c\udfaf Package Purpose","text":"<p>This package transforms raw text data into intelligent, searchable knowledge bases with AI-powered query capabilities. It handles the complete pipeline from data validation to AI-powered responses, making it easy to build production-ready RAG applications.</p>"},{"location":"corpus/#architecture","title":"\ud83c\udfd7\ufe0f Architecture","text":"classDiagram     class AnimalQuote {         +str text         +str author         +str category         +to_payload() Dict         +validate_non_empty_strings() str     }      class AnimalWisdom {         +List[AnimalQuote] quotes         +Optional[Path] source_file         +get_categories() List[str]         +get_authors() List[str]         +filter_by_category() List[AnimalQuote]         +filter_by_author() List[AnimalQuote]     }      class Animals {         +SimpleTextEmbedder embedder         +str collection_name         +Optional[AnimalWisdom] wisdom         +SemanticSearch semantic_search         +load_from_jsonl() AnimalWisdom         +index_all_quotes() List[str]         +search() List[ScoredPoint]         +ask_llm() AnimalWisdomResponse         +rag() Dict[str, Any]         +display_search_results() None     }      class AnimalWisdomResponse {         +str answer         +List[str] key_insights         +List[str] recommended_quotes         +List[str] follow_up_questions     }      AnimalWisdom *-- AnimalQuote : contains     Animals --&gt; AnimalWisdom : manages     Animals --&gt; AnimalWisdomResponse : creates     Animals --&gt; SemanticSearch : uses     Animals --&gt; EmbeddedVectorDB : uses"},{"location":"corpus/#components","title":"\ud83d\udce6 Components","text":""},{"location":"corpus/#core-components","title":"\ud83c\udfdb\ufe0f Core Components","text":"Component File Purpose <code>Animals</code> <code>animals.py</code> Main RAG system with search and AI capabilities <code>AnimalQuote</code> <code>data_models.py</code> Individual quote with metadata <code>AnimalWisdom</code> <code>data_models.py</code> Collection of validated quotes"},{"location":"corpus/#ai-integration","title":"\ud83e\udd16 AI Integration","text":"Component Purpose Key Features <code>AnimalWisdomResponse</code> Structured AI responses Insights, quotes, follow-ups RAG System Prompts AI instruction templates Optimized for animal wisdom LLM Integration OpenAI GPT integration Structured response generation"},{"location":"corpus/#typical-usage-flow","title":"\ud83d\udd04 Typical Usage Flow","text":"sequenceDiagram     participant User     participant Animals     participant AnimalWisdom     participant SemanticSearch     participant LLM      User-&gt;&gt;Animals: Initialize with vector DB     User-&gt;&gt;Animals: load_from_jsonl(file_path)     Animals-&gt;&gt;AnimalWisdom: Create from JSONL data     AnimalWisdom--&gt;&gt;Animals: Validated quote collection      User-&gt;&gt;Animals: index_all_quotes()     Animals-&gt;&gt;SemanticSearch: Batch index quotes     SemanticSearch--&gt;&gt;Animals: Point IDs      User-&gt;&gt;Animals: search(query)     Animals-&gt;&gt;SemanticSearch: Vector search     SemanticSearch--&gt;&gt;Animals: Scored results      User-&gt;&gt;Animals: ask_llm(question)     Animals-&gt;&gt;SemanticSearch: Find relevant quotes     Animals-&gt;&gt;LLM: Generate structured response     LLM--&gt;&gt;Animals: AnimalWisdomResponse     Animals--&gt;&gt;User: Rich formatted answer"},{"location":"corpus/#key-features","title":"\ud83d\udca1 Key Features","text":""},{"location":"corpus/#intelligent-search","title":"\ud83d\udd0d Intelligent Search","text":"<ul> <li>Semantic Understanding: Goes beyond keyword matching to understand meaning</li> <li>Metadata Filtering: Filter by author, category, or relevance score</li> <li>Batch Processing: Efficient handling of large quote collections</li> <li>Rich Display: Beautiful formatted results with the Rich library</li> </ul>"},{"location":"corpus/#ai-powered-responses","title":"\ud83e\udd16 AI-Powered Responses","text":"<ul> <li>Structured Outputs: Organized answers with insights and recommendations</li> <li>Source Attribution: All responses grounded in your quote collection</li> <li>Follow-up Questions: Suggested related queries for deeper exploration</li> <li>Multiple Response Types: Structured objects or simple text responses</li> </ul>"},{"location":"corpus/#data-management","title":"\ud83d\udcca Data Management","text":"<ul> <li>Validation: Comprehensive data validation using Pydantic</li> <li>Statistics: Collection analytics and health monitoring</li> <li>Consistency Checks: Verify database and embedder compatibility</li> <li>Error Handling: Detailed error messages with suggested solutions</li> </ul>"},{"location":"corpus/#quick-start-example","title":"\ud83d\ude80 Quick Start Example","text":"<pre><code>from pathlib import Path\nfrom rag_to_riches.vectordb.embedded_vectordb import EmbeddedVectorDB\nfrom rag_to_riches.corpus.animals import Animals\n\n# Initialize the system\nvector_db = EmbeddedVectorDB()\nanimals = Animals(vector_db, collection_name=\"wisdom_quotes\")\n\n# Load your data\nquotes_file = Path(\"data/animal_wisdom.jsonl\")\nwisdom = animals.load_from_jsonl(quotes_file)\nprint(f\"Loaded {len(wisdom)} quotes\")\n\n# Index for search\npoint_ids = animals.index_all_quotes()\nprint(f\"Indexed {len(point_ids)} quotes\")\n\n# Search semantically\nresults = animals.search(\"courage and bravery\", limit=5)\nanimals.display_search_results(results, \"Courage Quotes\")\n\n# Get AI insights\nresponse = animals.ask_llm(\"What can animals teach us about resilience?\")\nanimals.display_llm_response(response, \"resilience question\")\n\n# Complete RAG pipeline\nrag_result = animals.rag(\n    \"How do pets help with emotional healing?\",\n    limit=7,\n    response_type=\"structured\"\n)\n</code></pre>"},{"location":"corpus/#data-format","title":"\ud83d\udcc1 Data Format","text":"<p>The corpus expects JSONL (JSON Lines) format with this structure:</p> <pre><code>{\"text\": \"Dogs are not our whole life, but they make our lives whole.\", \"author\": \"Roger Caras\", \"category\": \"Pets and Companionship\"}\n{\"text\": \"The greatness of a nation can be judged by the way its animals are treated.\", \"author\": \"Mahatma Gandhi\", \"category\": \"Ethics and Compassion\"}\n</code></pre> <p>Required Fields: - <code>text</code>: The quote content (non-empty string) - <code>author</code>: Attribution (non-empty string) - <code>category</code>: Thematic classification (non-empty string)</p>"},{"location":"corpus/#advanced-configuration","title":"\ud83d\udee0\ufe0f Advanced Configuration","text":""},{"location":"corpus/#custom-system-prompts","title":"Custom System Prompts","text":"<p>The AI responses can be customized using external prompt files:</p> <pre><code># Custom prompt location\nAnimals.SYSTEM_PROMPT_PATH = Path(\"my_prompts/custom_animal_prompt.md\")\n\n# Or use the simple built-in prompt\nanimals.ask_llm(query, system_prompt=Animals.SIMPLE_ANIMALS_PROMPT)\n</code></pre>"},{"location":"corpus/#performance-tuning","title":"Performance Tuning","text":"<pre><code># Optimize for large collections\nanimals = Animals(\n    vector_db=vector_db,\n    collection_name=\"large_corpus\",\n    embedder=SimpleTextEmbedder(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n)\n\n# Batch operations for efficiency\nwisdom, point_ids = animals.load_and_index(large_file)\n\n# Filtered searches for precision\nresults = animals.search(\n    \"animal behavior\",\n    limit=10,\n    score_threshold=0.8,\n    category=\"Scientific Research\"\n)\n</code></pre>"},{"location":"corpus/#integration-with-other-packages","title":"\ud83d\udd17 Integration with Other Packages","text":"<p>The corpus package seamlessly integrates with other framework components:</p> <ul> <li>Vector Database: Persistent storage and retrieval</li> <li>Search: Semantic similarity matching  </li> <li>Exceptions: Comprehensive error handling</li> <li>Utils: Logging and configuration</li> </ul>"},{"location":"corpus/#detailed-documentation","title":"\ud83d\udcda Detailed Documentation","text":"<ul> <li>Animals Class: Complete RAG system documentation</li> <li>AnimalQuote Class: Individual quote data model</li> <li>AnimalWisdom Class: Quote collection management</li> </ul>"},{"location":"corpus/#use-cases","title":"\ud83c\udfaf Use Cases","text":"<ul> <li>Educational Chatbots: AI tutors with grounded animal knowledge</li> <li>Research Tools: Explore themes in animal-related literature</li> <li>Content Generation: Source-backed articles and presentations</li> <li>Interactive Learning: Question-answer systems for students</li> <li>Philosophical Exploration: Deep dives into animal wisdom and ethics</li> </ul> <p>The corpus package transforms static text into intelligent, interactive knowledge systems. Perfect for building educational tools, research applications, and AI-powered content systems. </p>"},{"location":"corpus/AnimalQuote/","title":"AnimalQuote Class: Individual Quote Data Model","text":""},{"location":"corpus/AnimalQuote/#class-overview","title":"\ud83c\udfaf Class Overview","text":"<p>The <code>AnimalQuote</code> class is a Pydantic data model that represents a single animal quote with comprehensive metadata. It provides robust validation, immutable data structures, and seamless integration with vector databases for semantic search applications.</p> <p>This class serves as the fundamental building block for the animal quotes corpus, ensuring data integrity and providing convenient methods for working with individual quotes.</p>"},{"location":"corpus/AnimalQuote/#class-definition","title":"\ud83d\udccb Class Definition","text":"<pre><code>class AnimalQuote(BaseModel):\n    \"\"\"Represents a single animal quote with metadata.\n\n    This model captures the structure of each line in the animals.jsonl file,\n    containing the quote text, author attribution, and thematic category.\n    \"\"\"\n</code></pre>"},{"location":"corpus/AnimalQuote/#class-architecture","title":"\ud83c\udfd7\ufe0f Class Architecture","text":"classDiagram     class AnimalQuote {         +str text         +str author         +str category         +ModelConfig model_config          +to_payload() Dict[str, Any]         +validate_non_empty_strings() str     }      note for AnimalQuote \"Immutable, validated data model\\nwith automatic whitespace handling\""},{"location":"corpus/AnimalQuote/#model-configuration","title":"\ud83d\udd27 Model Configuration","text":"<p>The class uses strict Pydantic configuration for data integrity:</p> <pre><code>model_config = ConfigDict(\n    str_strip_whitespace=True,    # Automatically strip whitespace\n    validate_assignment=True,     # Validate on field assignment\n    frozen=True,                  # Immutable after creation\n    extra=\"forbid\"               # Reject extra fields\n)\n</code></pre>"},{"location":"corpus/AnimalQuote/#configuration-features","title":"Configuration Features","text":"<ul> <li>Automatic Whitespace Stripping: All string fields are automatically trimmed</li> <li>Assignment Validation: Changes to fields are validated in real-time</li> <li>Immutable Objects: Quotes cannot be modified after creation (data integrity)</li> <li>Strict Schema: Extra fields are rejected to prevent data corruption</li> </ul>"},{"location":"corpus/AnimalQuote/#fields","title":"\ud83d\udcca Fields","text":""},{"location":"corpus/AnimalQuote/#text-str","title":"<code>text: str</code>","text":"<p>The actual quote content - the wisdom, insight, or saying attributed to animal behavior or human-animal relationships.</p> <p>Validation Rules: - Must be non-empty after whitespace stripping - Minimum length: 1 character - Automatically trimmed of leading/trailing whitespace</p> <p>Example Values: <pre><code>\"Dogs are not our whole life, but they make our lives whole.\"\n\"The greatness of a nation can be judged by the way its animals are treated.\"\n\"Until one has loved an animal, a part of one's soul remains unawakened.\"\n</code></pre></p>"},{"location":"corpus/AnimalQuote/#author-str","title":"<code>author: str</code>","text":"<p>Attribution of the quote to its original author - the person who said, wrote, or is credited with the wisdom.</p> <p>Validation Rules: - Must be non-empty after whitespace stripping - Minimum length: 1 character - Automatically trimmed of leading/trailing whitespace</p> <p>Example Values: <pre><code>\"Roger Caras\"\n\"Mahatma Gandhi\"\n\"Anatole France\"\n\"Albert Schweitzer\"\n</code></pre></p>"},{"location":"corpus/AnimalQuote/#category-str","title":"<code>category: str</code>","text":"<p>Thematic categorization that groups related quotes for easier discovery and filtering.</p> <p>Validation Rules: - Must be non-empty after whitespace stripping - Minimum length: 1 character - Automatically trimmed of leading/trailing whitespace</p> <p>Example Values: <pre><code>\"Pets and Companionship\"\n\"Ethics and Compassion\"\n\"Wisdom and Philosophy\"\n\"Animal Behavior\"\n\"Conservation and Nature\"\n</code></pre></p>"},{"location":"corpus/AnimalQuote/#methods","title":"\ud83d\udd0d Methods","text":""},{"location":"corpus/AnimalQuote/#validate_non_empty_stringscls-v-str-str","title":"<code>validate_non_empty_strings(cls, v: str) -&gt; str</code>","text":"<p>Class method validator that ensures all string fields are non-empty after stripping whitespace.</p>"},{"location":"corpus/AnimalQuote/#parameters","title":"Parameters","text":"Parameter Type Description <code>v</code> <code>str</code> The string value to validate"},{"location":"corpus/AnimalQuote/#returns","title":"Returns","text":"<p><code>str</code> - The validated and trimmed string</p>"},{"location":"corpus/AnimalQuote/#raises","title":"Raises","text":"<p><code>ValueError</code> - If the field is empty or contains only whitespace</p>"},{"location":"corpus/AnimalQuote/#implementation","title":"Implementation","text":"<pre><code>@field_validator('text', 'author', 'category')\n@classmethod\ndef validate_non_empty_strings(cls, v: str) -&gt; str:\n    \"\"\"Ensure all string fields are non-empty after stripping.\"\"\"\n    if not v or not v.strip():\n        raise ValueError(\"Field cannot be empty or whitespace only\")\n    return v.strip()\n</code></pre>"},{"location":"corpus/AnimalQuote/#to_payloadself-dictstr-any","title":"<code>to_payload(self) -&gt; Dict[str, Any]</code>","text":"<p>Convert the quote to a payload dictionary suitable for vector database storage.</p>"},{"location":"corpus/AnimalQuote/#returns_1","title":"Returns","text":"<p><code>Dict[str, Any]</code> - Dictionary with standardized keys for Qdrant point payload</p>"},{"location":"corpus/AnimalQuote/#return-structure","title":"Return Structure","text":"<pre><code>{\n    \"content\": self.text,           # The quote text for searching\n    \"content_type\": \"animal_quote\", # Type identifier\n    \"author\": self.author,          # Author attribution\n    \"category\": self.category       # Thematic category\n}\n</code></pre>"},{"location":"corpus/AnimalQuote/#example-usage","title":"Example Usage","text":"<pre><code>quote = AnimalQuote(\n    text=\"Dogs are loyal companions who teach us about unconditional love.\",\n    author=\"Unknown\",\n    category=\"Pets and Companionship\"\n)\n\npayload = quote.to_payload()\nprint(payload)\n# Output:\n# {\n#     \"content\": \"Dogs are loyal companions who teach us about unconditional love.\",\n#     \"content_type\": \"animal_quote\",\n#     \"author\": \"Unknown\", \n#     \"category\": \"Pets and Companionship\"\n# }\n</code></pre>"},{"location":"corpus/AnimalQuote/#use-cases","title":"Use Cases","text":"<ul> <li>Storing quotes in vector databases (Qdrant points)</li> <li>Serializing for API responses</li> <li>Converting to search metadata</li> <li>Preparing data for machine learning pipelines</li> </ul>"},{"location":"corpus/AnimalQuote/#usage-examples","title":"\ud83d\udca1 Usage Examples","text":""},{"location":"corpus/AnimalQuote/#basic-creation","title":"Basic Creation","text":"<pre><code>from rag_to_riches.corpus.data_models import AnimalQuote\n\n# Create a simple quote\nquote = AnimalQuote(\n    text=\"A dog is the only thing on earth that loves you more than you love yourself.\",\n    author=\"Josh Billings\",\n    category=\"Pets and Companionship\"\n)\n\nprint(f\"Quote: {quote.text}\")\nprint(f\"By: {quote.author}\")\nprint(f\"Category: {quote.category}\")\n</code></pre>"},{"location":"corpus/AnimalQuote/#from-jsonl-data","title":"From JSONL Data","text":"<pre><code>import json\n\n# Typical JSONL line\njsonl_line = '{\"text\": \"Animals are such agreeable friends\u2014they ask no questions; they pass no criticisms.\", \"author\": \"George Eliot\", \"category\": \"Friendship and Understanding\"}'\n\n# Parse and create quote\ndata = json.loads(jsonl_line)\nquote = AnimalQuote(**data)\n\nprint(f\"Created quote: {quote.text[:50]}...\")\n</code></pre>"},{"location":"corpus/AnimalQuote/#validation-in-action","title":"Validation in Action","text":"<pre><code># This will work - valid data\ngood_quote = AnimalQuote(\n    text=\"  Cats choose us; we don't own them.  \",  # Whitespace will be stripped\n    author=\"Kristin Cast\",\n    category=\"Pet Wisdom\"\n)\n\n# This will fail - empty text after stripping\ntry:\n    bad_quote = AnimalQuote(\n        text=\"   \",  # Only whitespace\n        author=\"Someone\",\n        category=\"Some Category\"\n    )\nexcept ValueError as e:\n    print(f\"Validation error: {e}\")\n</code></pre>"},{"location":"corpus/AnimalQuote/#immutability-demonstration","title":"Immutability Demonstration","text":"<pre><code>quote = AnimalQuote(\n    text=\"Dogs have a way of finding the people who need them.\",\n    author=\"Thom Jones\",\n    category=\"Healing and Therapy\"\n)\n\n# This will fail - objects are frozen\ntry:\n    quote.text = \"New text\"\nexcept ValueError as e:\n    print(f\"Cannot modify: {e}\")\n</code></pre>"},{"location":"corpus/AnimalQuote/#vector-database-integration","title":"Vector Database Integration","text":"<pre><code># Convert to payload for storage\nquote = AnimalQuote(\n    text=\"The bond with a dog is as lasting as the ties of this earth can ever be.\",\n    author=\"Konrad Lorenz\",\n    category=\"Human-Animal Bond\"\n)\n\n# Prepare for vector database\npayload = quote.to_payload()\n\n# This payload can be used with Qdrant points\npoint_id = str(uuid4())\nvector = embedder.embed_text(quote.text)\n\npoint = models.PointStruct(\n    id=point_id,\n    vector=vector,\n    payload=payload\n)\n</code></pre>"},{"location":"corpus/AnimalQuote/#error-handling","title":"\ud83d\udee1\ufe0f Error Handling","text":""},{"location":"corpus/AnimalQuote/#common-validation-errors","title":"Common Validation Errors","text":""},{"location":"corpus/AnimalQuote/#empty-fields","title":"Empty Fields","text":"<pre><code># These will all raise ValueError\ntry:\n    AnimalQuote(text=\"\", author=\"Author\", category=\"Category\")\nexcept ValueError:\n    print(\"Empty text not allowed\")\n\ntry:\n    AnimalQuote(text=\"Quote\", author=\"   \", category=\"Category\")  \nexcept ValueError:\n    print(\"Whitespace-only author not allowed\")\n\ntry:\n    AnimalQuote(text=\"Quote\", author=\"Author\", category=None)\nexcept ValueError:\n    print(\"None values not allowed\")\n</code></pre>"},{"location":"corpus/AnimalQuote/#extra-fields","title":"Extra Fields","text":"<pre><code># This will fail due to extra=\"forbid\"\ntry:\n    AnimalQuote(\n        text=\"Quote\",\n        author=\"Author\", \n        category=\"Category\",\n        extra_field=\"Not allowed\"\n    )\nexcept ValueError:\n    print(\"Extra fields not permitted\")\n</code></pre>"},{"location":"corpus/AnimalQuote/#type-errors","title":"Type Errors","text":"<pre><code># This will fail - wrong types\ntry:\n    AnimalQuote(\n        text=123,  # Should be string\n        author=\"Author\",\n        category=\"Category\"\n    )\nexcept ValueError:\n    print(\"Text must be a string\")\n</code></pre>"},{"location":"corpus/AnimalQuote/#integration-points","title":"\ud83d\udd17 Integration Points","text":""},{"location":"corpus/AnimalQuote/#with-animalwisdom","title":"With AnimalWisdom","text":"<pre><code>from rag_to_riches.corpus.data_models import AnimalWisdom\n\nquotes = [\n    AnimalQuote(text=\"Quote 1\", author=\"Author 1\", category=\"Category A\"),\n    AnimalQuote(text=\"Quote 2\", author=\"Author 2\", category=\"Category B\"),\n]\n\nwisdom = AnimalWisdom(quotes=quotes)\n</code></pre>"},{"location":"corpus/AnimalQuote/#with-vector-databases","title":"With Vector Databases","text":"<pre><code># Batch conversion for indexing\nquotes = [...]  # List of AnimalQuote objects\npayloads = [quote.to_payload() for quote in quotes]\ntexts = [quote.text for quote in quotes]\n\n# Ready for semantic search indexing\nsemantic_search.index_all_text(texts=texts, metadata_list=payloads)\n</code></pre>"},{"location":"corpus/AnimalQuote/#with-json-serialization","title":"With JSON Serialization","text":"<pre><code># Pydantic provides JSON serialization\nquote = AnimalQuote(text=\"Quote\", author=\"Author\", category=\"Category\")\n\n# To JSON\njson_str = quote.model_dump_json()\n\n# From JSON  \nquote_copy = AnimalQuote.model_validate_json(json_str)\n</code></pre>"},{"location":"corpus/AnimalQuote/#design-principles","title":"\ud83c\udfaf Design Principles","text":""},{"location":"corpus/AnimalQuote/#data-integrity","title":"Data Integrity","text":"<ul> <li>Immutable: Once created, quotes cannot be modified</li> <li>Validated: All fields are checked for correctness</li> <li>Consistent: Automatic whitespace handling ensures clean data</li> </ul>"},{"location":"corpus/AnimalQuote/#performance","title":"Performance","text":"<ul> <li>Lightweight: Minimal overhead for individual quotes</li> <li>Efficient: Fast validation and serialization</li> <li>Memory-friendly: Frozen objects can be safely shared</li> </ul>"},{"location":"corpus/AnimalQuote/#usability","title":"Usability","text":"<ul> <li>Clear API: Simple, intuitive field names and methods</li> <li>Rich Errors: Detailed error messages for debugging</li> <li>Integration-ready: Designed for vector database and AI workflows</li> </ul>"},{"location":"corpus/AnimalQuote/#advanced-usage","title":"\ud83d\udd0d Advanced Usage","text":""},{"location":"corpus/AnimalQuote/#custom-validation","title":"Custom Validation","text":"<pre><code>from pydantic import field_validator\n\nclass ExtendedAnimalQuote(AnimalQuote):\n    @field_validator('category')\n    @classmethod\n    def validate_category(cls, v):\n        valid_categories = [\n            \"Pets and Companionship\",\n            \"Ethics and Compassion\", \n            \"Wisdom and Philosophy\",\n            \"Animal Behavior\",\n            \"Conservation and Nature\"\n        ]\n        if v not in valid_categories:\n            raise ValueError(f\"Category must be one of: {valid_categories}\")\n        return v\n</code></pre>"},{"location":"corpus/AnimalQuote/#batch-processing","title":"Batch Processing","text":"<pre><code># Process multiple quotes efficiently\njsonl_data = [\n    {\"text\": \"Quote 1\", \"author\": \"Author 1\", \"category\": \"Category A\"},\n    {\"text\": \"Quote 2\", \"author\": \"Author 2\", \"category\": \"Category B\"},\n    # ... more quotes\n]\n\nquotes = []\nfor data in jsonl_data:\n    try:\n        quote = AnimalQuote(**data)\n        quotes.append(quote)\n    except ValueError as e:\n        print(f\"Skipping invalid quote: {e}\")\n\nprint(f\"Successfully created {len(quotes)} quotes\")\n</code></pre>"},{"location":"corpus/AnimalQuote/#source-code","title":"\ud83d\udcda Source Code","text":"<p>The AnimalQuote class exemplifies modern data modeling best practices - combining Pydantic's validation power with domain-specific requirements to create robust, reliable data structures for RAG applications. </p>"},{"location":"corpus/AnimalQuote/#rag_to_riches.corpus.data_models.AnimalQuote","title":"<code>rag_to_riches.corpus.data_models.AnimalQuote</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a single animal quote with metadata.</p> <p>This model captures the structure of each line in the animals.jsonl file, containing the quote text, author attribution, and thematic category.</p> <p>Attributes:</p> Name Type Description <code>text</code> <code>str</code> <p>The actual quote text content</p> <code>author</code> <code>str</code> <p>Attribution of the quote to its original author</p> <code>category</code> <code>str</code> <p>Thematic categorization for the quote</p> Source code in <code>src/rag_to_riches/corpus/data_models.py</code> <pre><code>class AnimalQuote(BaseModel):\n    \"\"\"Represents a single animal quote with metadata.\n\n    This model captures the structure of each line in the animals.jsonl file,\n    containing the quote text, author attribution, and thematic category.\n\n    Attributes:\n        text: The actual quote text content\n        author: Attribution of the quote to its original author\n        category: Thematic categorization for the quote\n    \"\"\"\n    model_config = ConfigDict(\n        str_strip_whitespace=True,\n        validate_assignment=True,\n        frozen=True,\n        extra=\"forbid\"\n    )\n\n    text: str = Field(\n        ..., \n        min_length=1, \n        description=\"The animal quote text content\"\n    )\n    author: str = Field(\n        ..., \n        min_length=1, \n        description=\"The author of the quote\"\n    )\n    category: str = Field(\n        ..., \n        min_length=1, \n        description=\"Thematic category for the quote\"\n    )\n\n    @field_validator('text', 'author', 'category')\n    @classmethod\n    def validate_non_empty_strings(cls, v: str) -&gt; str:\n        \"\"\"Ensure all string fields are non-empty after stripping.\"\"\"\n        if not v or not v.strip():\n            raise ValueError(\"Field cannot be empty or whitespace only\")\n        return v.strip()\n\n    def to_payload(self) -&gt; Dict[str, Any]:\n        \"\"\"Convert the quote to a payload dictionary for vector storage.\n\n        Returns:\n            Dictionary suitable for Qdrant point payload.\n        \"\"\"\n        return {\n            \"content\": self.text,\n            \"content_type\": \"animal_quote\",\n            \"author\": self.author,\n            \"category\": self.category\n        }\n</code></pre>"},{"location":"corpus/AnimalQuote/#rag_to_riches.corpus.data_models.AnimalQuote.to_payload","title":"<code>to_payload()</code>","text":"<p>Convert the quote to a payload dictionary for vector storage.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary suitable for Qdrant point payload.</p> Source code in <code>src/rag_to_riches/corpus/data_models.py</code> <pre><code>def to_payload(self) -&gt; Dict[str, Any]:\n    \"\"\"Convert the quote to a payload dictionary for vector storage.\n\n    Returns:\n        Dictionary suitable for Qdrant point payload.\n    \"\"\"\n    return {\n        \"content\": self.text,\n        \"content_type\": \"animal_quote\",\n        \"author\": self.author,\n        \"category\": self.category\n    }\n</code></pre>"},{"location":"corpus/AnimalQuote/#rag_to_riches.corpus.data_models.AnimalQuote.validate_non_empty_strings","title":"<code>validate_non_empty_strings(v)</code>  <code>classmethod</code>","text":"<p>Ensure all string fields are non-empty after stripping.</p> Source code in <code>src/rag_to_riches/corpus/data_models.py</code> <pre><code>@field_validator('text', 'author', 'category')\n@classmethod\ndef validate_non_empty_strings(cls, v: str) -&gt; str:\n    \"\"\"Ensure all string fields are non-empty after stripping.\"\"\"\n    if not v or not v.strip():\n        raise ValueError(\"Field cannot be empty or whitespace only\")\n    return v.strip()\n</code></pre>"},{"location":"corpus/AnimalWisdom/","title":"AnimalWisdom Class: Quote Collection Management","text":""},{"location":"corpus/AnimalWisdom/#class-overview","title":"\ud83c\udfaf Class Overview","text":"<p>The <code>AnimalWisdom</code> class is a sophisticated Pydantic data model that represents a complete collection of animal quotes. It provides validation, convenient access methods, and powerful filtering capabilities for managing large sets of quotes loaded from corpus files.</p> <p>This class serves as the primary container for quote collections, offering both data integrity and rich functionality for exploring and analyzing animal wisdom across different authors, categories, and themes.</p>"},{"location":"corpus/AnimalWisdom/#class-definition","title":"\ud83d\udccb Class Definition","text":"<pre><code>class AnimalWisdom(BaseModel):\n    \"\"\"Collection of animal quotes loaded from the corpus.\n\n    This model represents the complete collection of animal quotes,\n    providing validation and convenient access methods for the data.\n    \"\"\"\n</code></pre>"},{"location":"corpus/AnimalWisdom/#class-architecture","title":"\ud83c\udfd7\ufe0f Class Architecture","text":"classDiagram     class AnimalWisdom {         +List[AnimalQuote] quotes         +Optional[Path] source_file         +ModelConfig model_config          +__len__() int         +get_categories() List[str]         +get_authors() List[str]         +filter_by_category(category) List[AnimalQuote]         +filter_by_author(author) List[AnimalQuote]         +validate_quotes_not_empty() List[AnimalQuote]     }      class AnimalQuote {         +str text         +str author         +str category     }      AnimalWisdom *-- AnimalQuote : contains many      note for AnimalWisdom \"Collection container with\\nfiltering and analysis methods\""},{"location":"corpus/AnimalWisdom/#model-configuration","title":"\ud83d\udd27 Model Configuration","text":"<p>The class uses flexible Pydantic configuration for collection management:</p> <pre><code>model_config = ConfigDict(\n    validate_assignment=True,      # Validate on field assignment\n    arbitrary_types_allowed=True   # Allow Path objects\n)\n</code></pre>"},{"location":"corpus/AnimalWisdom/#configuration-features","title":"Configuration Features","text":"<ul> <li>Assignment Validation: Changes to the collection are validated</li> <li>Type Flexibility: Supports Path objects for source file tracking</li> <li>Mutable Collections: Allows for dynamic quote management</li> <li>Extensible Design: Ready for additional metadata and features</li> </ul>"},{"location":"corpus/AnimalWisdom/#fields","title":"\ud83d\udcca Fields","text":""},{"location":"corpus/AnimalWisdom/#quotes-listanimalquote","title":"<code>quotes: List[AnimalQuote]</code>","text":"<p>The core collection of animal quotes, each represented as a validated <code>AnimalQuote</code> instance.</p> <p>Validation Rules: - Must contain at least one quote (non-empty list) - All items must be valid <code>AnimalQuote</code> instances - Validated on assignment and initialization</p> <p>Example Structure: <pre><code>quotes = [\n    AnimalQuote(\n        text=\"Dogs are not our whole life, but they make our lives whole.\",\n        author=\"Roger Caras\",\n        category=\"Pets and Companionship\"\n    ),\n    AnimalQuote(\n        text=\"The greatness of a nation can be judged by the way its animals are treated.\",\n        author=\"Mahatma Gandhi\", \n        category=\"Ethics and Compassion\"\n    ),\n    # ... more quotes\n]\n</code></pre></p>"},{"location":"corpus/AnimalWisdom/#source_file-optionalpath","title":"<code>source_file: Optional[Path]</code>","text":"<p>Optional path to the source JSONL file from which the quotes were loaded. Useful for tracking data provenance and enabling reload operations.</p> <p>Features: - Tracks the origin of the quote collection - Enables data lineage and debugging - Supports reload and refresh operations - Can be None for programmatically created collections</p> <p>Example Values: <pre><code>source_file = Path(\"data/corpus/animals/animals.jsonl\")\nsource_file = Path(\"/home/user/quotes/wisdom_collection.jsonl\")\nsource_file = None  # For programmatically created collections\n</code></pre></p>"},{"location":"corpus/AnimalWisdom/#methods","title":"\ud83d\udd0d Methods","text":""},{"location":"corpus/AnimalWisdom/#__len__self-int","title":"<code>__len__(self) -&gt; int</code>","text":"<p>Return the number of quotes in the collection.</p>"},{"location":"corpus/AnimalWisdom/#returns","title":"Returns","text":"<p><code>int</code> - Total count of quotes in the collection</p>"},{"location":"corpus/AnimalWisdom/#example-usage","title":"Example Usage","text":"<pre><code>wisdom = AnimalWisdom(quotes=[...])\nprint(f\"Collection contains {len(wisdom)} quotes\")\n\n# Use in conditionals\nif len(wisdom) &gt; 100:\n    print(\"Large collection detected\")\n</code></pre>"},{"location":"corpus/AnimalWisdom/#get_categoriesself-liststr","title":"<code>get_categories(self) -&gt; List[str]</code>","text":"<p>Get unique categories from all quotes in the collection.</p>"},{"location":"corpus/AnimalWisdom/#returns_1","title":"Returns","text":"<p><code>List[str]</code> - Sorted list of unique category names</p>"},{"location":"corpus/AnimalWisdom/#example-usage_1","title":"Example Usage","text":"<pre><code>categories = wisdom.get_categories()\nprint(f\"Available categories ({len(categories)}):\")\nfor category in categories:\n    print(f\"  - {category}\")\n\n# Example output:\n# Available categories (5):\n#   - Animal Behavior\n#   - Ethics and Compassion\n#   - Pets and Companionship\n#   - Wisdom and Philosophy\n#   - Wildlife and Conservation\n</code></pre>"},{"location":"corpus/AnimalWisdom/#use-cases","title":"Use Cases","text":"<ul> <li>Building category filters for search interfaces</li> <li>Analyzing thematic distribution of quotes</li> <li>Creating navigation menus</li> <li>Generating collection statistics</li> </ul>"},{"location":"corpus/AnimalWisdom/#get_authorsself-liststr","title":"<code>get_authors(self) -&gt; List[str]</code>","text":"<p>Get unique authors from all quotes in the collection.</p>"},{"location":"corpus/AnimalWisdom/#returns_2","title":"Returns","text":"<p><code>List[str]</code> - Sorted list of unique author names</p>"},{"location":"corpus/AnimalWisdom/#example-usage_2","title":"Example Usage","text":"<pre><code>authors = wisdom.get_authors()\nprint(f\"Quotes from {len(authors)} different authors:\")\nfor author in authors[:10]:  # Show first 10\n    print(f\"  - {author}\")\n\n# Find most prolific authors\nauthor_counts = {}\nfor quote in wisdom.quotes:\n    author_counts[quote.author] = author_counts.get(quote.author, 0) + 1\n\ntop_authors = sorted(author_counts.items(), key=lambda x: x[1], reverse=True)\nprint(f\"Most quoted author: {top_authors[0][0]} ({top_authors[0][1]} quotes)\")\n</code></pre>"},{"location":"corpus/AnimalWisdom/#use-cases_1","title":"Use Cases","text":"<ul> <li>Author-based filtering and search</li> <li>Attribution analysis and verification</li> <li>Building author indexes</li> <li>Identifying collection coverage and gaps</li> </ul>"},{"location":"corpus/AnimalWisdom/#filter_by_categoryself-category-str-listanimalquote","title":"<code>filter_by_category(self, category: str) -&gt; List[AnimalQuote]</code>","text":"<p>Filter quotes by category, returning all quotes that match the specified category.</p>"},{"location":"corpus/AnimalWisdom/#parameters","title":"Parameters","text":"Parameter Type Description <code>category</code> <code>str</code> Category name to filter by (exact match)"},{"location":"corpus/AnimalWisdom/#returns_3","title":"Returns","text":"<p><code>List[AnimalQuote]</code> - List of quotes matching the specified category</p>"},{"location":"corpus/AnimalWisdom/#example-usage_3","title":"Example Usage","text":"<pre><code># Get all quotes about pets\npet_quotes = wisdom.filter_by_category(\"Pets and Companionship\")\nprint(f\"Found {len(pet_quotes)} quotes about pets:\")\n\nfor quote in pet_quotes[:3]:\n    print(f\"  '{quote.text}' - {quote.author}\")\n\n# Analyze category distribution\nethics_quotes = wisdom.filter_by_category(\"Ethics and Compassion\")\nwisdom_quotes = wisdom.filter_by_category(\"Wisdom and Philosophy\")\n\nprint(f\"Ethics quotes: {len(ethics_quotes)}\")\nprint(f\"Wisdom quotes: {len(wisdom_quotes)}\")\n</code></pre>"},{"location":"corpus/AnimalWisdom/#use-cases_2","title":"Use Cases","text":"<ul> <li>Thematic exploration of quotes</li> <li>Building category-specific collections</li> <li>Content curation for specific topics</li> <li>Analyzing quote distribution across themes</li> </ul>"},{"location":"corpus/AnimalWisdom/#filter_by_authorself-author-str-listanimalquote","title":"<code>filter_by_author(self, author: str) -&gt; List[AnimalQuote]</code>","text":"<p>Filter quotes by author, returning all quotes attributed to the specified author.</p>"},{"location":"corpus/AnimalWisdom/#parameters_1","title":"Parameters","text":"Parameter Type Description <code>author</code> <code>str</code> Author name to filter by (exact match)"},{"location":"corpus/AnimalWisdom/#returns_4","title":"Returns","text":"<p><code>List[AnimalQuote]</code> - List of quotes by the specified author</p>"},{"location":"corpus/AnimalWisdom/#example-usage_4","title":"Example Usage","text":"<pre><code># Get all quotes by Gandhi\ngandhi_quotes = wisdom.filter_by_author(\"Mahatma Gandhi\")\nprint(f\"Gandhi's quotes about animals ({len(gandhi_quotes)}):\")\n\nfor quote in gandhi_quotes:\n    print(f\"  '{quote.text}'\")\n    print(f\"  Category: {quote.category}\")\n    print()\n\n# Compare authors\neinstein_quotes = wisdom.filter_by_author(\"Albert Einstein\")\nschweitzer_quotes = wisdom.filter_by_author(\"Albert Schweitzer\")\n\nprint(f\"Einstein: {len(einstein_quotes)} quotes\")\nprint(f\"Schweitzer: {len(schweitzer_quotes)} quotes\")\n</code></pre>"},{"location":"corpus/AnimalWisdom/#use-cases_3","title":"Use Cases","text":"<ul> <li>Author-focused research and analysis</li> <li>Building author-specific quote collections</li> <li>Verifying attribution and coverage</li> <li>Comparative analysis between authors</li> </ul>"},{"location":"corpus/AnimalWisdom/#validate_quotes_not_emptycls-v-listanimalquote-listanimalquote","title":"<code>validate_quotes_not_empty(cls, v: List[AnimalQuote]) -&gt; List[AnimalQuote]</code>","text":"<p>Class method validator that ensures the quotes collection is not empty.</p>"},{"location":"corpus/AnimalWisdom/#parameters_2","title":"Parameters","text":"Parameter Type Description <code>v</code> <code>List[AnimalQuote]</code> The quotes list to validate"},{"location":"corpus/AnimalWisdom/#returns_5","title":"Returns","text":"<p><code>List[AnimalQuote]</code> - The validated quotes list</p>"},{"location":"corpus/AnimalWisdom/#raises","title":"Raises","text":"<p><code>ValueError</code> - If the quotes collection is empty</p>"},{"location":"corpus/AnimalWisdom/#implementation","title":"Implementation","text":"<pre><code>@field_validator('quotes')\n@classmethod\ndef validate_quotes_not_empty(cls, v: List[AnimalQuote]) -&gt; List[AnimalQuote]:\n    \"\"\"Ensure quotes list is not empty.\"\"\"\n    if not v:\n        raise ValueError(\"Quotes collection cannot be empty\")\n    return v\n</code></pre>"},{"location":"corpus/AnimalWisdom/#usage-examples","title":"\ud83d\udca1 Usage Examples","text":""},{"location":"corpus/AnimalWisdom/#basic-creation","title":"Basic Creation","text":"<pre><code>from pathlib import Path\nfrom rag_to_riches.corpus.data_models import AnimalQuote, AnimalWisdom\n\n# Create individual quotes\nquotes = [\n    AnimalQuote(\n        text=\"A dog is the only thing on earth that loves you more than you love yourself.\",\n        author=\"Josh Billings\",\n        category=\"Pets and Companionship\"\n    ),\n    AnimalQuote(\n        text=\"Animals are such agreeable friends\u2014they ask no questions; they pass no criticisms.\",\n        author=\"George Eliot\",\n        category=\"Friendship and Understanding\"\n    ),\n    AnimalQuote(\n        text=\"The greatness of a nation can be judged by the way its animals are treated.\",\n        author=\"Mahatma Gandhi\",\n        category=\"Ethics and Compassion\"\n    )\n]\n\n# Create wisdom collection\nwisdom = AnimalWisdom(\n    quotes=quotes,\n    source_file=Path(\"data/sample_quotes.jsonl\")\n)\n\nprint(f\"Created collection with {len(wisdom)} quotes\")\n</code></pre>"},{"location":"corpus/AnimalWisdom/#from-jsonl-loading","title":"From JSONL Loading","text":"<pre><code>import json\nfrom pathlib import Path\n\n# Simulate loading from JSONL file\njsonl_content = [\n    '{\"text\": \"Dogs have a way of finding the people who need them.\", \"author\": \"Thom Jones\", \"category\": \"Healing and Therapy\"}',\n    '{\"text\": \"Cats choose us; we don\\'t own them.\", \"author\": \"Kristin Cast\", \"category\": \"Pet Wisdom\"}',\n    '{\"text\": \"The bond with a dog is as lasting as the ties of this earth can ever be.\", \"author\": \"Konrad Lorenz\", \"category\": \"Human-Animal Bond\"}'\n]\n\n# Parse quotes\nquotes = []\nfor line in jsonl_content:\n    data = json.loads(line)\n    quotes.append(AnimalQuote(**data))\n\n# Create wisdom collection\nwisdom = AnimalWisdom(\n    quotes=quotes,\n    source_file=Path(\"data/therapy_quotes.jsonl\")\n)\n\nprint(f\"Loaded {len(wisdom)} quotes from JSONL\")\n</code></pre>"},{"location":"corpus/AnimalWisdom/#collection-analysis","title":"Collection Analysis","text":"<pre><code># Comprehensive collection analysis\nwisdom = AnimalWisdom(quotes=[...])  # Assume loaded collection\n\nprint(\"=== Collection Statistics ===\")\nprint(f\"Total quotes: {len(wisdom)}\")\nprint(f\"Unique authors: {len(wisdom.get_authors())}\")\nprint(f\"Categories: {len(wisdom.get_categories())}\")\nprint()\n\nprint(\"=== Category Distribution ===\")\ncategories = wisdom.get_categories()\nfor category in categories:\n    count = len(wisdom.filter_by_category(category))\n    percentage = (count / len(wisdom)) * 100\n    print(f\"{category}: {count} quotes ({percentage:.1f}%)\")\nprint()\n\nprint(\"=== Top Authors ===\")\nauthor_counts = {}\nfor quote in wisdom.quotes:\n    author_counts[quote.author] = author_counts.get(quote.author, 0) + 1\n\ntop_authors = sorted(author_counts.items(), key=lambda x: x[1], reverse=True)\nfor author, count in top_authors[:5]:\n    print(f\"{author}: {count} quotes\")\n</code></pre>"},{"location":"corpus/AnimalWisdom/#filtering-and-exploration","title":"Filtering and Exploration","text":"<pre><code># Explore specific themes\nwisdom = AnimalWisdom(quotes=[...])\n\n# Find all ethics-related quotes\nethics_quotes = wisdom.filter_by_category(\"Ethics and Compassion\")\nprint(f\"Ethics and Compassion ({len(ethics_quotes)} quotes):\")\nfor quote in ethics_quotes:\n    print(f\"  '{quote.text[:60]}...' - {quote.author}\")\nprint()\n\n# Explore a specific author's perspective\ngandhi_quotes = wisdom.filter_by_author(\"Mahatma Gandhi\")\nprint(f\"Mahatma Gandhi's perspective ({len(gandhi_quotes)} quotes):\")\nfor quote in gandhi_quotes:\n    print(f\"  Category: {quote.category}\")\n    print(f\"  Quote: '{quote.text}'\")\n    print()\n\n# Cross-analysis: Find authors who wrote about specific themes\npet_authors = set()\nfor quote in wisdom.filter_by_category(\"Pets and Companionship\"):\n    pet_authors.add(quote.author)\n\nprint(f\"Authors who wrote about pets: {len(pet_authors)}\")\nfor author in sorted(pet_authors):\n    print(f\"  - {author}\")\n</code></pre>"},{"location":"corpus/AnimalWisdom/#data-validation","title":"Data Validation","text":"<pre><code># Validation examples\ntry:\n    # This will fail - empty collection\n    empty_wisdom = AnimalWisdom(quotes=[])\nexcept ValueError as e:\n    print(f\"Validation error: {e}\")\n\ntry:\n    # This will work - valid collection\n    valid_quotes = [\n        AnimalQuote(text=\"Quote 1\", author=\"Author 1\", category=\"Category A\"),\n        AnimalQuote(text=\"Quote 2\", author=\"Author 2\", category=\"Category B\")\n    ]\n    valid_wisdom = AnimalWisdom(quotes=valid_quotes)\n    print(f\"Successfully created collection with {len(valid_wisdom)} quotes\")\nexcept ValueError as e:\n    print(f\"Unexpected error: {e}\")\n</code></pre>"},{"location":"corpus/AnimalWisdom/#error-handling","title":"\ud83d\udee1\ufe0f Error Handling","text":""},{"location":"corpus/AnimalWisdom/#common-validation-errors","title":"Common Validation Errors","text":""},{"location":"corpus/AnimalWisdom/#empty-collection","title":"Empty Collection","text":"<pre><code># This will raise ValueError\ntry:\n    empty_wisdom = AnimalWisdom(quotes=[])\nexcept ValueError as e:\n    print(f\"Cannot create empty collection: {e}\")\n</code></pre>"},{"location":"corpus/AnimalWisdom/#invalid-quote-objects","title":"Invalid Quote Objects","text":"<pre><code># This will raise validation errors\ntry:\n    invalid_wisdom = AnimalWisdom(quotes=[\"not a quote object\"])\nexcept ValueError as e:\n    print(f\"Invalid quote type: {e}\")\n</code></pre>"},{"location":"corpus/AnimalWisdom/#source-file-issues","title":"Source File Issues","text":"<pre><code># Source file validation (if custom validators are added)\ntry:\n    wisdom = AnimalWisdom(\n        quotes=[valid_quote],\n        source_file=\"not_a_path_object\"  # Should be Path object\n    )\nexcept ValueError as e:\n    print(f\"Source file error: {e}\")\n</code></pre>"},{"location":"corpus/AnimalWisdom/#integration-points","title":"\ud83d\udd17 Integration Points","text":""},{"location":"corpus/AnimalWisdom/#with-animals-class","title":"With Animals Class","text":"<pre><code>from rag_to_riches.corpus.animals import Animals\n\n# AnimalWisdom is returned by Animals.load_from_jsonl()\nanimals = Animals(vector_db)\nwisdom = animals.load_from_jsonl(Path(\"quotes.jsonl\"))\n\n# Access the collection methods\nprint(f\"Categories: {wisdom.get_categories()}\")\nprint(f\"Authors: {wisdom.get_authors()}\")\n</code></pre>"},{"location":"corpus/AnimalWisdom/#with-vector-databases","title":"With Vector Databases","text":"<pre><code># Prepare for indexing\nwisdom = AnimalWisdom(quotes=[...])\n\n# Extract data for vector operations\ntexts = [quote.text for quote in wisdom.quotes]\npayloads = [quote.to_payload() for quote in wisdom.quotes]\n\n# Index in vector database\nsemantic_search.index_all_text(texts=texts, metadata_list=payloads)\n</code></pre>"},{"location":"corpus/AnimalWisdom/#with-analysis-tools","title":"With Analysis Tools","text":"<pre><code># Export for external analysis\nimport pandas as pd\n\nwisdom = AnimalWisdom(quotes=[...])\n\n# Convert to DataFrame\ndata = []\nfor quote in wisdom.quotes:\n    data.append({\n        'text': quote.text,\n        'author': quote.author,\n        'category': quote.category,\n        'text_length': len(quote.text),\n        'word_count': len(quote.text.split())\n    })\n\ndf = pd.DataFrame(data)\nprint(df.describe())\n</code></pre>"},{"location":"corpus/AnimalWisdom/#design-principles","title":"\ud83c\udfaf Design Principles","text":""},{"location":"corpus/AnimalWisdom/#collection-management","title":"Collection Management","text":"<ul> <li>Comprehensive: Manages complete quote collections with metadata</li> <li>Flexible: Supports various collection sizes and sources</li> <li>Analytical: Provides rich methods for exploring and filtering data</li> </ul>"},{"location":"corpus/AnimalWisdom/#data-integrity","title":"Data Integrity","text":"<ul> <li>Validated: Ensures all quotes are valid AnimalQuote instances</li> <li>Consistent: Maintains collection invariants and constraints</li> <li>Traceable: Tracks data provenance through source file references</li> </ul>"},{"location":"corpus/AnimalWisdom/#performance","title":"Performance","text":"<ul> <li>Efficient Filtering: Fast category and author-based filtering</li> <li>Memory Conscious: Reasonable memory usage for large collections</li> <li>Lazy Operations: Methods compute results on-demand</li> </ul>"},{"location":"corpus/AnimalWisdom/#advanced-usage","title":"\ud83d\udd0d Advanced Usage","text":""},{"location":"corpus/AnimalWisdom/#custom-analysis-methods","title":"Custom Analysis Methods","text":"<pre><code>class ExtendedAnimalWisdom(AnimalWisdom):\n    def get_quotes_by_length(self, min_length: int = 0, max_length: int = float('inf')) -&gt; List[AnimalQuote]:\n        \"\"\"Filter quotes by text length.\"\"\"\n        return [\n            quote for quote in self.quotes \n            if min_length &lt;= len(quote.text) &lt;= max_length\n        ]\n\n    def get_most_quoted_authors(self, top_n: int = 5) -&gt; List[tuple]:\n        \"\"\"Get the most frequently quoted authors.\"\"\"\n        author_counts = {}\n        for quote in self.quotes:\n            author_counts[quote.author] = author_counts.get(quote.author, 0) + 1\n\n        return sorted(author_counts.items(), key=lambda x: x[1], reverse=True)[:top_n]\n\n    def search_text(self, search_term: str, case_sensitive: bool = False) -&gt; List[AnimalQuote]:\n        \"\"\"Simple text search within quotes.\"\"\"\n        if not case_sensitive:\n            search_term = search_term.lower()\n\n        return [\n            quote for quote in self.quotes\n            if search_term in (quote.text.lower() if not case_sensitive else quote.text)\n        ]\n</code></pre>"},{"location":"corpus/AnimalWisdom/#batch-operations","title":"Batch Operations","text":"<pre><code># Process multiple collections\ncollections = []\njsonl_files = [\n    Path(\"wisdom_quotes.jsonl\"),\n    Path(\"pet_quotes.jsonl\"), \n    Path(\"conservation_quotes.jsonl\")\n]\n\nfor file_path in jsonl_files:\n    # Load each collection\n    quotes = load_quotes_from_file(file_path)  # Custom loading function\n    wisdom = AnimalWisdom(quotes=quotes, source_file=file_path)\n    collections.append(wisdom)\n\n# Combine collections\nall_quotes = []\nfor collection in collections:\n    all_quotes.extend(collection.quotes)\n\ncombined_wisdom = AnimalWisdom(quotes=all_quotes)\nprint(f\"Combined collection: {len(combined_wisdom)} quotes from {len(collections)} sources\")\n</code></pre>"},{"location":"corpus/AnimalWisdom/#source-code","title":"\ud83d\udcda Source Code","text":"<p>The AnimalWisdom class provides a robust foundation for managing quote collections - combining data validation, rich analysis capabilities, and seamless integration with the broader RAG framework. Perfect for building intelligent content systems that need to explore and understand large collections of textual wisdom. </p>"},{"location":"corpus/AnimalWisdom/#rag_to_riches.corpus.data_models.AnimalWisdom","title":"<code>rag_to_riches.corpus.data_models.AnimalWisdom</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Collection of animal quotes loaded from the corpus.</p> <p>This model represents the complete collection of animal quotes, providing validation and convenient access methods for the data.</p> <p>Attributes:</p> Name Type Description <code>quotes</code> <code>List[AnimalQuote]</code> <p>List of AnimalQuote instances</p> <code>source_file</code> <code>Optional[Path]</code> <p>Optional path to the source JSONL file</p> Source code in <code>src/rag_to_riches/corpus/data_models.py</code> <pre><code>class AnimalWisdom(BaseModel):\n    \"\"\"Collection of animal quotes loaded from the corpus.\n\n    This model represents the complete collection of animal quotes,\n    providing validation and convenient access methods for the data.\n\n    Attributes:\n        quotes: List of AnimalQuote instances\n        source_file: Optional path to the source JSONL file\n    \"\"\"\n    model_config = ConfigDict(\n        validate_assignment=True,\n        arbitrary_types_allowed=True\n    )\n\n    quotes: List[AnimalQuote] = Field(\n        ..., \n        min_length=1, \n        description=\"Collection of animal quotes\"\n    )\n    source_file: Optional[Path] = Field(\n        default=None,\n        description=\"Path to the source JSONL file\"\n    )\n\n    @field_validator('quotes')\n    @classmethod\n    def validate_quotes_not_empty(cls, v: List[AnimalQuote]) -&gt; List[AnimalQuote]:\n        \"\"\"Ensure quotes list is not empty.\"\"\"\n        if not v:\n            raise ValueError(\"Quotes collection cannot be empty\")\n        return v\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the number of quotes in the collection.\"\"\"\n        return len(self.quotes)\n\n    def get_categories(self) -&gt; List[str]:\n        \"\"\"Get unique categories from all quotes.\n\n        Returns:\n            Sorted list of unique category names.\n        \"\"\"\n        categories = {quote.category for quote in self.quotes}\n        return sorted(categories)\n\n    def get_authors(self) -&gt; List[str]:\n        \"\"\"Get unique authors from all quotes.\n\n        Returns:\n            Sorted list of unique author names.\n        \"\"\"\n        authors = {quote.author for quote in self.quotes}\n        return sorted(authors)\n\n    def filter_by_category(self, category: str) -&gt; List[AnimalQuote]:\n        \"\"\"Filter quotes by category.\n\n        Args:\n            category: Category name to filter by.\n\n        Returns:\n            List of quotes matching the category.\n        \"\"\"\n        return [quote for quote in self.quotes if quote.category == category]\n\n    def filter_by_author(self, author: str) -&gt; List[AnimalQuote]:\n        \"\"\"Filter quotes by author.\n\n        Args:\n            author: Author name to filter by.\n\n        Returns:\n            List of quotes by the specified author.\n        \"\"\"\n        return [quote for quote in self.quotes if quote.author == author]\n</code></pre>"},{"location":"corpus/AnimalWisdom/#rag_to_riches.corpus.data_models.AnimalWisdom.__len__","title":"<code>__len__()</code>","text":"<p>Return the number of quotes in the collection.</p> Source code in <code>src/rag_to_riches/corpus/data_models.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of quotes in the collection.\"\"\"\n    return len(self.quotes)\n</code></pre>"},{"location":"corpus/AnimalWisdom/#rag_to_riches.corpus.data_models.AnimalWisdom.filter_by_author","title":"<code>filter_by_author(author)</code>","text":"<p>Filter quotes by author.</p> <p>Parameters:</p> Name Type Description Default <code>author</code> <code>str</code> <p>Author name to filter by.</p> required <p>Returns:</p> Type Description <code>List[AnimalQuote]</code> <p>List of quotes by the specified author.</p> Source code in <code>src/rag_to_riches/corpus/data_models.py</code> <pre><code>def filter_by_author(self, author: str) -&gt; List[AnimalQuote]:\n    \"\"\"Filter quotes by author.\n\n    Args:\n        author: Author name to filter by.\n\n    Returns:\n        List of quotes by the specified author.\n    \"\"\"\n    return [quote for quote in self.quotes if quote.author == author]\n</code></pre>"},{"location":"corpus/AnimalWisdom/#rag_to_riches.corpus.data_models.AnimalWisdom.filter_by_category","title":"<code>filter_by_category(category)</code>","text":"<p>Filter quotes by category.</p> <p>Parameters:</p> Name Type Description Default <code>category</code> <code>str</code> <p>Category name to filter by.</p> required <p>Returns:</p> Type Description <code>List[AnimalQuote]</code> <p>List of quotes matching the category.</p> Source code in <code>src/rag_to_riches/corpus/data_models.py</code> <pre><code>def filter_by_category(self, category: str) -&gt; List[AnimalQuote]:\n    \"\"\"Filter quotes by category.\n\n    Args:\n        category: Category name to filter by.\n\n    Returns:\n        List of quotes matching the category.\n    \"\"\"\n    return [quote for quote in self.quotes if quote.category == category]\n</code></pre>"},{"location":"corpus/AnimalWisdom/#rag_to_riches.corpus.data_models.AnimalWisdom.get_authors","title":"<code>get_authors()</code>","text":"<p>Get unique authors from all quotes.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>Sorted list of unique author names.</p> Source code in <code>src/rag_to_riches/corpus/data_models.py</code> <pre><code>def get_authors(self) -&gt; List[str]:\n    \"\"\"Get unique authors from all quotes.\n\n    Returns:\n        Sorted list of unique author names.\n    \"\"\"\n    authors = {quote.author for quote in self.quotes}\n    return sorted(authors)\n</code></pre>"},{"location":"corpus/AnimalWisdom/#rag_to_riches.corpus.data_models.AnimalWisdom.get_categories","title":"<code>get_categories()</code>","text":"<p>Get unique categories from all quotes.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>Sorted list of unique category names.</p> Source code in <code>src/rag_to_riches/corpus/data_models.py</code> <pre><code>def get_categories(self) -&gt; List[str]:\n    \"\"\"Get unique categories from all quotes.\n\n    Returns:\n        Sorted list of unique category names.\n    \"\"\"\n    categories = {quote.category for quote in self.quotes}\n    return sorted(categories)\n</code></pre>"},{"location":"corpus/AnimalWisdom/#rag_to_riches.corpus.data_models.AnimalWisdom.validate_quotes_not_empty","title":"<code>validate_quotes_not_empty(v)</code>  <code>classmethod</code>","text":"<p>Ensure quotes list is not empty.</p> Source code in <code>src/rag_to_riches/corpus/data_models.py</code> <pre><code>@field_validator('quotes')\n@classmethod\ndef validate_quotes_not_empty(cls, v: List[AnimalQuote]) -&gt; List[AnimalQuote]:\n    \"\"\"Ensure quotes list is not empty.\"\"\"\n    if not v:\n        raise ValueError(\"Quotes collection cannot be empty\")\n    return v\n</code></pre>"},{"location":"corpus/Animals/","title":"Animals Class: Complete RAG System","text":""},{"location":"corpus/Animals/#class-overview","title":"\ud83c\udfaf Class Overview","text":"<p>The <code>Animals</code> class is the flagship component of the RAG to Riches framework - a powerful, intelligent corpus loader that combines semantic search, vector databases, and AI-powered question answering into a single, easy-to-use interface.</p> <p>This class provides a complete solution for working with collections of animal quotes, offering semantic search, AI-powered question answering, and beautiful result display. Perfect for educational applications, research, or building chatbots that need access to animal wisdom and quotes.</p>"},{"location":"corpus/Animals/#class-definition","title":"\ud83d\udccb Class Definition","text":"<pre><code>class Animals:\n    \"\"\"A powerful, intelligent corpus loader for animal quotes with RAG capabilities.\"\"\"\n</code></pre>"},{"location":"corpus/Animals/#class-architecture","title":"\ud83c\udfd7\ufe0f Class Architecture","text":"classDiagram     class Animals {         +SimpleTextEmbedder embedder         +str collection_name         +Optional[AnimalWisdom] wisdom         +SemanticSearch semantic_search         +str ANIMALS_RAG_SYSTEM_PROMPT         +Path SYSTEM_PROMPT_PATH          +__init__(vector_db, embedder, collection_name)         +load_from_jsonl(jsonl_path) AnimalWisdom         +index_all_quotes() List[str]         +search(query, limit, filters) List[ScoredPoint]         +ask_llm(query, filters, model) AnimalWisdomResponse         +rag(query, filters, response_type) Dict[str, Any]         +display_search_results(results, description)         +get_collection_stats() Dict[str, Any]         +consistency_check() bool         +recreate_collection() None          -_load_system_prompt() str         -_apply_metadata_filters() List[ScoredPoint]         -_display_search_results_simple() None         -_display_llm_response_simple() None     }      class AnimalWisdomResponse {         +str answer         +List[str] key_insights         +List[str] recommended_quotes         +List[str] follow_up_questions     }      Animals --&gt; SemanticSearch : uses     Animals --&gt; EmbeddedVectorDB : uses     Animals --&gt; AnimalWisdom : manages     Animals --&gt; AnimalWisdomResponse : creates"},{"location":"corpus/Animals/#key-features","title":"\ud83d\ude80 Key Features","text":"<ul> <li>Complete RAG Pipeline: Search + LLM response in a single method call</li> <li>Semantic Search: Advanced sentence transformer embeddings for meaning-based retrieval</li> <li>AI Integration: OpenAI GPT models with structured response generation</li> <li>Rich Display: Beautiful formatted output with Rich library</li> <li>Batch Operations: Efficient handling of large quote collections</li> <li>Metadata Filtering: Filter by author, category, or similarity score</li> <li>Health Monitoring: Collection statistics and consistency checks</li> </ul>"},{"location":"corpus/Animals/#constructor","title":"\ud83d\udcd6 Constructor","text":""},{"location":"corpus/Animals/#__init__vector_db-embeddernone-collection_nameanimals","title":"<code>__init__(vector_db, embedder=None, collection_name=\"animals\")</code>","text":"<p>Initialize your Animals quote corpus with intelligent search capabilities.</p>"},{"location":"corpus/Animals/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>vector_db</code> <code>EmbeddedVectorDB</code> Required Vector database instance for storage <code>embedder</code> <code>SimpleTextEmbedder</code> <code>None</code> Text embedding model (uses default if None) <code>collection_name</code> <code>str</code> <code>\"animals\"</code> Unique name for your quote collection"},{"location":"corpus/Animals/#example-usage","title":"Example Usage","text":"<pre><code>from rag_to_riches.vectordb.embedded_vectordb import EmbeddedVectorDB\nfrom rag_to_riches.corpus.animals import Animals\n\n# Basic setup with default embedder\nvector_db = EmbeddedVectorDB()\nanimals = Animals(vector_db)\n\n# Custom setup with specific collection\nanimals = Animals(\n    vector_db=vector_db,\n    collection_name=\"philosophical_animal_quotes\"\n)\n\n# Advanced setup with custom embedder\ncustom_embedder = SimpleTextEmbedder(model_name=\"custom-model\")\nanimals = Animals(vector_db, embedder=custom_embedder)\n</code></pre>"},{"location":"corpus/Animals/#design-by-contract","title":"Design by Contract","text":"<ul> <li>Preconditions: </li> <li><code>vector_db</code> must be an <code>EmbeddedVectorDB</code> instance</li> <li><code>embedder</code> must be <code>None</code> or a <code>SimpleTextEmbedder</code> instance</li> <li>Postconditions: All required attributes are initialized</li> </ul>"},{"location":"corpus/Animals/#data-loading-methods","title":"\ud83d\udce5 Data Loading Methods","text":""},{"location":"corpus/Animals/#load_from_jsonljsonl_path","title":"<code>load_from_jsonl(jsonl_path)</code>","text":"<p>Load and validate animal quotes from a JSONL (JSON Lines) file.</p>"},{"location":"corpus/Animals/#parameters_1","title":"Parameters","text":"Parameter Type Description <code>jsonl_path</code> <code>Path</code> Path to JSONL file containing animal quotes"},{"location":"corpus/Animals/#returns","title":"Returns","text":"<p><code>AnimalWisdom</code> - Validated collection of quotes ready for indexing</p>"},{"location":"corpus/Animals/#expected-jsonl-format","title":"Expected JSONL Format","text":"<pre><code>{\"text\": \"Dogs are not our whole life, but they make our lives whole.\", \"author\": \"Roger Caras\", \"category\": \"Pets and Companionship\"}\n{\"text\": \"The greatness of a nation can be judged by the way its animals are treated.\", \"author\": \"Mahatma Gandhi\", \"category\": \"Ethics and Compassion\"}\n</code></pre>"},{"location":"corpus/Animals/#example-usage_1","title":"Example Usage","text":"<pre><code>from pathlib import Path\n\n# Load quotes from file\nquotes_path = Path(\"data/animal_wisdom.jsonl\")\nwisdom = animals.load_from_jsonl(quotes_path)\n\nprint(f\"Loaded {len(wisdom)} quotes\")\nprint(f\"Categories: {wisdom.get_categories()}\")\nprint(f\"Authors: {wisdom.get_authors()}\")\n\n# Access individual quotes\nfor quote in wisdom.quotes[:3]:\n    print(f'\"{quote.text}\" - {quote.author}')\n</code></pre>"},{"location":"corpus/Animals/#error-handling","title":"Error Handling","text":"<ul> <li><code>FileNotFoundError</code>: When the specified file doesn't exist</li> <li><code>InvalidPointsError</code>: When no valid quotes are found in the file</li> </ul>"},{"location":"corpus/Animals/#index_all_quotes","title":"<code>index_all_quotes()</code>","text":"<p>Transform all loaded quotes into searchable vector embeddings.</p>"},{"location":"corpus/Animals/#returns_1","title":"Returns","text":"<p><code>List[str]</code> - List of unique point IDs for each indexed quote</p>"},{"location":"corpus/Animals/#process-flow","title":"Process Flow","text":"<ol> <li>Extracts text content from each quote</li> <li>Generates semantic embeddings using the configured model</li> <li>Stores vectors in the database with rich metadata</li> <li>Creates searchable points for instant retrieval</li> </ol>"},{"location":"corpus/Animals/#example-usage_2","title":"Example Usage","text":"<pre><code># Load quotes first\nwisdom = animals.load_from_jsonl(\"quotes.jsonl\")\n\n# Index for semantic search\npoint_ids = animals.index_all_quotes()\nprint(f\"Successfully indexed {len(point_ids)} quotes\")\n\n# Now you can search semantically\nresults = animals.search(\"loyalty and friendship\")\n</code></pre>"},{"location":"corpus/Animals/#performance-notes","title":"Performance Notes","text":"<ul> <li>Batch processing is used for efficiency with large collections</li> <li>Indexing time scales with collection size and model complexity</li> <li>Typical speed: ~100-500 quotes per second depending on hardware</li> <li>GPU acceleration automatically used if available</li> </ul>"},{"location":"corpus/Animals/#load_and_indexjsonl_path","title":"<code>load_and_index(jsonl_path)</code>","text":"<p>One-step solution: load quotes from file and make them instantly searchable.</p>"},{"location":"corpus/Animals/#parameters_2","title":"Parameters","text":"Parameter Type Description <code>jsonl_path</code> <code>Path</code> Path to JSONL file containing animal quotes"},{"location":"corpus/Animals/#returns_2","title":"Returns","text":"<p><code>Tuple[AnimalWisdom, List[str]]</code> - Loaded wisdom and point IDs</p>"},{"location":"corpus/Animals/#example-usage_3","title":"Example Usage","text":"<pre><code># Complete setup in one line\nwisdom, point_ids = animals.load_and_index(\"my_quotes.jsonl\")\n\nprint(f\"Ready to search {len(wisdom)} quotes!\")\n\n# Immediately start searching\nresults = animals.search(\"courage and bravery\")\n</code></pre>"},{"location":"corpus/Animals/#search-methods","title":"\ud83d\udd0d Search Methods","text":""},{"location":"corpus/Animals/#searchquery-limit10-score_thresholdnone-authornone-categorynone","title":"<code>search(query, limit=10, score_threshold=None, author=None, category=None)</code>","text":"<p>Find the most relevant animal quotes using intelligent semantic search.</p>"},{"location":"corpus/Animals/#parameters_3","title":"Parameters","text":"Parameter Type Default Description <code>query</code> <code>str</code> Required Search question or topic in natural language <code>limit</code> <code>int</code> <code>10</code> Maximum number of results to return <code>score_threshold</code> <code>float</code> <code>None</code> Minimum similarity score (0.0-1.0) <code>author</code> <code>str</code> <code>None</code> Filter to only include quotes by this author <code>category</code> <code>str</code> <code>None</code> Filter to only include quotes from this category"},{"location":"corpus/Animals/#returns_3","title":"Returns","text":"<p><code>List[models.ScoredPoint]</code> - Results sorted by relevance (highest scores first)</p>"},{"location":"corpus/Animals/#example-usage_4","title":"Example Usage","text":"<pre><code># Basic semantic search\nresults = animals.search(\"loyalty and friendship\")\n\n# Precise search with high threshold\nresults = animals.search(\n    \"courage in difficult times\",\n    limit=5,\n    score_threshold=0.8\n)\n\n# Search within specific author's quotes\ngandhi_quotes = animals.search(\n    \"compassion\",\n    author=\"Mahatma Gandhi\",\n    limit=3\n)\n\n# Browse by category\nwisdom_quotes = animals.search(\n    \"life lessons\",\n    category=\"Wisdom and Philosophy\"\n)\n\n# Process results\nfor result in results:\n    print(f\"Score: {result.score:.3f}\")\n    print(f\"Quote: {result.payload['content']}\")\n    print(f\"Author: {result.payload['author']}\")\n    print(\"---\")\n</code></pre>"},{"location":"corpus/Animals/#search-tips","title":"Search Tips","text":"<ul> <li>Use descriptive phrases rather than single keywords</li> <li>Try different phrasings if you don't find what you're looking for</li> <li>Lower the score_threshold to see more diverse results</li> <li>Combine filters to narrow down to specific types of quotes</li> </ul>"},{"location":"corpus/Animals/#design-by-contract_1","title":"Design by Contract","text":"<ul> <li>Preconditions:</li> <li><code>query</code> must be a non-empty string</li> <li><code>limit</code> must be a positive integer</li> <li><code>author</code> and <code>category</code> filters must be None or non-empty strings</li> <li>Postconditions: Returns a list of ScoredPoint objects</li> </ul>"},{"location":"corpus/Animals/#ai-integration-methods","title":"\ud83e\udd16 AI Integration Methods","text":""},{"location":"corpus/Animals/#ask_llmuser_query-limit5-score_thresholdnone-authornone-categorynone-modelgpt-4o","title":"<code>ask_llm(user_query, limit=5, score_threshold=None, author=None, category=None, model=\"gpt-4o\")</code>","text":"<p>Ask AI thoughtful questions about animals and get structured, insightful answers.</p>"},{"location":"corpus/Animals/#parameters_4","title":"Parameters","text":"Parameter Type Default Description <code>user_query</code> <code>str</code> Required Your question about animals <code>limit</code> <code>int</code> <code>5</code> Number of relevant quotes to provide as context <code>score_threshold</code> <code>float</code> <code>None</code> Only use quotes above this similarity score <code>author</code> <code>str</code> <code>None</code> Focus on quotes from this specific author <code>category</code> <code>str</code> <code>None</code> Limit context to quotes from this category <code>model</code> <code>str</code> <code>\"gpt-4o\"</code> OpenAI model to use"},{"location":"corpus/Animals/#returns_4","title":"Returns","text":"<p><code>AnimalWisdomResponse</code> - Structured response containing: - <code>answer</code>: Comprehensive, thoughtful response - <code>key_insights</code>: 2-5 main themes or takeaways - <code>recommended_quotes</code>: Most relevant quotes with attribution - <code>follow_up_questions</code>: Suggested related questions</p>"},{"location":"corpus/Animals/#example-usage_5","title":"Example Usage","text":"<pre><code># Ask a philosophical question\nresponse = animals.ask_llm(\n    \"What can animals teach us about resilience and survival?\"\n)\n\n# Display the structured response\nanimals.display_llm_response(response, \"resilience question\")\n\n# Access specific parts\nprint(\"Main Answer:\")\nprint(response.answer)\n\nprint(\"\\nKey Insights:\")\nfor insight in response.key_insights:\n    print(f\"- {insight}\")\n\n# Ask follow-up questions\nfor question in response.follow_up_questions:\n    print(f\"Next: {question}\")\n</code></pre>"},{"location":"corpus/Animals/#question-ideas","title":"Question Ideas","text":"<ul> <li>\"How do animals demonstrate unconditional love?\"</li> <li>\"What survival strategies can humans learn from animals?\"</li> <li>\"How do different cultures view human-animal relationships?\"</li> <li>\"What role do animals play in teaching empathy?\"</li> </ul>"},{"location":"corpus/Animals/#ask_llm_simpleuser_query-limit3-modelgpt-4o","title":"<code>ask_llm_simple(user_query, limit=3, model=\"gpt-4o\")</code>","text":"<p>Get a simple text response from the LLM about animals.</p>"},{"location":"corpus/Animals/#parameters_5","title":"Parameters","text":"Parameter Type Default Description <code>user_query</code> <code>str</code> Required Your question about animals <code>limit</code> <code>int</code> <code>3</code> Maximum number of search results to include <code>model</code> <code>str</code> <code>\"gpt-4o\"</code> OpenAI model to use"},{"location":"corpus/Animals/#returns_5","title":"Returns","text":"<p><code>str</code> - Simple text response from the LLM</p>"},{"location":"corpus/Animals/#raguser_query-limit5-score_thresholdnone-authornone-categorynone-modelgpt-4o-response_typestructured","title":"<code>rag(user_query, limit=5, score_threshold=None, author=None, category=None, model=\"gpt-4o\", response_type=\"structured\")</code>","text":"<p>\ud83d\ude80 Complete AI-powered question answering in one powerful method call.</p> <p>This is your one-stop solution for getting intelligent answers about animals. It automatically searches your quote collection, finds the most relevant content, and generates comprehensive AI responses with full transparency into the process.</p>"},{"location":"corpus/Animals/#the-complete-rag-pipeline","title":"The Complete RAG Pipeline","text":"<ol> <li>\ud83d\udd0d Semantic search finds relevant quotes from your collection</li> <li>\ud83d\udcdd Context generation creates optimized prompts for the AI</li> <li>\ud83e\udd16 AI reasoning produces thoughtful, grounded responses</li> <li>\ud83d\udcca Full transparency with all intermediate results returned</li> </ol>"},{"location":"corpus/Animals/#parameters_6","title":"Parameters","text":"Parameter Type Default Description <code>user_query</code> <code>str</code> Required Your question about animals <code>limit</code> <code>int</code> <code>5</code> Number of quotes to use as context <code>score_threshold</code> <code>float</code> <code>None</code> Minimum relevance score for quotes <code>author</code> <code>str</code> <code>None</code> Limit context to quotes from this author <code>category</code> <code>str</code> <code>None</code> Focus on quotes from this category <code>model</code> <code>str</code> <code>\"gpt-4o\"</code> OpenAI model for AI responses <code>response_type</code> <code>str</code> <code>\"structured\"</code> \"structured\" or \"simple\" response format"},{"location":"corpus/Animals/#returns_6","title":"Returns","text":"<p><code>Dict[str, Any]</code> - Complete results dictionary containing: - <code>llm_response</code>: AI answer (structured object or simple string) - <code>search_results</code>: List of relevant quotes found (with scores) - <code>rag_context</code>: Full prompt sent to AI (for debugging/transparency) - <code>query_info</code>: Metadata about the query and processing parameters</p>"},{"location":"corpus/Animals/#example-usage_6","title":"Example Usage","text":"<pre><code># Complete RAG in one call\nresult = animals.rag(\n    \"What do animals teach us about unconditional love?\",\n    limit=7,\n    score_threshold=0.6,\n    response_type=\"structured\"\n)\n\n# Access the AI response\nai_answer = result[\"llm_response\"]\nprint(\"AI Answer:\", ai_answer.answer)\n\n# See what quotes were used\nquotes_used = result[\"search_results\"]\nprint(f\"Based on {len(quotes_used)} relevant quotes\")\n\n# Inspect the full context (for debugging)\nfull_prompt = result[\"rag_context\"]\n\n# Get query metadata\ninfo = result[\"query_info\"]\nprint(f\"Model: {info['model']}, Results: {info['results_count']}\")\n</code></pre>"},{"location":"corpus/Animals/#advanced-usage","title":"Advanced Usage","text":"<pre><code># Domain-specific question\nethics_result = animals.rag(\n    \"How should humans treat wild animals?\",\n    category=\"Ethics and Compassion\",\n    limit=10\n)\n\n# Author-focused inquiry\ngandhi_result = animals.rag(\n    \"What did Gandhi believe about animals?\",\n    author=\"Mahatma Gandhi\",\n    response_type=\"simple\"\n)\n</code></pre>"},{"location":"corpus/Animals/#display-methods","title":"\ud83c\udfa8 Display Methods","text":""},{"location":"corpus/Animals/#display_search_resultsresults-search_description-max_text_length120","title":"<code>display_search_results(results, search_description, max_text_length=120)</code>","text":"<p>Present search results in a beautiful, easy-to-read table format.</p>"},{"location":"corpus/Animals/#parameters_7","title":"Parameters","text":"Parameter Type Default Description <code>results</code> <code>List[models.ScoredPoint]</code> Required Search results to display <code>search_description</code> <code>str</code> Required Descriptive title for the search <code>max_text_length</code> <code>int</code> <code>120</code> Maximum characters before truncation"},{"location":"corpus/Animals/#features","title":"Features","text":"<ul> <li>\ud83c\udfa8 Color-coded columns for easy scanning</li> <li>\ud83d\udcca Relevance scores prominently displayed</li> <li>\u2702\ufe0f Smart text truncation to maintain readability</li> <li>\ud83d\udcf1 Responsive layout that works in various terminal sizes</li> <li>\ud83d\udeab Graceful handling of empty results</li> </ul>"},{"location":"corpus/Animals/#example-usage_7","title":"Example Usage","text":"<pre><code># Search and display results beautifully\nresults = animals.search(\"courage and bravery\", limit=5)\nanimals.display_search_results(\n    results, \n    \"Quotes about Courage and Bravery\",\n    max_text_length=100\n)\n</code></pre>"},{"location":"corpus/Animals/#display_llm_responseresponse-user_query","title":"<code>display_llm_response(response, user_query)</code>","text":"<p>Display the LLM response in a formatted way using Rich.</p>"},{"location":"corpus/Animals/#parameters_8","title":"Parameters","text":"Parameter Type Description <code>response</code> <code>AnimalWisdomResponse</code> Structured response from the LLM <code>user_query</code> <code>str</code> Original user query"},{"location":"corpus/Animals/#features_1","title":"Features","text":"<ul> <li>\ud83e\udd16 Main answer in highlighted panel</li> <li>\ud83d\udca1 Key insights in organized list</li> <li>\ud83d\udcda Recommended quotes with attribution</li> <li>\ud83d\udd0d Follow-up questions for continued exploration</li> </ul>"},{"location":"corpus/Animals/#management-methods","title":"\ud83d\udcca Management Methods","text":""},{"location":"corpus/Animals/#get_collection_stats","title":"<code>get_collection_stats()</code>","text":"<p>Get comprehensive statistics and insights about your quote collection.</p>"},{"location":"corpus/Animals/#returns_7","title":"Returns","text":"<p><code>Dict[str, Any]</code> - Dictionary containing detailed statistics: - <code>collection_name</code>: Name of your quote collection - <code>collection_exists</code>: Whether the database collection exists - <code>point_count</code>: Total quotes stored in the database - <code>loaded_quotes</code>: Number of quotes currently loaded in memory - <code>categories</code>: List of all unique quote categories (sorted) - <code>authors</code>: List of all unique authors (sorted)</p>"},{"location":"corpus/Animals/#example-usage_8","title":"Example Usage","text":"<pre><code>stats = animals.get_collection_stats()\n\nprint(f\"Collection: {stats['collection_name']}\")\nprint(f\"Total quotes in database: {stats['point_count']}\")\nprint(f\"Quotes loaded in memory: {stats['loaded_quotes']}\")\nprint(f\"Categories ({len(stats['categories'])}): {stats['categories']}\")\nprint(f\"Authors ({len(stats['authors'])}): {stats['authors'][:5]}...\")\n\n# Check if ready for search\nif stats['collection_exists'] and stats['point_count'] &gt; 0:\n    print(\"\u2705 Ready for semantic search!\")\nelse:\n    print(\"\u274c Need to load and index quotes first\")\n</code></pre>"},{"location":"corpus/Animals/#consistency_check","title":"<code>consistency_check()</code>","text":"<p>Verify that your database collection is properly configured and ready to use.</p>"},{"location":"corpus/Animals/#returns_8","title":"Returns","text":"<p><code>bool</code> - True if everything is properly configured, False if issues detected</p>"},{"location":"corpus/Animals/#whats-checked","title":"What's Checked","text":"<ul> <li>Vector dimensions match between collection and embedder</li> <li>Distance metric compatibility</li> <li>Collection existence and accessibility</li> <li>Basic connectivity to the vector database</li> </ul>"},{"location":"corpus/Animals/#example-usage_9","title":"Example Usage","text":"<pre><code>if animals.consistency_check():\n    print(\"\u2705 Collection is healthy and ready!\")\n    results = animals.search(\"your query here\")\nelse:\n    print(\"\u274c Configuration issues detected\")\n    print(\"Consider recreating the collection:\")\n    animals.recreate_collection()\n</code></pre>"},{"location":"corpus/Animals/#recreate_collection","title":"<code>recreate_collection()</code>","text":"<p>Completely reset your quote collection with a fresh, empty database.</p>"},{"location":"corpus/Animals/#process","title":"Process","text":"<ol> <li>Safely deletes the existing collection if it exists</li> <li>Creates a new empty collection with optimal settings</li> <li>Clears all loaded quote data from memory</li> <li>Prepares the system for fresh data loading</li> </ol>"},{"location":"corpus/Animals/#example-usage_10","title":"Example Usage","text":"<pre><code># Reset everything and start fresh\nanimals.recreate_collection()\n\n# Now load new data\nnew_wisdom = animals.load_from_jsonl(\"updated_quotes.jsonl\")\nanimals.index_all_quotes()\n</code></pre>"},{"location":"corpus/Animals/#warning","title":"\u26a0\ufe0f Warning","text":"<p>This operation is irreversible! All existing quotes in the collection will be permanently deleted. Make sure you have backups of important data before calling this method.</p>"},{"location":"corpus/Animals/#rag-helper-methods","title":"\ud83d\udd27 RAG Helper Methods","text":""},{"location":"corpus/Animals/#format_search_results_for_ragsearch_results-max_results5","title":"<code>format_search_results_for_rag(search_results, max_results=5)</code>","text":"<p>Format search results for RAG system prompt.</p>"},{"location":"corpus/Animals/#parameters_9","title":"Parameters","text":"Parameter Type Default Description <code>search_results</code> <code>List[models.ScoredPoint]</code> Required Search results to format <code>max_results</code> <code>int</code> <code>5</code> Maximum number of results to include"},{"location":"corpus/Animals/#returns_9","title":"Returns","text":"<p><code>str</code> - Formatted string for RAG context</p>"},{"location":"corpus/Animals/#create_rag_contextuser_query-search_results-system_promptnone","title":"<code>create_rag_context(user_query, search_results, system_prompt=None)</code>","text":"<p>Create a complete RAG context with system prompt and formatted results.</p>"},{"location":"corpus/Animals/#parameters_10","title":"Parameters","text":"Parameter Type Default Description <code>user_query</code> <code>str</code> Required The user's question <code>search_results</code> <code>List[models.ScoredPoint]</code> Required Search results <code>system_prompt</code> <code>str</code> <code>None</code> System prompt (uses default if None)"},{"location":"corpus/Animals/#returns_10","title":"Returns","text":"<p><code>str</code> - Complete RAG context string</p>"},{"location":"corpus/Animals/#search_and_create_rag_contextuser_query-limit5-kwargs","title":"<code>search_and_create_rag_context(user_query, limit=5, **kwargs)</code>","text":"<p>Search for quotes and create RAG context in one convenient method.</p>"},{"location":"corpus/Animals/#parameters_11","title":"Parameters","text":"<p>Combines parameters from <code>search()</code> and <code>create_rag_context()</code> methods.</p>"},{"location":"corpus/Animals/#returns_11","title":"Returns","text":"<p><code>str</code> - Complete RAG context string</p>"},{"location":"corpus/Animals/#private-methods","title":"\ud83d\udd12 Private Methods","text":""},{"location":"corpus/Animals/#_load_system_prompt","title":"<code>_load_system_prompt()</code>","text":"<p>Load the AI system prompt from external configuration file.</p>"},{"location":"corpus/Animals/#returns_12","title":"Returns","text":"<p><code>str</code> - The system prompt text for RAG operations, or empty string if unavailable</p>"},{"location":"corpus/Animals/#_apply_metadata_filtersresults-author_filternone-category_filternone","title":"<code>_apply_metadata_filters(results, author_filter=None, category_filter=None)</code>","text":"<p>Apply author and/or category filters to search results.</p>"},{"location":"corpus/Animals/#parameters_12","title":"Parameters","text":"Parameter Type Default Description <code>results</code> <code>List[models.ScoredPoint]</code> Required List of scored points from vector search <code>author_filter</code> <code>str</code> <code>None</code> Optional author name to filter by <code>category_filter</code> <code>str</code> <code>None</code> Optional category name to filter by"},{"location":"corpus/Animals/#returns_13","title":"Returns","text":"<p><code>List[models.ScoredPoint]</code> - Filtered list of scored points</p>"},{"location":"corpus/Animals/#_display_search_results_simpleresults-search_description-max_text_length","title":"<code>_display_search_results_simple(results, search_description, max_text_length)</code>","text":"<p>Simple fallback display method when Rich library is not available.</p>"},{"location":"corpus/Animals/#_display_llm_response_simpleresponse-user_query","title":"<code>_display_llm_response_simple(response, user_query)</code>","text":"<p>Simple fallback display method for LLM responses when Rich is not available.</p>"},{"location":"corpus/Animals/#class-attributes","title":"\ud83d\udcdd Class Attributes","text":""},{"location":"corpus/Animals/#system_prompt_path","title":"<code>SYSTEM_PROMPT_PATH</code>","text":"<p><code>Path</code> - Path to the external system prompt file for RAG operations.</p> <p>Default: <code>Path(__file__).parent / \"prompts\" / \"animals_system_prompt.md\"</code></p>"},{"location":"corpus/Animals/#animals_rag_system_prompt","title":"<code>ANIMALS_RAG_SYSTEM_PROMPT</code>","text":"<p><code>str</code> - Comprehensive RAG system prompt for Animals class (loaded at init time).</p>"},{"location":"corpus/Animals/#simple_animals_prompt","title":"<code>SIMPLE_ANIMALS_PROMPT</code>","text":"<p><code>str</code> - Alternative shorter version for quick use:</p> <pre><code>SIMPLE_ANIMALS_PROMPT = \"\"\"\nYou are an expert on animal wisdom and quotes. Use the provided search results \nto answer questions about animals, human-animal relationships, and life lessons. \nAlways attribute quotes to their authors and explain their relevance to the user's question. \nBe conversational, thoughtful, and helpful in connecting users with the wisdom \nfound in animal quotes throughout history.\n\"\"\"\n</code></pre>"},{"location":"corpus/Animals/#use-cases","title":"\ud83c\udfaf Use Cases","text":"<ul> <li>Educational Chatbots: AI tutors with grounded animal knowledge</li> <li>Research Tools: Explore themes in animal-related literature</li> <li>Content Generation: Source-backed articles and presentations</li> <li>Interactive Learning: Question-answer systems for students</li> <li>Philosophical Exploration: Deep dives into animal wisdom and ethics</li> </ul>"},{"location":"corpus/Animals/#dependencies","title":"\ud83d\udd17 Dependencies","text":"<p>The Animals class integrates with several other framework components:</p> <ul> <li><code>SemanticSearch</code>: Core search functionality</li> <li><code>EmbeddedVectorDB</code>: Vector storage and retrieval</li> <li><code>SimpleTextEmbedder</code>: Text embedding generation</li> <li><code>AnimalQuote</code> and <code>AnimalWisdom</code>: Data models</li> <li>OpenAI: LLM integration via instructor</li> <li>Rich: Beautiful terminal output</li> <li>Loguru: Comprehensive logging</li> </ul>"},{"location":"corpus/Animals/#source-code","title":"\ud83d\udcda Source Code","text":"<p>The Animals class represents the culmination of modern RAG system design - combining semantic search, AI reasoning, and beautiful presentation into a single, powerful interface. Perfect for building production-ready applications that need intelligent, grounded responses about animal wisdom and knowledge. </p>"},{"location":"corpus/Animals/#rag_to_riches.corpus.animals.Animals","title":"<code>rag_to_riches.corpus.animals.Animals</code>","text":"<p>A powerful, intelligent corpus loader for animal quotes with RAG capabilities.</p> <p>This class provides a complete solution for working with collections of animal quotes, offering semantic search, AI-powered question answering, and beautiful result display. Perfect for educational applications, research, or building chatbots that need access to animal wisdom and quotes.</p> Key Features <ul> <li>Load quotes from JSONL files with automatic validation</li> <li>Semantic search using state-of-the-art embeddings</li> <li>Filter by author, category, or similarity score</li> <li>AI-powered question answering with GPT models</li> <li>Beautiful formatted output with Rich library</li> <li>Complete RAG (Retrieval-Augmented Generation) pipeline</li> <li>Batch operations for efficiency</li> </ul> Typical Workflow <ol> <li>Initialize with a vector database</li> <li>Load quotes from a JSONL file</li> <li>Index quotes for semantic search</li> <li>Search for relevant quotes</li> <li>Ask AI questions about the quotes</li> </ol> Example <pre><code>from pathlib import Path\nfrom rag_to_riches.vectordb.embedded_vectordb import EmbeddedVectorDB\nfrom rag_to_riches.corpus.animals import Animals\n\n# Initialize\nvector_db = EmbeddedVectorDB()\nanimals = Animals(vector_db, collection_name=\"my_quotes\")\n\n# Load and index quotes\nquotes_file = Path(\"data/animal_quotes.jsonl\")\nanimals.load_and_index(quotes_file)\n\n# Search for quotes\nresults = animals.search(\"wisdom about dogs\", limit=5)\n\n# Ask AI a question\nresponse = animals.ask_llm(\"What do animals teach us about loyalty?\")\nanimals.display_llm_response(response, \"loyalty question\")\n</code></pre> <p>Attributes:</p> Name Type Description <code>embedder</code> <p>Text embedding model for vector representations</p> <code>collection_name</code> <p>Name of the Qdrant collection storing the quotes</p> <code>wisdom</code> <code>Optional[AnimalWisdom]</code> <p>Loaded collection of animal quotes (None until loaded)</p> <code>semantic_search</code> <p>Underlying search engine for similarity queries</p> Source code in <code>src/rag_to_riches/corpus/animals.py</code> <pre><code>class Animals:\n    \"\"\"A powerful, intelligent corpus loader for animal quotes with RAG capabilities.\n\n    This class provides a complete solution for working with collections of animal quotes,\n    offering semantic search, AI-powered question answering, and beautiful result display.\n    Perfect for educational applications, research, or building chatbots that need access\n    to animal wisdom and quotes.\n\n    Key Features:\n        - Load quotes from JSONL files with automatic validation\n        - Semantic search using state-of-the-art embeddings\n        - Filter by author, category, or similarity score\n        - AI-powered question answering with GPT models\n        - Beautiful formatted output with Rich library\n        - Complete RAG (Retrieval-Augmented Generation) pipeline\n        - Batch operations for efficiency\n\n    Typical Workflow:\n        1. Initialize with a vector database\n        2. Load quotes from a JSONL file\n        3. Index quotes for semantic search\n        4. Search for relevant quotes\n        5. Ask AI questions about the quotes\n\n    Example:\n        ```python\n        from pathlib import Path\n        from rag_to_riches.vectordb.embedded_vectordb import EmbeddedVectorDB\n        from rag_to_riches.corpus.animals import Animals\n\n        # Initialize\n        vector_db = EmbeddedVectorDB()\n        animals = Animals(vector_db, collection_name=\"my_quotes\")\n\n        # Load and index quotes\n        quotes_file = Path(\"data/animal_quotes.jsonl\")\n        animals.load_and_index(quotes_file)\n\n        # Search for quotes\n        results = animals.search(\"wisdom about dogs\", limit=5)\n\n        # Ask AI a question\n        response = animals.ask_llm(\"What do animals teach us about loyalty?\")\n        animals.display_llm_response(response, \"loyalty question\")\n        ```\n\n    Attributes:\n        embedder: Text embedding model for vector representations\n        collection_name: Name of the Qdrant collection storing the quotes\n        wisdom: Loaded collection of animal quotes (None until loaded)\n        semantic_search: Underlying search engine for similarity queries\n    \"\"\"\n\n    # ----------------------------------------------------------------------------------------\n    #  Constructor\n    # ----------------------------------------------------------------------------------------\n    @require(lambda vector_db: isinstance(vector_db, EmbeddedVectorDB),\n             \"Vector DB must be an EmbeddedVectorDB instance\")\n    @require(lambda embedder: embedder is None or isinstance(embedder, SimpleTextEmbedder),\n             \"Embedder must be None or a SimpleTextEmbedder instance\")\n    def __init__(self, vector_db: EmbeddedVectorDB, \n                 embedder: Optional[SimpleTextEmbedder] = None,\n                 collection_name: str = \"animals\") -&gt; None:\n        \"\"\"Initialize your Animals quote corpus with intelligent search capabilities.\n\n        Sets up the complete infrastructure for loading, indexing, and searching animal\n        quotes. The system uses advanced sentence transformers for semantic understanding\n        and can work with any size collection efficiently.\n\n        Args:\n            vector_db: Your vector database instance where quotes will be stored.\n                This handles all the vector storage and retrieval operations.\n            embedder: Optional text embedding model. If None, uses the default\n                'sentence-transformers/all-MiniLM-L6-v2' model which provides\n                excellent semantic understanding for quotes and wisdom.\n            collection_name: Unique name for your quote collection. Use descriptive\n                names like \"animal_wisdom\", \"pet_quotes\", or \"nature_sayings\" to\n                organize multiple collections.\n\n        Example:\n            ```python\n            # Basic setup with default embedder\n            animals = Animals(vector_db)\n\n            # Custom setup with specific collection\n            animals = Animals(\n                vector_db=my_db,\n                collection_name=\"philosophical_animal_quotes\"\n            )\n\n            # Advanced setup with custom embedder\n            custom_embedder = SimpleTextEmbedder(model_name=\"custom-model\")\n            animals = Animals(vector_db, embedder=custom_embedder)\n            ```\n\n        Note:\n            The constructor automatically loads the RAG system prompt for AI interactions.\n            If the prompt file is missing, a warning is logged but the system continues\n            to work with reduced AI capabilities.\n        \"\"\"\n        self.embedder = embedder or SimpleTextEmbedder()\n        self.collection_name = collection_name\n        self.wisdom: Optional[AnimalWisdom] = None\n\n        # Initialize the underlying semantic search engine\n        self.semantic_search = SemanticSearch(\n            embedder=self.embedder,\n            vector_db=vector_db,\n            collection_name=collection_name\n        )\n\n        logger.info(f\"Initialized Animals corpus loader for collection '{collection_name}'\")\n        if not Animals.ANIMALS_RAG_SYSTEM_PROMPT:\n            Animals.ANIMALS_RAG_SYSTEM_PROMPT = self._load_system_prompt()\n\n    def _load_system_prompt(self) -&gt; str:\n        \"\"\"Load the AI system prompt from external configuration file.\n\n        Returns:\n            The system prompt text for RAG operations, or empty string if unavailable.\n        \"\"\"\n        try:\n            return Animals.SYSTEM_PROMPT_PATH.read_text(encoding=\"utf-8\")\n        except Exception as e:\n            logger.warning(f\"Could not load system prompt: {e}\")\n            return \"\"\n\n\n    # ----------------------------------------------------------------------------------------\n    #  Load from JSONL\n    # ----------------------------------------------------------------------------------------\n    @require(lambda jsonl_path: isinstance(jsonl_path, (str, Path)),\n             \"JSONL path must be a string or Path object\")\n    @ensure(lambda result: isinstance(result, AnimalWisdom),\n            \"Must return an AnimalWisdom instance\")\n    def load_from_jsonl(self, jsonl_path: Path) -&gt; AnimalWisdom:\n        \"\"\"Load and validate animal quotes from a JSONL (JSON Lines) file.\n\n        Reads a file where each line contains a JSON object with quote data. The method\n        performs comprehensive validation, skips malformed entries with helpful warnings,\n        and returns a structured collection of quotes ready for indexing and search.\n\n        Expected JSONL Format:\n            Each line should be a JSON object with these fields:\n            - \"text\": The actual quote content (required)\n            - \"author\": Who said or wrote the quote (required)  \n            - \"category\": Thematic classification like \"Wisdom\", \"Humor\" (required)\n\n        Args:\n            jsonl_path: Path to your JSONL file containing animal quotes.\n                Can be a string path or pathlib.Path object.\n\n        Returns:\n            AnimalWisdom object containing all successfully loaded quotes with\n            convenient methods for filtering and analysis.\n\n        Raises:\n            FileNotFoundError: When the specified file doesn't exist at the given path.\n            InvalidPointsError: When no valid quotes are found in the file, indicating\n                format issues or empty content.\n\n        Example:\n            ```python\n            # Load quotes from file\n            quotes_path = Path(\"data/animal_wisdom.jsonl\")\n            wisdom = animals.load_from_jsonl(quotes_path)\n\n            print(f\"Loaded {len(wisdom)} quotes\")\n            print(f\"Categories: {wisdom.get_categories()}\")\n            print(f\"Authors: {wisdom.get_authors()}\")\n\n            # Access individual quotes\n            for quote in wisdom.quotes[:3]:\n                print(f'\"{quote.text}\" - {quote.author}')\n            ```\n\n        File Format Example:\n            ```\n            {\"text\": \"Dogs are not our whole life, but they make our lives whole.\", \"author\": \"Roger Caras\", \"category\": \"Pets and Companionship\"}\n            {\"text\": \"The greatness of a nation can be judged by the way its animals are treated.\", \"author\": \"Mahatma Gandhi\", \"category\": \"Ethics and Compassion\"}\n            ```\n\n        Note:\n            - Empty lines in the file are automatically skipped\n            - Malformed JSON lines generate warnings but don't stop the process\n            - The loaded quotes are stored in self.wisdom for later use\n            - All text fields are automatically stripped of whitespace\n        \"\"\"\n        jsonl_path = Path(jsonl_path)\n\n        if not jsonl_path.exists():\n            raise FileNotFoundError(f\"JSONL file not found: {jsonl_path}\")\n\n        try:\n            quotes = []\n            with open(jsonl_path, 'r', encoding='utf-8') as file:\n                for line_num, line in enumerate(file, 1):\n                    line = line.strip()\n                    if not line:  # Skip empty lines\n                        continue\n\n                    try:\n                        data = json.loads(line)\n                        quote = AnimalQuote(**data)\n                        quotes.append(quote)\n                    except (json.JSONDecodeError, ValueError) as e:\n                        logger.warning(f\"Skipped invalid line {line_num} in {jsonl_path}: {e}\")\n                        continue\n\n            if not quotes:\n                raise InvalidPointsError(\n                    issue=f\"No valid quotes found in {jsonl_path}\",\n                    points_count=0\n                )\n\n            self.wisdom = AnimalWisdom(quotes=quotes, source_file=jsonl_path)\n            logger.info(f\"Loaded {len(quotes)} animal quotes from {jsonl_path}\")\n            return self.wisdom\n\n        except Exception as e:\n            raise InvalidPointsError(\n                issue=f\"Failed to load animal quotes from {jsonl_path}: {str(e)}\",\n                points_count=0\n            )\n\n    # ----------------------------------------------------------------------------------------\n    #  Index All Quotes\n    # ----------------------------------------------------------------------------------------\n    @require(lambda self: self.wisdom is not None,\n             \"Animal wisdom must be loaded before indexing\")\n    def index_all_quotes(self) -&gt; List[str]:\n        \"\"\"Transform all loaded quotes into searchable vector embeddings.\n\n        This method takes your loaded quotes and creates high-dimensional vector\n        representations that enable semantic search. The process uses advanced\n        sentence transformers to understand the meaning and context of each quote,\n        not just keyword matching.\n\n        The indexing process:\n        1. Extracts text content from each quote\n        2. Generates semantic embeddings using the configured model\n        3. Stores vectors in the database with rich metadata\n        4. Creates searchable points for instant retrieval\n\n        Returns:\n            List of unique point IDs for each indexed quote. These IDs can be used\n            for direct retrieval, debugging, or managing specific quotes.\n\n        Raises:\n            InvalidPointsError: When indexing fails due to embedding errors,\n                database issues, or missing quote data.\n\n        Example:\n            ```python\n            # Load quotes first\n            wisdom = animals.load_from_jsonl(\"quotes.jsonl\")\n\n            # Index for semantic search\n            point_ids = animals.index_all_quotes()\n            print(f\"Successfully indexed {len(point_ids)} quotes\")\n\n            # Now you can search semantically\n            results = animals.search(\"loyalty and friendship\")\n            ```\n\n        Performance Notes:\n            - Batch processing is used for efficiency with large collections\n            - Indexing time scales with collection size and model complexity\n            - Typical speed: ~100-500 quotes per second depending on hardware\n            - GPU acceleration automatically used if available\n\n        Note:\n            You must call load_from_jsonl() before indexing. The method will\n            fail gracefully if no quotes are loaded, providing clear error messages.\n        \"\"\"\n        if not self.wisdom:\n            raise InvalidPointsError(\n                issue=\"No animal wisdom loaded. Call load_from_jsonl() first.\",\n                points_count=0\n            )\n\n        try:\n            # Prepare texts and metadata for batch indexing\n            texts = [quote.text for quote in self.wisdom.quotes]\n            metadata_list = [quote.to_payload() for quote in self.wisdom.quotes]\n\n            # Use SemanticSearch's batch indexing capability\n            indexed_ids = self.semantic_search.index_all_text(\n                texts=texts,\n                metadata_list=metadata_list\n            )\n\n            logger.info(f\"Successfully indexed {len(indexed_ids)} animal quotes into collection '{self.collection_name}'\")\n            return indexed_ids\n\n        except Exception as e:\n            raise InvalidPointsError(\n                issue=f\"Failed to index animal quotes: {str(e)}\",\n                points_count=len(self.wisdom.quotes) if self.wisdom else 0\n            )\n\n    # ----------------------------------------------------------------------------------------\n    #  Collection Management\n    # ----------------------------------------------------------------------------------------\n    def recreate_collection(self) -&gt; None:\n        \"\"\"Completely reset your quote collection with a fresh, empty database.\n\n        This is a powerful cleanup method that removes all existing quotes and\n        creates a brand new collection. Use this when you need to start over,\n        fix corruption issues, or completely change your quote dataset.\n\n        What this method does:\n        1. Safely deletes the existing collection if it exists\n        2. Creates a new empty collection with optimal settings\n        3. Clears all loaded quote data from memory\n        4. Prepares the system for fresh data loading\n\n        Raises:\n            InvalidPointsError: If the recreation process fails due to database\n                connection issues or permission problems.\n\n        Example:\n            ```python\n            # Reset everything and start fresh\n            animals.recreate_collection()\n\n            # Now load new data\n            new_wisdom = animals.load_from_jsonl(\"updated_quotes.jsonl\")\n            animals.index_all_quotes()\n            ```\n\n        Warning:\n            This operation is irreversible! All existing quotes in the collection\n            will be permanently deleted. Make sure you have backups of important\n            data before calling this method.\n\n        Use Cases:\n            - Switching to a completely different quote dataset\n            - Fixing corrupted vector data\n            - Changing embedding models (requires reindexing)\n            - Cleaning up test data before production deployment\n        \"\"\"\n        try:\n            # Delete existing collection if it exists\n            if self.semantic_search.vector_db.collection_exists(self.collection_name):\n                logger.info(f\"Deleting existing collection '{self.collection_name}'\")\n                self.semantic_search.vector_db.delete_collection(self.collection_name)\n\n            # Create new empty collection\n            logger.info(f\"Creating new empty collection '{self.collection_name}'\")\n            self.semantic_search.vector_db.create_collection(\n                collection_name=self.collection_name,\n                vector_size=self.semantic_search.embedder.get_vector_size(),\n                distance=self.semantic_search.embedder.get_distance_metric()\n            )\n\n            # Clear loaded wisdom data\n            self.wisdom = None\n\n            logger.info(f\"Successfully recreated empty collection '{self.collection_name}'\")\n\n        except Exception as e:\n            raise InvalidPointsError(\n                issue=f\"Failed to recreate collection: {str(e)}\",\n                points_count=0\n            )\n\n    # ----------------------------------------------------------------------------------------\n    #  Load and Index\n    # ----------------------------------------------------------------------------------------\n    def load_and_index(self, jsonl_path: Path) -&gt; tuple[AnimalWisdom, List[str]]:\n        \"\"\"One-step solution: load quotes from file and make them instantly searchable.\n\n        This convenience method combines loading and indexing in a single call,\n        perfect for getting up and running quickly. It handles the complete\n        pipeline from raw JSONL file to searchable vector database.\n\n        Args:\n            jsonl_path: Path to your JSONL file containing animal quotes.\n\n        Returns:\n            A tuple containing:\n            - AnimalWisdom: Your loaded and validated quote collection\n            - List[str]: Point IDs for all indexed quotes\n\n        Example:\n            ```python\n            # Complete setup in one line\n            wisdom, point_ids = animals.load_and_index(\"my_quotes.jsonl\")\n\n            print(f\"Ready to search {len(wisdom)} quotes!\")\n\n            # Immediately start searching\n            results = animals.search(\"courage and bravery\")\n            ```\n\n        Note:\n            This method is equivalent to calling load_from_jsonl() followed by\n            index_all_quotes(), but more convenient for common workflows.\n        \"\"\"\n        wisdom = self.load_from_jsonl(jsonl_path)\n        point_ids = self.index_all_quotes()\n        return wisdom, point_ids\n\n    # ----------------------------------------------------------------------------------------\n    #  Search Quotes\n    # ----------------------------------------------------------------------------------------\n    @require(lambda query: isinstance(query, str) and len(query.strip()) &gt; 0,\n             \"Query must be a non-empty string\")\n    @require(lambda limit: isinstance(limit, int) and limit &gt; 0,\n             \"Limit must be a positive integer\")\n    @require(lambda author: author is None or (isinstance(author, str) and len(author.strip()) &gt; 0),\n             \"Author filter must be None or a non-empty string\")\n    @require(lambda category: category is None or (isinstance(category, str) and len(category.strip()) &gt; 0),\n             \"Category filter must be None or a non-empty string\")\n    @ensure(lambda result: isinstance(result, list), \"Must return a list\")\n    def search(self, query: str, limit: int = 10, \n              score_threshold: Optional[float] = None,\n              author: Optional[str] = None,\n              category: Optional[str] = None) -&gt; List[models.ScoredPoint]:\n        \"\"\"Find the most relevant animal quotes using intelligent semantic search.\n\n        This powerful search method goes beyond simple keyword matching to understand\n        the meaning and context of your query. It finds quotes that are conceptually\n        similar, even if they don't share exact words with your search terms.\n\n        Args:\n            query: Your search question or topic. Use natural language like\n                \"what do animals teach us about love?\" or \"quotes about courage\".\n            limit: Maximum number of results to return (default: 10).\n                Higher values give more options but may include less relevant results.\n            score_threshold: Minimum similarity score (0.0-1.0). Only quotes with\n                similarity above this threshold will be returned. Use 0.7+ for\n                highly relevant results, 0.5+ for broader matches.\n            author: Filter results to only include quotes by this specific author.\n                Case-insensitive matching (e.g., \"Gandhi\" matches \"Mahatma Gandhi\").\n            category: Filter results to only include quotes from this category.\n                Case-insensitive matching (e.g., \"wisdom\" matches \"Wisdom and Philosophy\").\n\n        Returns:\n            List of ScoredPoint objects, each containing:\n            - score: Similarity score (higher = more relevant)\n            - payload: Quote metadata (content, author, category)\n            Results are automatically sorted by relevance (highest scores first).\n\n        Raises:\n            InvalidPointsError: When search fails due to database issues or\n                invalid query parameters.\n\n        Example:\n            ```python\n            # Basic semantic search\n            results = animals.search(\"loyalty and friendship\")\n\n            # Precise search with high threshold\n            results = animals.search(\n                \"courage in difficult times\",\n                limit=5,\n                score_threshold=0.8\n            )\n\n            # Search within specific author's quotes\n            gandhi_quotes = animals.search(\n                \"compassion\",\n                author=\"Mahatma Gandhi\",\n                limit=3\n            )\n\n            # Browse by category\n            wisdom_quotes = animals.search(\n                \"life lessons\",\n                category=\"Wisdom and Philosophy\"\n            )\n\n            # Process results\n            for result in results:\n                print(f\"Score: {result.score:.3f}\")\n                print(f\"Quote: {result.payload['content']}\")\n                print(f\"Author: {result.payload['author']}\")\n                print(\"---\")\n            ```\n\n        Search Tips:\n            - Use descriptive phrases rather than single keywords\n            - Try different phrasings if you don't find what you're looking for\n            - Lower the score_threshold to see more diverse results\n            - Combine filters to narrow down to specific types of quotes\n\n        Performance:\n            - Search is typically very fast (&lt; 100ms for most collections)\n            - Larger collections may take slightly longer but remain responsive\n            - Filtering by author/category happens after vector search for efficiency\n        \"\"\"\n        try:\n            # Use SemanticSearch for the core search functionality\n            # Request more results than needed to allow for filtering\n            search_limit = limit * 3 if (author or category) else limit\n\n            initial_results = self.semantic_search.search_with_text(\n                query_text=query.strip(),\n                limit=search_limit,\n                score_threshold=score_threshold\n            )\n\n            # Apply metadata filters if specified\n            filtered_results = self._apply_metadata_filters(\n                results=initial_results,\n                author_filter=author,\n                category_filter=category\n            )\n\n            # Limit to requested number of results\n            final_results = filtered_results[:limit]\n\n            logger.info(f\"Animal quotes search for '{query[:50]}...' returned {len(final_results)} results\"\n                       f\"{' (filtered by author)' if author else ''}\"\n                       f\"{' (filtered by category)' if category else ''}\")\n\n            return final_results\n\n        except Exception as e:\n            raise InvalidPointsError(\n                issue=f\"Failed to search animal quotes: {str(e)}\",\n                points_count=1\n            )\n\n    # ----------------------------------------------------------------------------------------\n    #  Get Collection Stats\n    # ----------------------------------------------------------------------------------------\n    def get_collection_stats(self) -&gt; Dict[str, Any]:\n        \"\"\"Get comprehensive statistics and insights about your quote collection.\n\n        Provides a detailed overview of your collection's size, content diversity,\n        and database status. Perfect for monitoring, debugging, or presenting\n        collection metrics to users.\n\n        Returns:\n            Dictionary containing detailed statistics:\n            - collection_name: Name of your quote collection\n            - collection_exists: Whether the database collection exists\n            - point_count: Total quotes stored in the database\n            - loaded_quotes: Number of quotes currently loaded in memory\n            - categories: List of all unique quote categories (sorted)\n            - authors: List of all unique authors (sorted)\n\n        Example:\n            ```python\n            stats = animals.get_collection_stats()\n\n            print(f\"Collection: {stats['collection_name']}\")\n            print(f\"Total quotes in database: {stats['point_count']}\")\n            print(f\"Quotes loaded in memory: {stats['loaded_quotes']}\")\n            print(f\"Categories ({len(stats['categories'])}): {stats['categories']}\")\n            print(f\"Authors ({len(stats['authors'])}): {stats['authors'][:5]}...\")\n\n            # Check if ready for search\n            if stats['collection_exists'] and stats['point_count'] &gt; 0:\n                print(\"\u2705 Ready for semantic search!\")\n            else:\n                print(\"\u274c Need to load and index quotes first\")\n            ```\n\n        Use Cases:\n            - Verify successful data loading and indexing\n            - Display collection overview in user interfaces\n            - Debug database connectivity issues\n            - Monitor collection growth over time\n            - Validate data integrity after operations\n        \"\"\"\n        stats = {\n            \"collection_name\": self.collection_name,\n            \"collection_exists\": self.semantic_search.vector_db.collection_exists(self.collection_name),\n            \"point_count\": 0,\n            \"loaded_quotes\": 0,\n            \"categories\": [],\n            \"authors\": []\n        }\n\n        if stats[\"collection_exists\"]:\n            stats[\"point_count\"] = self.semantic_search.vector_db.count_points(self.collection_name)\n\n        if self.wisdom:\n            stats[\"loaded_quotes\"] = len(self.wisdom)\n            stats[\"categories\"] = self.wisdom.get_categories()\n            stats[\"authors\"] = self.wisdom.get_authors()\n\n        return stats\n\n    # ----------------------------------------------------------------------------------------\n    #  Additional SemanticSearch Integration\n    # ----------------------------------------------------------------------------------------\n    def consistency_check(self) -&gt; bool:\n        \"\"\"Verify that your database collection is properly configured and ready to use.\n\n        Performs a comprehensive health check to ensure your collection's vector\n        dimensions, distance metrics, and other parameters match your embedding model.\n        This prevents subtle bugs that could cause poor search results or errors.\n\n        Returns:\n            True if everything is properly configured and ready for search operations.\n            False indicates configuration mismatches that need attention.\n\n        Example:\n            ```python\n            if animals.consistency_check():\n                print(\"\u2705 Collection is healthy and ready!\")\n                results = animals.search(\"your query here\")\n            else:\n                print(\"\u274c Configuration issues detected\")\n                print(\"Consider recreating the collection:\")\n                animals.recreate_collection()\n            ```\n\n        What's Checked:\n            - Vector dimensions match between collection and embedder\n            - Distance metric compatibility\n            - Collection existence and accessibility\n            - Basic connectivity to the vector database\n\n        Use Cases:\n            - Troubleshooting search performance issues\n            - Validating setup after configuration changes\n            - Health checks in production systems\n            - Debugging after model or database updates\n        \"\"\"\n        return self.semantic_search.consistency_check()\n\n    def index_single_quote(self, quote: AnimalQuote) -&gt; str:\n        \"\"\"Index a single animal quote.\n\n        Args:\n            quote: AnimalQuote instance to index.\n\n        Returns:\n            Point ID of the indexed quote.\n        \"\"\"\n        return self.semantic_search.index_text(\n            text=quote.text,\n            metadata=quote.to_payload()\n        )\n\n    # ----------------------------------------------------------------------------------------\n    #  RAG System Prompts\n    # ----------------------------------------------------------------------------------------\n    # Path to the external system prompt file\n    SYSTEM_PROMPT_PATH = Path(__file__).parent / \"prompts\" / \"animals_system_prompt.md\"\n\n    # Comprehensive RAG System Prompt for Animals Class (loaded at init time)\n    ANIMALS_RAG_SYSTEM_PROMPT: str = \"\"\n\n    # Alternative shorter version for quick use\n    SIMPLE_ANIMALS_PROMPT = \"\"\"\n    You are an expert on animal wisdom and quotes. Use the provided search results \n    to answer questions about animals, human-animal relationships, and life lessons. \n    Always attribute quotes to their authors and explain their relevance to the user's question. \n    Be conversational, thoughtful, and helpful in connecting users with the wisdom \n    found in animal quotes throughout history.\n    \"\"\"\n\n    # ----------------------------------------------------------------------------------------\n    #  RAG Helper Methods\n    # ----------------------------------------------------------------------------------------\n    @require(lambda search_results: isinstance(search_results, list), \"Search results must be a list\")\n    @require(lambda max_results: isinstance(max_results, int) and max_results &gt; 0,\n             \"Max results must be a positive integer\")\n    def format_search_results_for_rag(self, search_results: List[models.ScoredPoint], \n                                     max_results: int = 5) -&gt; str:\n        \"\"\"Format search results from Animals class for RAG system prompt.\n\n        Args:\n            search_results: List of ScoredPoint objects from animals.search()\n            max_results: Maximum number of results to include\n\n        Returns:\n            Formatted string for RAG context\n        \"\"\"\n        if not search_results:\n            return \"No relevant quotes found for this query.\"\n\n        formatted_results = []\n        for i, result in enumerate(search_results[:max_results], 1):\n            content = result.payload.get(\"content\", \"\")\n            author = result.payload.get(\"author\", \"Unknown\")\n            category = result.payload.get(\"category\", \"Unknown\")\n            score = result.score\n\n            formatted_results.append(f\"\"\"\nQuote {i}: \"{content}\"\nAuthor: {author}\nCategory: {category}\nRelevance Score: {score:.3f}\n\"\"\")\n\n        return \"\\n\".join(formatted_results)\n\n    @require(lambda user_query: isinstance(user_query, str) and len(user_query.strip()) &gt; 0,\n             \"User query must be a non-empty string\")\n    @require(lambda search_results: isinstance(search_results, list), \"Search results must be a list\")\n    def create_rag_context(self, user_query: str, search_results: List[models.ScoredPoint], \n                          system_prompt: Optional[str] = None) -&gt; str:\n        \"\"\"Create a complete RAG context with system prompt and formatted results.\n\n        Args:\n            user_query: The user's question\n            search_results: Search results from animals.search()\n            system_prompt: System prompt to use (defaults to comprehensive prompt)\n\n        Returns:\n            Complete RAG context string\n        \"\"\"\n        if system_prompt is None:\n            system_prompt = self.ANIMALS_RAG_SYSTEM_PROMPT\n        if not isinstance(system_prompt, str) or not system_prompt.strip():\n            raise ValueError(\"System prompt must be a non-empty string\")\n\n        formatted_results = self.format_search_results_for_rag(search_results)\n\n        context = f\"\"\"\n{system_prompt}\n\n## User Query\n{user_query}\n\n## Relevant Quotes\n{formatted_results}\n\nPlease answer the user's question using the provided quotes and following the guidelines above.\n\"\"\"\n        return context\n\n    @require(lambda user_query: isinstance(user_query, str) and len(user_query.strip()) &gt; 0,\n             \"User query must be a non-empty string\")\n    @require(lambda limit: isinstance(limit, int) and limit &gt; 0, \"Limit must be a positive integer\")\n    def search_and_create_rag_context(self, user_query: str, limit: int = 5,\n                                    score_threshold: Optional[float] = None,\n                                    author: Optional[str] = None,\n                                    category: Optional[str] = None,\n                                    system_prompt: Optional[str] = None) -&gt; str:\n        \"\"\"Search for quotes and create RAG context in one convenient method.\n\n        Args:\n            user_query: The user's question\n            limit: Maximum number of search results to include\n            score_threshold: Minimum similarity score threshold\n            author: Optional filter to only return quotes by this author\n            category: Optional filter to only return quotes in this category\n            system_prompt: System prompt to use (defaults to comprehensive prompt)\n\n        Returns:\n            Complete RAG context string\n        \"\"\"\n        # Search for relevant quotes\n        search_results = self.search(\n            query=user_query,\n            limit=limit,\n            score_threshold=score_threshold,\n            author=author,\n            category=category\n        )\n\n        # Create RAG context\n        return self.create_rag_context(user_query, search_results, system_prompt)\n\n    # ----------------------------------------------------------------------------------------\n    #  Helper Methods (Private)\n    # ----------------------------------------------------------------------------------------\n    @require(lambda results: isinstance(results, list), \"Results must be a list\")\n    @require(lambda search_description: isinstance(search_description, str) and len(search_description.strip()) &gt; 0,\n             \"Search description must be a non-empty string\")\n    @require(lambda max_text_length: isinstance(max_text_length, int) and max_text_length &gt; 0,\n             \"Max text length must be a positive integer\")\n    def display_search_results(self, results: List[models.ScoredPoint], \n                              search_description: str, \n                              max_text_length: int = 120) -&gt; None:\n        \"\"\"Present search results in a beautiful, easy-to-read table format.\n\n        Creates an elegant visual display of your search results using the Rich library\n        for colorful, well-formatted output. Perfect for interactive applications,\n        demos, or any time you want to show results in a professional way.\n\n        Args:\n            results: Your search results from the search() method. Each result\n                contains the quote text, author, category, and relevance score.\n            search_description: A descriptive title for the search that will be\n                displayed at the top of the table (e.g., \"Quotes about loyalty\").\n            max_text_length: Maximum characters to display for each quote before\n                truncating with \"...\" (default: 120). Keeps table readable.\n\n        Example:\n            ```python\n            # Search and display results beautifully\n            results = animals.search(\"courage and bravery\", limit=5)\n            animals.display_search_results(\n                results, \n                \"Quotes about Courage and Bravery\",\n                max_text_length=100\n            )\n            ```\n\n        Output Features:\n            - \ud83c\udfa8 Color-coded columns for easy scanning\n            - \ud83d\udcca Relevance scores prominently displayed\n            - \u2702\ufe0f Smart text truncation to maintain readability\n            - \ud83d\udcf1 Responsive layout that works in various terminal sizes\n            - \ud83d\udeab Graceful handling of empty results\n\n        Fallback Behavior:\n            If the Rich library isn't available, automatically falls back to\n            simple text output that works in any environment.\n\n        Use Cases:\n            - Interactive demos and presentations\n            - Development and debugging sessions\n            - Educational tools showing search capabilities\n            - Command-line applications with rich output\n        \"\"\"\n        try:\n            from rich.console import Console\n            from rich.table import Table\n            from rich.text import Text\n\n            console = Console()\n\n            # Create table\n            table = Table(\n                title=f\"\ud83d\udd0d {search_description}\",\n                show_header=True,\n                header_style=\"bold magenta\",\n                border_style=\"blue\",\n                padding=(1, 2)  # Add significant vertical and horizontal padding\n            )\n\n            # Add columns\n            table.add_column(\"#\", style=\"magenta\", width=15, justify=\"center\")\n            table.add_column(\"Score\", style=\"green\", width=20, justify=\"center\")\n            table.add_column(\"Quote\", style=\"bright_white\", width=60)\n            table.add_column(\"Author\", style=\"bold bright_yellow\", width=25)\n            table.add_column(\"Category\", style=\"white\", width=25)\n\n            if not results:\n                table.add_row(\"\", \"\", \"\u274c No results found.\", \"\", \"\")\n                console.print(table)\n                return\n\n            # Add rows\n            for i, result in enumerate(results, 1):\n                content = result.payload.get(\"content\", \"\")\n                author = result.payload.get(\"author\", \"Unknown\")\n                category = result.payload.get(\"category\", \"Unknown\")\n                score = result.score\n\n                # Truncate long quotes for readability\n                display_content = (content if len(content) &lt;= max_text_length \n                                 else content[:max_text_length-3] + \"...\")\n\n                # Create styled text for quote\n                quote_text = Text(f'\"{display_content}\"', style=\"italic\")\n\n                table.add_row(\n                    str(i),\n                    f\"{score:.3f}\",\n                    quote_text,\n                    author,\n                    category\n                )\n\n            # Display table\n            console.print(table)\n            console.print(f\"\ud83d\udcca Found {len(results)} results\", style=\"bold green\")\n\n        except ImportError:\n            # Fallback to simple print if rich is not available\n            logger.warning(\"Rich library not available, falling back to simple display\")\n            self._display_search_results_simple(results, search_description, max_text_length)\n        except Exception as e:\n            logger.error(f\"Failed to display search results: {str(e)}\")\n            # Fallback to simple display\n            self._display_search_results_simple(results, search_description, max_text_length)\n\n    def _display_search_results_simple(self, results: List[models.ScoredPoint], \n                                      search_description: str, \n                                      max_text_length: int) -&gt; None:\n        \"\"\"Simple fallback display method when rich is not available.\n\n        Args:\n            results: List of ScoredPoint objects from search results.\n            search_description: Description of the search to display.\n            max_text_length: Maximum length for quote text before truncation.\n        \"\"\"\n        print(f\"\\n\ud83d\udd0d {search_description}\")\n        print(\"=\" * len(f\"\ud83d\udd0d {search_description}\"))\n\n        if not results:\n            print(\"   \u274c No results found.\")\n            return\n\n        print(f\"   \ud83d\udcca Found {len(results)} results\")\n        print()\n\n        for i, result in enumerate(results, 1):\n            content = result.payload.get(\"content\", \"\")\n            author = result.payload.get(\"author\", \"Unknown\")\n            category = result.payload.get(\"category\", \"Unknown\")\n\n            # Truncate long quotes for readability\n            display_content = (content if len(content) &lt;= max_text_length \n                             else content[:max_text_length-3] + \"...\")\n\n            print(f\"   {i}. \ud83d\udcca Score: {result.score:.3f}\")\n            print(f\"      \ud83d\udcac Quote: \\\"{display_content}\\\"\")\n            print(f\"      \u270d\ufe0f  Author: {author}\")\n            print(f\"      \ud83c\udff7\ufe0f  Category: {category}\")\n            print()\n\n    def _apply_metadata_filters(self, results: List[models.ScoredPoint],\n                               author_filter: Optional[str] = None,\n                               category_filter: Optional[str] = None) -&gt; List[models.ScoredPoint]:\n        \"\"\"Apply author and/or category filters to search results.\n\n        Args:\n            results: List of scored points from vector search.\n            author_filter: Optional author name to filter by.\n            category_filter: Optional category name to filter by.\n\n        Returns:\n            Filtered list of scored points.\n        \"\"\"\n        if not author_filter and not category_filter:\n            return results\n\n        filtered_results = []\n\n        for result in results:\n            # Skip results without payload\n            if not result.payload:\n                continue\n\n            # Apply author filter\n            if author_filter:\n                result_author = result.payload.get(\"author\", \"\")\n                if not result_author or result_author.lower() != author_filter.lower():\n                    continue\n\n            # Apply category filter\n            if category_filter:\n                result_category = result.payload.get(\"category\", \"\")\n                if not result_category or result_category.lower() != category_filter.lower():\n                    continue\n\n            filtered_results.append(result)\n\n        return filtered_results\n\n    # ----------------------------------------------------------------------------------------\n    #  LLM Response Models\n    # ----------------------------------------------------------------------------------------\n    class AnimalWisdomResponse(BaseModel):\n        \"\"\"Structured response from LLM about animal wisdom.\"\"\"\n\n        answer: str = Field(\n            ..., \n            description=\"A thoughtful answer to the user's question about animals, using the provided quotes\"\n        )\n        key_insights: List[str] = Field(\n            ..., \n            min_length=1,\n            max_length=5,\n            description=\"2-5 key insights or themes from the quotes\"\n        )\n        recommended_quotes: List[str] = Field(\n            default_factory=list,\n            description=\"Specific quotes that are most relevant to the answer (with author attribution)\"\n        )\n        follow_up_questions: List[str] = Field(\n            default_factory=list,\n            description=\"2-3 follow-up questions to explore related topics\"\n        )\n\n        @field_validator('answer')\n        @classmethod\n        def validate_answer_length(cls, v: str) -&gt; str:\n            \"\"\"Ensure answer is substantial.\"\"\"\n            if len(v.strip()) &lt; 50:\n                raise ValueError(\"Answer must be at least 50 characters long\")\n            return v\n\n    # ----------------------------------------------------------------------------------------\n    #  LLM Integration Methods\n    # ----------------------------------------------------------------------------------------\n    @require(lambda user_query: isinstance(user_query, str) and len(user_query.strip()) &gt; 0,\n             \"User query must be a non-empty string\")\n    @require(lambda limit: isinstance(limit, int) and limit &gt; 0, \"Limit must be a positive integer\")\n    def ask_llm(self, user_query: str, limit: int = 5, \n                score_threshold: Optional[float] = None,\n                author: Optional[str] = None,\n                category: Optional[str] = None,\n                model: str = \"gpt-4o\") -&gt; AnimalWisdomResponse:\n        \"\"\"Ask AI thoughtful questions about animals and get structured, insightful answers.\n\n        This method combines the power of semantic search with advanced AI reasoning\n        to provide comprehensive answers about animal wisdom, behavior, and human-animal\n        relationships. The AI draws from your quote collection to give contextual,\n        well-sourced responses.\n\n        Args:\n            user_query: Your question about animals. Can be philosophical (\"What do\n                animals teach us about love?\"), practical (\"How do pets help humans?\"),\n                or exploratory (\"What wisdom comes from observing nature?\").\n            limit: Number of relevant quotes to provide as context (default: 5).\n                More quotes give richer context but may slow response time.\n            score_threshold: Only use quotes above this similarity score (0.0-1.0).\n                Higher values ensure more relevant context for better answers.\n            author: Focus the answer on quotes from this specific author only.\n            category: Limit context to quotes from this category only.\n            model: OpenAI model to use. \"gpt-4o\" (default) provides the most\n                thoughtful responses, \"gpt-3.5-turbo\" is faster and cheaper.\n\n        Returns:\n            AnimalWisdomResponse containing:\n            - answer: Comprehensive, thoughtful response to your question\n            - key_insights: 2-5 main themes or takeaways from the analysis\n            - recommended_quotes: Most relevant quotes with proper attribution\n            - follow_up_questions: Suggested related questions to explore further\n\n        Example:\n            ```python\n            # Ask a philosophical question\n            response = animals.ask_llm(\n                \"What can animals teach us about resilience and survival?\"\n            )\n\n            # Display the structured response\n            animals.display_llm_response(response, \"resilience question\")\n\n            # Access specific parts\n            print(\"Main Answer:\")\n            print(response.answer)\n\n            print(\"\\\\nKey Insights:\")\n            for insight in response.key_insights:\n                print(f\"- {insight}\")\n\n            # Ask follow-up questions\n            for question in response.follow_up_questions:\n                print(f\"Next: {question}\")\n            ```\n\n        Question Ideas:\n            - \"How do animals demonstrate unconditional love?\"\n            - \"What survival strategies can humans learn from animals?\"\n            - \"How do different cultures view human-animal relationships?\"\n            - \"What role do animals play in teaching empathy?\"\n\n        Note:\n            Requires OpenAI API key in environment. The AI uses your indexed quotes\n            as primary sources, ensuring answers are grounded in your collection\n            rather than general knowledge alone.\n        \"\"\"\n        try:\n            # Create RAG context\n            rag_context = self.search_and_create_rag_context(\n                user_query=user_query,\n                limit=limit,\n                score_threshold=score_threshold,\n                author=author,\n                category=category\n            )\n\n            # Create instructor-patched client\n            client = instructor.from_openai(OpenAI())\n\n            # Get structured response from LLM\n            response = client.chat.completions.create(\n                model=model,\n                response_model=self.AnimalWisdomResponse,\n                messages=[\n                    {\"role\": \"user\", \"content\": rag_context}\n                ]\n            )\n\n            logger.info(f\"LLM response generated for query: '{user_query[:50]}...'\")\n            return response\n\n        except Exception as e:\n            logger.error(f\"Failed to get LLM response: {str(e)}\")\n            raise InvalidPointsError(\n                issue=f\"LLM query failed: {str(e)}\",\n                points_count=1\n            )\n\n    @require(lambda user_query: isinstance(user_query, str) and len(user_query.strip()) &gt; 0,\n             \"User query must be a non-empty string\")\n    def ask_llm_simple(self, user_query: str, limit: int = 3, \n                      model: str = \"gpt-4o\") -&gt; str:\n        \"\"\"Get a simple text response from the LLM about animals.\n\n        Args:\n            user_query: The user's question about animals\n            limit: Maximum number of search results to include\n            model: OpenAI model to use (default: gpt-4o)\n\n        Returns:\n            Simple text response from the LLM\n        \"\"\"\n        try:\n            # Create RAG context\n            rag_context = self.search_and_create_rag_context(\n                user_query=user_query,\n                limit=limit\n            )\n\n            # Create OpenAI client\n            client = OpenAI()\n\n            # Get simple response from LLM\n            response = client.chat.completions.create(\n                model=model,\n                messages=[\n                    {\"role\": \"user\", \"content\": rag_context}\n                ],\n                max_tokens=500,\n                temperature=0.7\n            )\n\n            answer = response.choices[0].message.content\n            logger.info(f\"Simple LLM response generated for query: '{user_query[:50]}...'\")\n            return answer\n\n        except Exception as e:\n            logger.error(f\"Failed to get simple LLM response: {str(e)}\")\n            raise InvalidPointsError(\n                issue=f\"Simple LLM query failed: {str(e)}\",\n                points_count=1\n            )\n\n    def display_llm_response(self, response: AnimalWisdomResponse, user_query: str) -&gt; None:\n        \"\"\"Display the LLM response in a formatted way using rich.\n\n        Args:\n            response: The structured response from the LLM\n            user_query: The original user query\n        \"\"\"\n        try:\n            from rich.console import Console\n            from rich.panel import Panel\n            from rich.text import Text\n            from rich.columns import Columns\n\n            console = Console()\n\n            # Display the main answer\n            console.print(Panel(\n                Text(response.answer, style=\"white\"),\n                title=f\"\ud83e\udd16 LLM Answer to: '{user_query}'\",\n                border_style=\"green\"\n            ))\n\n            # Display key insights\n            insights_text = \"\\n\".join([f\"\u2022 {insight}\" for insight in response.key_insights])\n            console.print(Panel(\n                Text(insights_text, style=\"cyan\"),\n                title=\"\ud83d\udca1 Key Insights\",\n                border_style=\"blue\"\n            ))\n\n            # Display recommended quotes\n            if response.recommended_quotes:\n                quotes_text = \"\\n\\n\".join([f\"\ud83d\udcac {quote}\" for quote in response.recommended_quotes])\n                console.print(Panel(\n                    Text(quotes_text, style=\"yellow\"),\n                    title=\"\ud83d\udcda Recommended Quotes\",\n                    border_style=\"yellow\"\n                ))\n\n            # Display follow-up questions\n            if response.follow_up_questions:\n                questions_text = \"\\n\".join([f\"\u2753 {question}\" for question in response.follow_up_questions])\n                console.print(Panel(\n                    Text(questions_text, style=\"magenta\"),\n                    title=\"\ud83d\udd0d Follow-up Questions\",\n                    border_style=\"magenta\"\n                ))\n\n        except ImportError:\n            # Fallback to simple print if rich is not available\n            logger.warning(\"Rich library not available, falling back to simple display\")\n            self._display_llm_response_simple(response, user_query)\n        except Exception as e:\n            logger.error(f\"Failed to display LLM response: {str(e)}\")\n            self._display_llm_response_simple(response, user_query)\n\n    def _display_llm_response_simple(self, response: AnimalWisdomResponse, user_query: str) -&gt; None:\n        \"\"\"Simple fallback display method when rich is not available.\n\n        Args:\n            response: The structured response from the LLM\n            user_query: The original user query\n        \"\"\"\n        print(f\"\\n\ud83e\udd16 LLM Answer to: '{user_query}'\")\n        print(\"=\" * 60)\n        print(response.answer)\n        print()\n\n        print(\"\ud83d\udca1 Key Insights:\")\n        for insight in response.key_insights:\n            print(f\"  \u2022 {insight}\")\n        print()\n\n        if response.recommended_quotes:\n            print(\"\ud83d\udcda Recommended Quotes:\")\n            for quote in response.recommended_quotes:\n                print(f\"  \ud83d\udcac {quote}\")\n            print()\n\n        if response.follow_up_questions:\n            print(\"\ud83d\udd0d Follow-up Questions:\")\n            for question in response.follow_up_questions:\n                print(f\"  \u2753 {question}\")\n            print()\n\n    # ----------------------------------------------------------------------------------------\n    #  RAG Facade Method\n    # ----------------------------------------------------------------------------------------\n    @require(lambda user_query: isinstance(user_query, str) and len(user_query.strip()) &gt; 0,\n             \"User query must be a non-empty string\")\n    @require(lambda limit: isinstance(limit, int) and limit &gt; 0, \"Limit must be a positive integer\")\n    def rag(self, user_query: str, limit: int = 5, \n            score_threshold: Optional[float] = None,\n            author: Optional[str] = None,\n            category: Optional[str] = None,\n            model: str = \"gpt-4o\",\n            response_type: str = \"structured\") -&gt; Dict[str, Any]:\n        \"\"\"\ud83d\ude80 Complete AI-powered question answering in one powerful method call.\n\n        This is your one-stop solution for getting intelligent answers about animals.\n        It automatically searches your quote collection, finds the most relevant content,\n        and generates comprehensive AI responses with full transparency into the process.\n\n        Perfect for building chatbots, educational tools, or research applications where\n        you need both the AI answer and access to the underlying source material.\n\n        The Complete RAG Pipeline:\n        1. \ud83d\udd0d Semantic search finds relevant quotes from your collection\n        2. \ud83d\udcdd Context generation creates optimized prompts for the AI\n        3. \ud83e\udd16 AI reasoning produces thoughtful, grounded responses\n        4. \ud83d\udcca Full transparency with all intermediate results returned\n\n        Args:\n            user_query: Your question about animals. Use natural, conversational\n                language like \"How do animals show love?\" or \"What can pets teach\n                children about responsibility?\"\n            limit: Number of quotes to use as context (default: 5). More context\n                can improve answer quality but increases cost and response time.\n            score_threshold: Minimum relevance score for quotes (0.0-1.0). Higher\n                values ensure only highly relevant quotes are used as context.\n            author: Limit context to quotes from this author only. Great for\n                exploring specific perspectives or philosophies.\n            category: Focus on quotes from this category only. Useful for domain-\n                specific questions like \"Ethics\" or \"Pet Care\".\n            model: OpenAI model for AI responses. \"gpt-4o\" gives the best quality,\n                \"gpt-3.5-turbo\" is faster and more economical.\n            response_type: Format of AI response:\n                - \"structured\": Rich AnimalWisdomResponse with insights and follow-ups\n                - \"simple\": Plain text response for basic use cases\n\n        Returns:\n            Complete results dictionary containing:\n            - llm_response: AI answer (structured object or simple string)\n            - search_results: List of relevant quotes found (with scores)\n            - rag_context: Full prompt sent to AI (for debugging/transparency)\n            - query_info: Metadata about the query and processing parameters\n\n        Raises:\n            InvalidPointsError: When any step fails (search, context generation,\n                or AI response). Error messages indicate which step failed.\n\n        Example:\n            ```python\n            # Complete RAG in one call\n            result = animals.rag(\n                \"What do animals teach us about unconditional love?\",\n                limit=7,\n                score_threshold=0.6,\n                response_type=\"structured\"\n            )\n\n            # Access the AI response\n            ai_answer = result[\"llm_response\"]\n            print(\"AI Answer:\", ai_answer.answer)\n\n            # See what quotes were used\n            quotes_used = result[\"search_results\"]\n            print(f\"Based on {len(quotes_used)} relevant quotes\")\n\n            # Inspect the full context (for debugging)\n            full_prompt = result[\"rag_context\"]\n\n            # Get query metadata\n            info = result[\"query_info\"]\n            print(f\"Model: {info['model']}, Results: {info['results_count']}\")\n            ```\n\n        Advanced Usage:\n            ```python\n            # Domain-specific question\n            ethics_result = animals.rag(\n                \"How should humans treat wild animals?\",\n                category=\"Ethics and Compassion\",\n                limit=10\n            )\n\n            # Author-focused inquiry\n            gandhi_result = animals.rag(\n                \"What did Gandhi believe about animals?\",\n                author=\"Mahatma Gandhi\",\n                response_type=\"simple\"\n            )\n            ```\n\n        Use Cases:\n            - Educational Q&amp;A systems about animals and nature\n            - Research tools for exploring animal-human relationships\n            - Content generation for blogs, articles, or presentations\n            - Interactive chatbots with grounded, source-backed responses\n            - Philosophical exploration of animal wisdom and ethics\n\n        Performance Tips:\n            - Start with limit=5 for good balance of quality and speed\n            - Use score_threshold=0.7+ for highly focused questions\n            - Choose \"simple\" response_type for faster, lower-cost interactions\n            - Cache results for frequently asked questions\n        \"\"\"\n        try:\n            # Step 1: Perform semantic search\n            search_results = self.search(\n                query=user_query,\n                limit=limit,\n                score_threshold=score_threshold,\n                author=author,\n                category=category\n            )\n\n            # Step 2: Generate RAG context\n            rag_context = self.create_rag_context(\n                user_query=user_query,\n                search_results=search_results\n            )\n\n            # Step 3: Get LLM response based on type\n            if response_type.lower() == \"structured\":\n                llm_response = self.ask_llm(\n                    user_query=user_query,\n                    limit=limit,\n                    score_threshold=score_threshold,\n                    author=author,\n                    category=category,\n                    model=model\n                )\n            elif response_type.lower() == \"simple\":\n                llm_response = self.ask_llm_simple(\n                    user_query=user_query,\n                    limit=limit,\n                    model=model\n                )\n            else:\n                raise ValueError(f\"Invalid response_type: {response_type}. Must be 'structured' or 'simple'\")\n\n            # Step 4: Prepare query info\n            query_info = {\n                \"user_query\": user_query,\n                \"limit\": limit,\n                \"score_threshold\": score_threshold,\n                \"author_filter\": author,\n                \"category_filter\": category,\n                \"model\": model,\n                \"response_type\": response_type,\n                \"results_count\": len(search_results)\n            }\n\n            # Step 5: Return complete RAG result\n            result = {\n                \"llm_response\": llm_response,\n                \"search_results\": search_results,\n                \"rag_context\": rag_context,\n                \"query_info\": query_info\n            }\n\n            logger.info(f\"Complete RAG pipeline executed for query: '{user_query[:50]}...' \"\n                       f\"with {len(search_results)} results and {response_type} response\")\n\n            return result\n\n        except Exception as e:\n            logger.error(f\"RAG pipeline failed: {str(e)}\")\n            raise InvalidPointsError(\n                issue=f\"RAG pipeline failed: {str(e)}\",\n                points_count=1\n            )\n</code></pre>"},{"location":"corpus/Animals/#rag_to_riches.corpus.animals.Animals.AnimalWisdomResponse","title":"<code>AnimalWisdomResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Structured response from LLM about animal wisdom.</p> Source code in <code>src/rag_to_riches/corpus/animals.py</code> <pre><code>class AnimalWisdomResponse(BaseModel):\n    \"\"\"Structured response from LLM about animal wisdom.\"\"\"\n\n    answer: str = Field(\n        ..., \n        description=\"A thoughtful answer to the user's question about animals, using the provided quotes\"\n    )\n    key_insights: List[str] = Field(\n        ..., \n        min_length=1,\n        max_length=5,\n        description=\"2-5 key insights or themes from the quotes\"\n    )\n    recommended_quotes: List[str] = Field(\n        default_factory=list,\n        description=\"Specific quotes that are most relevant to the answer (with author attribution)\"\n    )\n    follow_up_questions: List[str] = Field(\n        default_factory=list,\n        description=\"2-3 follow-up questions to explore related topics\"\n    )\n\n    @field_validator('answer')\n    @classmethod\n    def validate_answer_length(cls, v: str) -&gt; str:\n        \"\"\"Ensure answer is substantial.\"\"\"\n        if len(v.strip()) &lt; 50:\n            raise ValueError(\"Answer must be at least 50 characters long\")\n        return v\n</code></pre>"},{"location":"corpus/Animals/#rag_to_riches.corpus.animals.Animals.AnimalWisdomResponse.validate_answer_length","title":"<code>validate_answer_length(v)</code>  <code>classmethod</code>","text":"<p>Ensure answer is substantial.</p> Source code in <code>src/rag_to_riches/corpus/animals.py</code> <pre><code>@field_validator('answer')\n@classmethod\ndef validate_answer_length(cls, v: str) -&gt; str:\n    \"\"\"Ensure answer is substantial.\"\"\"\n    if len(v.strip()) &lt; 50:\n        raise ValueError(\"Answer must be at least 50 characters long\")\n    return v\n</code></pre>"},{"location":"corpus/Animals/#rag_to_riches.corpus.animals.Animals.__init__","title":"<code>__init__(vector_db, embedder=None, collection_name='animals')</code>","text":"<p>Initialize your Animals quote corpus with intelligent search capabilities.</p> <p>Sets up the complete infrastructure for loading, indexing, and searching animal quotes. The system uses advanced sentence transformers for semantic understanding and can work with any size collection efficiently.</p> <p>Parameters:</p> Name Type Description Default <code>vector_db</code> <code>EmbeddedVectorDB</code> <p>Your vector database instance where quotes will be stored. This handles all the vector storage and retrieval operations.</p> required <code>embedder</code> <code>Optional[SimpleTextEmbedder]</code> <p>Optional text embedding model. If None, uses the default 'sentence-transformers/all-MiniLM-L6-v2' model which provides excellent semantic understanding for quotes and wisdom.</p> <code>None</code> <code>collection_name</code> <code>str</code> <p>Unique name for your quote collection. Use descriptive names like \"animal_wisdom\", \"pet_quotes\", or \"nature_sayings\" to organize multiple collections.</p> <code>'animals'</code> Example <pre><code># Basic setup with default embedder\nanimals = Animals(vector_db)\n\n# Custom setup with specific collection\nanimals = Animals(\n    vector_db=my_db,\n    collection_name=\"philosophical_animal_quotes\"\n)\n\n# Advanced setup with custom embedder\ncustom_embedder = SimpleTextEmbedder(model_name=\"custom-model\")\nanimals = Animals(vector_db, embedder=custom_embedder)\n</code></pre> Note <p>The constructor automatically loads the RAG system prompt for AI interactions. If the prompt file is missing, a warning is logged but the system continues to work with reduced AI capabilities.</p> Source code in <code>src/rag_to_riches/corpus/animals.py</code> <pre><code>@require(lambda vector_db: isinstance(vector_db, EmbeddedVectorDB),\n         \"Vector DB must be an EmbeddedVectorDB instance\")\n@require(lambda embedder: embedder is None or isinstance(embedder, SimpleTextEmbedder),\n         \"Embedder must be None or a SimpleTextEmbedder instance\")\ndef __init__(self, vector_db: EmbeddedVectorDB, \n             embedder: Optional[SimpleTextEmbedder] = None,\n             collection_name: str = \"animals\") -&gt; None:\n    \"\"\"Initialize your Animals quote corpus with intelligent search capabilities.\n\n    Sets up the complete infrastructure for loading, indexing, and searching animal\n    quotes. The system uses advanced sentence transformers for semantic understanding\n    and can work with any size collection efficiently.\n\n    Args:\n        vector_db: Your vector database instance where quotes will be stored.\n            This handles all the vector storage and retrieval operations.\n        embedder: Optional text embedding model. If None, uses the default\n            'sentence-transformers/all-MiniLM-L6-v2' model which provides\n            excellent semantic understanding for quotes and wisdom.\n        collection_name: Unique name for your quote collection. Use descriptive\n            names like \"animal_wisdom\", \"pet_quotes\", or \"nature_sayings\" to\n            organize multiple collections.\n\n    Example:\n        ```python\n        # Basic setup with default embedder\n        animals = Animals(vector_db)\n\n        # Custom setup with specific collection\n        animals = Animals(\n            vector_db=my_db,\n            collection_name=\"philosophical_animal_quotes\"\n        )\n\n        # Advanced setup with custom embedder\n        custom_embedder = SimpleTextEmbedder(model_name=\"custom-model\")\n        animals = Animals(vector_db, embedder=custom_embedder)\n        ```\n\n    Note:\n        The constructor automatically loads the RAG system prompt for AI interactions.\n        If the prompt file is missing, a warning is logged but the system continues\n        to work with reduced AI capabilities.\n    \"\"\"\n    self.embedder = embedder or SimpleTextEmbedder()\n    self.collection_name = collection_name\n    self.wisdom: Optional[AnimalWisdom] = None\n\n    # Initialize the underlying semantic search engine\n    self.semantic_search = SemanticSearch(\n        embedder=self.embedder,\n        vector_db=vector_db,\n        collection_name=collection_name\n    )\n\n    logger.info(f\"Initialized Animals corpus loader for collection '{collection_name}'\")\n    if not Animals.ANIMALS_RAG_SYSTEM_PROMPT:\n        Animals.ANIMALS_RAG_SYSTEM_PROMPT = self._load_system_prompt()\n</code></pre>"},{"location":"corpus/Animals/#rag_to_riches.corpus.animals.Animals.ask_llm","title":"<code>ask_llm(user_query, limit=5, score_threshold=None, author=None, category=None, model='gpt-4o')</code>","text":"<p>Ask AI thoughtful questions about animals and get structured, insightful answers.</p> <p>This method combines the power of semantic search with advanced AI reasoning to provide comprehensive answers about animal wisdom, behavior, and human-animal relationships. The AI draws from your quote collection to give contextual, well-sourced responses.</p> <p>Parameters:</p> Name Type Description Default <code>user_query</code> <code>str</code> <p>Your question about animals. Can be philosophical (\"What do animals teach us about love?\"), practical (\"How do pets help humans?\"), or exploratory (\"What wisdom comes from observing nature?\").</p> required <code>limit</code> <code>int</code> <p>Number of relevant quotes to provide as context (default: 5). More quotes give richer context but may slow response time.</p> <code>5</code> <code>score_threshold</code> <code>Optional[float]</code> <p>Only use quotes above this similarity score (0.0-1.0). Higher values ensure more relevant context for better answers.</p> <code>None</code> <code>author</code> <code>Optional[str]</code> <p>Focus the answer on quotes from this specific author only.</p> <code>None</code> <code>category</code> <code>Optional[str]</code> <p>Limit context to quotes from this category only.</p> <code>None</code> <code>model</code> <code>str</code> <p>OpenAI model to use. \"gpt-4o\" (default) provides the most thoughtful responses, \"gpt-3.5-turbo\" is faster and cheaper.</p> <code>'gpt-4o'</code> <p>Returns:</p> Type Description <code>AnimalWisdomResponse</code> <p>AnimalWisdomResponse containing:</p> <code>AnimalWisdomResponse</code> <ul> <li>answer: Comprehensive, thoughtful response to your question</li> </ul> <code>AnimalWisdomResponse</code> <ul> <li>key_insights: 2-5 main themes or takeaways from the analysis</li> </ul> <code>AnimalWisdomResponse</code> <ul> <li>recommended_quotes: Most relevant quotes with proper attribution</li> </ul> <code>AnimalWisdomResponse</code> <ul> <li>follow_up_questions: Suggested related questions to explore further</li> </ul> Example <pre><code># Ask a philosophical question\nresponse = animals.ask_llm(\n    \"What can animals teach us about resilience and survival?\"\n)\n\n# Display the structured response\nanimals.display_llm_response(response, \"resilience question\")\n\n# Access specific parts\nprint(\"Main Answer:\")\nprint(response.answer)\n\nprint(\"\\nKey Insights:\")\nfor insight in response.key_insights:\n    print(f\"- {insight}\")\n\n# Ask follow-up questions\nfor question in response.follow_up_questions:\n    print(f\"Next: {question}\")\n</code></pre> Question Ideas <ul> <li>\"How do animals demonstrate unconditional love?\"</li> <li>\"What survival strategies can humans learn from animals?\"</li> <li>\"How do different cultures view human-animal relationships?\"</li> <li>\"What role do animals play in teaching empathy?\"</li> </ul> Note <p>Requires OpenAI API key in environment. The AI uses your indexed quotes as primary sources, ensuring answers are grounded in your collection rather than general knowledge alone.</p> Source code in <code>src/rag_to_riches/corpus/animals.py</code> <pre><code>@require(lambda user_query: isinstance(user_query, str) and len(user_query.strip()) &gt; 0,\n         \"User query must be a non-empty string\")\n@require(lambda limit: isinstance(limit, int) and limit &gt; 0, \"Limit must be a positive integer\")\ndef ask_llm(self, user_query: str, limit: int = 5, \n            score_threshold: Optional[float] = None,\n            author: Optional[str] = None,\n            category: Optional[str] = None,\n            model: str = \"gpt-4o\") -&gt; AnimalWisdomResponse:\n    \"\"\"Ask AI thoughtful questions about animals and get structured, insightful answers.\n\n    This method combines the power of semantic search with advanced AI reasoning\n    to provide comprehensive answers about animal wisdom, behavior, and human-animal\n    relationships. The AI draws from your quote collection to give contextual,\n    well-sourced responses.\n\n    Args:\n        user_query: Your question about animals. Can be philosophical (\"What do\n            animals teach us about love?\"), practical (\"How do pets help humans?\"),\n            or exploratory (\"What wisdom comes from observing nature?\").\n        limit: Number of relevant quotes to provide as context (default: 5).\n            More quotes give richer context but may slow response time.\n        score_threshold: Only use quotes above this similarity score (0.0-1.0).\n            Higher values ensure more relevant context for better answers.\n        author: Focus the answer on quotes from this specific author only.\n        category: Limit context to quotes from this category only.\n        model: OpenAI model to use. \"gpt-4o\" (default) provides the most\n            thoughtful responses, \"gpt-3.5-turbo\" is faster and cheaper.\n\n    Returns:\n        AnimalWisdomResponse containing:\n        - answer: Comprehensive, thoughtful response to your question\n        - key_insights: 2-5 main themes or takeaways from the analysis\n        - recommended_quotes: Most relevant quotes with proper attribution\n        - follow_up_questions: Suggested related questions to explore further\n\n    Example:\n        ```python\n        # Ask a philosophical question\n        response = animals.ask_llm(\n            \"What can animals teach us about resilience and survival?\"\n        )\n\n        # Display the structured response\n        animals.display_llm_response(response, \"resilience question\")\n\n        # Access specific parts\n        print(\"Main Answer:\")\n        print(response.answer)\n\n        print(\"\\\\nKey Insights:\")\n        for insight in response.key_insights:\n            print(f\"- {insight}\")\n\n        # Ask follow-up questions\n        for question in response.follow_up_questions:\n            print(f\"Next: {question}\")\n        ```\n\n    Question Ideas:\n        - \"How do animals demonstrate unconditional love?\"\n        - \"What survival strategies can humans learn from animals?\"\n        - \"How do different cultures view human-animal relationships?\"\n        - \"What role do animals play in teaching empathy?\"\n\n    Note:\n        Requires OpenAI API key in environment. The AI uses your indexed quotes\n        as primary sources, ensuring answers are grounded in your collection\n        rather than general knowledge alone.\n    \"\"\"\n    try:\n        # Create RAG context\n        rag_context = self.search_and_create_rag_context(\n            user_query=user_query,\n            limit=limit,\n            score_threshold=score_threshold,\n            author=author,\n            category=category\n        )\n\n        # Create instructor-patched client\n        client = instructor.from_openai(OpenAI())\n\n        # Get structured response from LLM\n        response = client.chat.completions.create(\n            model=model,\n            response_model=self.AnimalWisdomResponse,\n            messages=[\n                {\"role\": \"user\", \"content\": rag_context}\n            ]\n        )\n\n        logger.info(f\"LLM response generated for query: '{user_query[:50]}...'\")\n        return response\n\n    except Exception as e:\n        logger.error(f\"Failed to get LLM response: {str(e)}\")\n        raise InvalidPointsError(\n            issue=f\"LLM query failed: {str(e)}\",\n            points_count=1\n        )\n</code></pre>"},{"location":"corpus/Animals/#rag_to_riches.corpus.animals.Animals.ask_llm_simple","title":"<code>ask_llm_simple(user_query, limit=3, model='gpt-4o')</code>","text":"<p>Get a simple text response from the LLM about animals.</p> <p>Parameters:</p> Name Type Description Default <code>user_query</code> <code>str</code> <p>The user's question about animals</p> required <code>limit</code> <code>int</code> <p>Maximum number of search results to include</p> <code>3</code> <code>model</code> <code>str</code> <p>OpenAI model to use (default: gpt-4o)</p> <code>'gpt-4o'</code> <p>Returns:</p> Type Description <code>str</code> <p>Simple text response from the LLM</p> Source code in <code>src/rag_to_riches/corpus/animals.py</code> <pre><code>@require(lambda user_query: isinstance(user_query, str) and len(user_query.strip()) &gt; 0,\n         \"User query must be a non-empty string\")\ndef ask_llm_simple(self, user_query: str, limit: int = 3, \n                  model: str = \"gpt-4o\") -&gt; str:\n    \"\"\"Get a simple text response from the LLM about animals.\n\n    Args:\n        user_query: The user's question about animals\n        limit: Maximum number of search results to include\n        model: OpenAI model to use (default: gpt-4o)\n\n    Returns:\n        Simple text response from the LLM\n    \"\"\"\n    try:\n        # Create RAG context\n        rag_context = self.search_and_create_rag_context(\n            user_query=user_query,\n            limit=limit\n        )\n\n        # Create OpenAI client\n        client = OpenAI()\n\n        # Get simple response from LLM\n        response = client.chat.completions.create(\n            model=model,\n            messages=[\n                {\"role\": \"user\", \"content\": rag_context}\n            ],\n            max_tokens=500,\n            temperature=0.7\n        )\n\n        answer = response.choices[0].message.content\n        logger.info(f\"Simple LLM response generated for query: '{user_query[:50]}...'\")\n        return answer\n\n    except Exception as e:\n        logger.error(f\"Failed to get simple LLM response: {str(e)}\")\n        raise InvalidPointsError(\n            issue=f\"Simple LLM query failed: {str(e)}\",\n            points_count=1\n        )\n</code></pre>"},{"location":"corpus/Animals/#rag_to_riches.corpus.animals.Animals.consistency_check","title":"<code>consistency_check()</code>","text":"<p>Verify that your database collection is properly configured and ready to use.</p> <p>Performs a comprehensive health check to ensure your collection's vector dimensions, distance metrics, and other parameters match your embedding model. This prevents subtle bugs that could cause poor search results or errors.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if everything is properly configured and ready for search operations.</p> <code>bool</code> <p>False indicates configuration mismatches that need attention.</p> Example <pre><code>if animals.consistency_check():\n    print(\"\u2705 Collection is healthy and ready!\")\n    results = animals.search(\"your query here\")\nelse:\n    print(\"\u274c Configuration issues detected\")\n    print(\"Consider recreating the collection:\")\n    animals.recreate_collection()\n</code></pre> <p>What's Checked:     - Vector dimensions match between collection and embedder     - Distance metric compatibility     - Collection existence and accessibility     - Basic connectivity to the vector database</p> Use Cases <ul> <li>Troubleshooting search performance issues</li> <li>Validating setup after configuration changes</li> <li>Health checks in production systems</li> <li>Debugging after model or database updates</li> </ul> Source code in <code>src/rag_to_riches/corpus/animals.py</code> <pre><code>def consistency_check(self) -&gt; bool:\n    \"\"\"Verify that your database collection is properly configured and ready to use.\n\n    Performs a comprehensive health check to ensure your collection's vector\n    dimensions, distance metrics, and other parameters match your embedding model.\n    This prevents subtle bugs that could cause poor search results or errors.\n\n    Returns:\n        True if everything is properly configured and ready for search operations.\n        False indicates configuration mismatches that need attention.\n\n    Example:\n        ```python\n        if animals.consistency_check():\n            print(\"\u2705 Collection is healthy and ready!\")\n            results = animals.search(\"your query here\")\n        else:\n            print(\"\u274c Configuration issues detected\")\n            print(\"Consider recreating the collection:\")\n            animals.recreate_collection()\n        ```\n\n    What's Checked:\n        - Vector dimensions match between collection and embedder\n        - Distance metric compatibility\n        - Collection existence and accessibility\n        - Basic connectivity to the vector database\n\n    Use Cases:\n        - Troubleshooting search performance issues\n        - Validating setup after configuration changes\n        - Health checks in production systems\n        - Debugging after model or database updates\n    \"\"\"\n    return self.semantic_search.consistency_check()\n</code></pre>"},{"location":"corpus/Animals/#rag_to_riches.corpus.animals.Animals.create_rag_context","title":"<code>create_rag_context(user_query, search_results, system_prompt=None)</code>","text":"<p>Create a complete RAG context with system prompt and formatted results.</p> <p>Parameters:</p> Name Type Description Default <code>user_query</code> <code>str</code> <p>The user's question</p> required <code>search_results</code> <code>List[ScoredPoint]</code> <p>Search results from animals.search()</p> required <code>system_prompt</code> <code>Optional[str]</code> <p>System prompt to use (defaults to comprehensive prompt)</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>Complete RAG context string</p> Source code in <code>src/rag_to_riches/corpus/animals.py</code> <pre><code>    @require(lambda user_query: isinstance(user_query, str) and len(user_query.strip()) &gt; 0,\n             \"User query must be a non-empty string\")\n    @require(lambda search_results: isinstance(search_results, list), \"Search results must be a list\")\n    def create_rag_context(self, user_query: str, search_results: List[models.ScoredPoint], \n                          system_prompt: Optional[str] = None) -&gt; str:\n        \"\"\"Create a complete RAG context with system prompt and formatted results.\n\n        Args:\n            user_query: The user's question\n            search_results: Search results from animals.search()\n            system_prompt: System prompt to use (defaults to comprehensive prompt)\n\n        Returns:\n            Complete RAG context string\n        \"\"\"\n        if system_prompt is None:\n            system_prompt = self.ANIMALS_RAG_SYSTEM_PROMPT\n        if not isinstance(system_prompt, str) or not system_prompt.strip():\n            raise ValueError(\"System prompt must be a non-empty string\")\n\n        formatted_results = self.format_search_results_for_rag(search_results)\n\n        context = f\"\"\"\n{system_prompt}\n\n## User Query\n{user_query}\n\n## Relevant Quotes\n{formatted_results}\n\nPlease answer the user's question using the provided quotes and following the guidelines above.\n\"\"\"\n        return context\n</code></pre>"},{"location":"corpus/Animals/#rag_to_riches.corpus.animals.Animals.display_llm_response","title":"<code>display_llm_response(response, user_query)</code>","text":"<p>Display the LLM response in a formatted way using rich.</p> <p>Parameters:</p> Name Type Description Default <code>response</code> <code>AnimalWisdomResponse</code> <p>The structured response from the LLM</p> required <code>user_query</code> <code>str</code> <p>The original user query</p> required Source code in <code>src/rag_to_riches/corpus/animals.py</code> <pre><code>def display_llm_response(self, response: AnimalWisdomResponse, user_query: str) -&gt; None:\n    \"\"\"Display the LLM response in a formatted way using rich.\n\n    Args:\n        response: The structured response from the LLM\n        user_query: The original user query\n    \"\"\"\n    try:\n        from rich.console import Console\n        from rich.panel import Panel\n        from rich.text import Text\n        from rich.columns import Columns\n\n        console = Console()\n\n        # Display the main answer\n        console.print(Panel(\n            Text(response.answer, style=\"white\"),\n            title=f\"\ud83e\udd16 LLM Answer to: '{user_query}'\",\n            border_style=\"green\"\n        ))\n\n        # Display key insights\n        insights_text = \"\\n\".join([f\"\u2022 {insight}\" for insight in response.key_insights])\n        console.print(Panel(\n            Text(insights_text, style=\"cyan\"),\n            title=\"\ud83d\udca1 Key Insights\",\n            border_style=\"blue\"\n        ))\n\n        # Display recommended quotes\n        if response.recommended_quotes:\n            quotes_text = \"\\n\\n\".join([f\"\ud83d\udcac {quote}\" for quote in response.recommended_quotes])\n            console.print(Panel(\n                Text(quotes_text, style=\"yellow\"),\n                title=\"\ud83d\udcda Recommended Quotes\",\n                border_style=\"yellow\"\n            ))\n\n        # Display follow-up questions\n        if response.follow_up_questions:\n            questions_text = \"\\n\".join([f\"\u2753 {question}\" for question in response.follow_up_questions])\n            console.print(Panel(\n                Text(questions_text, style=\"magenta\"),\n                title=\"\ud83d\udd0d Follow-up Questions\",\n                border_style=\"magenta\"\n            ))\n\n    except ImportError:\n        # Fallback to simple print if rich is not available\n        logger.warning(\"Rich library not available, falling back to simple display\")\n        self._display_llm_response_simple(response, user_query)\n    except Exception as e:\n        logger.error(f\"Failed to display LLM response: {str(e)}\")\n        self._display_llm_response_simple(response, user_query)\n</code></pre>"},{"location":"corpus/Animals/#rag_to_riches.corpus.animals.Animals.display_search_results","title":"<code>display_search_results(results, search_description, max_text_length=120)</code>","text":"<p>Present search results in a beautiful, easy-to-read table format.</p> <p>Creates an elegant visual display of your search results using the Rich library for colorful, well-formatted output. Perfect for interactive applications, demos, or any time you want to show results in a professional way.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>List[ScoredPoint]</code> <p>Your search results from the search() method. Each result contains the quote text, author, category, and relevance score.</p> required <code>search_description</code> <code>str</code> <p>A descriptive title for the search that will be displayed at the top of the table (e.g., \"Quotes about loyalty\").</p> required <code>max_text_length</code> <code>int</code> <p>Maximum characters to display for each quote before truncating with \"...\" (default: 120). Keeps table readable.</p> <code>120</code> Example <pre><code># Search and display results beautifully\nresults = animals.search(\"courage and bravery\", limit=5)\nanimals.display_search_results(\n    results, \n    \"Quotes about Courage and Bravery\",\n    max_text_length=100\n)\n</code></pre> Output Features <ul> <li>\ud83c\udfa8 Color-coded columns for easy scanning</li> <li>\ud83d\udcca Relevance scores prominently displayed</li> <li>\u2702\ufe0f Smart text truncation to maintain readability</li> <li>\ud83d\udcf1 Responsive layout that works in various terminal sizes</li> <li>\ud83d\udeab Graceful handling of empty results</li> </ul> Fallback Behavior <p>If the Rich library isn't available, automatically falls back to simple text output that works in any environment.</p> Use Cases <ul> <li>Interactive demos and presentations</li> <li>Development and debugging sessions</li> <li>Educational tools showing search capabilities</li> <li>Command-line applications with rich output</li> </ul> Source code in <code>src/rag_to_riches/corpus/animals.py</code> <pre><code>@require(lambda results: isinstance(results, list), \"Results must be a list\")\n@require(lambda search_description: isinstance(search_description, str) and len(search_description.strip()) &gt; 0,\n         \"Search description must be a non-empty string\")\n@require(lambda max_text_length: isinstance(max_text_length, int) and max_text_length &gt; 0,\n         \"Max text length must be a positive integer\")\ndef display_search_results(self, results: List[models.ScoredPoint], \n                          search_description: str, \n                          max_text_length: int = 120) -&gt; None:\n    \"\"\"Present search results in a beautiful, easy-to-read table format.\n\n    Creates an elegant visual display of your search results using the Rich library\n    for colorful, well-formatted output. Perfect for interactive applications,\n    demos, or any time you want to show results in a professional way.\n\n    Args:\n        results: Your search results from the search() method. Each result\n            contains the quote text, author, category, and relevance score.\n        search_description: A descriptive title for the search that will be\n            displayed at the top of the table (e.g., \"Quotes about loyalty\").\n        max_text_length: Maximum characters to display for each quote before\n            truncating with \"...\" (default: 120). Keeps table readable.\n\n    Example:\n        ```python\n        # Search and display results beautifully\n        results = animals.search(\"courage and bravery\", limit=5)\n        animals.display_search_results(\n            results, \n            \"Quotes about Courage and Bravery\",\n            max_text_length=100\n        )\n        ```\n\n    Output Features:\n        - \ud83c\udfa8 Color-coded columns for easy scanning\n        - \ud83d\udcca Relevance scores prominently displayed\n        - \u2702\ufe0f Smart text truncation to maintain readability\n        - \ud83d\udcf1 Responsive layout that works in various terminal sizes\n        - \ud83d\udeab Graceful handling of empty results\n\n    Fallback Behavior:\n        If the Rich library isn't available, automatically falls back to\n        simple text output that works in any environment.\n\n    Use Cases:\n        - Interactive demos and presentations\n        - Development and debugging sessions\n        - Educational tools showing search capabilities\n        - Command-line applications with rich output\n    \"\"\"\n    try:\n        from rich.console import Console\n        from rich.table import Table\n        from rich.text import Text\n\n        console = Console()\n\n        # Create table\n        table = Table(\n            title=f\"\ud83d\udd0d {search_description}\",\n            show_header=True,\n            header_style=\"bold magenta\",\n            border_style=\"blue\",\n            padding=(1, 2)  # Add significant vertical and horizontal padding\n        )\n\n        # Add columns\n        table.add_column(\"#\", style=\"magenta\", width=15, justify=\"center\")\n        table.add_column(\"Score\", style=\"green\", width=20, justify=\"center\")\n        table.add_column(\"Quote\", style=\"bright_white\", width=60)\n        table.add_column(\"Author\", style=\"bold bright_yellow\", width=25)\n        table.add_column(\"Category\", style=\"white\", width=25)\n\n        if not results:\n            table.add_row(\"\", \"\", \"\u274c No results found.\", \"\", \"\")\n            console.print(table)\n            return\n\n        # Add rows\n        for i, result in enumerate(results, 1):\n            content = result.payload.get(\"content\", \"\")\n            author = result.payload.get(\"author\", \"Unknown\")\n            category = result.payload.get(\"category\", \"Unknown\")\n            score = result.score\n\n            # Truncate long quotes for readability\n            display_content = (content if len(content) &lt;= max_text_length \n                             else content[:max_text_length-3] + \"...\")\n\n            # Create styled text for quote\n            quote_text = Text(f'\"{display_content}\"', style=\"italic\")\n\n            table.add_row(\n                str(i),\n                f\"{score:.3f}\",\n                quote_text,\n                author,\n                category\n            )\n\n        # Display table\n        console.print(table)\n        console.print(f\"\ud83d\udcca Found {len(results)} results\", style=\"bold green\")\n\n    except ImportError:\n        # Fallback to simple print if rich is not available\n        logger.warning(\"Rich library not available, falling back to simple display\")\n        self._display_search_results_simple(results, search_description, max_text_length)\n    except Exception as e:\n        logger.error(f\"Failed to display search results: {str(e)}\")\n        # Fallback to simple display\n        self._display_search_results_simple(results, search_description, max_text_length)\n</code></pre>"},{"location":"corpus/Animals/#rag_to_riches.corpus.animals.Animals.format_search_results_for_rag","title":"<code>format_search_results_for_rag(search_results, max_results=5)</code>","text":"<p>Format search results from Animals class for RAG system prompt.</p> <p>Parameters:</p> Name Type Description Default <code>search_results</code> <code>List[ScoredPoint]</code> <p>List of ScoredPoint objects from animals.search()</p> required <code>max_results</code> <code>int</code> <p>Maximum number of results to include</p> <code>5</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted string for RAG context</p> Source code in <code>src/rag_to_riches/corpus/animals.py</code> <pre><code>    @require(lambda search_results: isinstance(search_results, list), \"Search results must be a list\")\n    @require(lambda max_results: isinstance(max_results, int) and max_results &gt; 0,\n             \"Max results must be a positive integer\")\n    def format_search_results_for_rag(self, search_results: List[models.ScoredPoint], \n                                     max_results: int = 5) -&gt; str:\n        \"\"\"Format search results from Animals class for RAG system prompt.\n\n        Args:\n            search_results: List of ScoredPoint objects from animals.search()\n            max_results: Maximum number of results to include\n\n        Returns:\n            Formatted string for RAG context\n        \"\"\"\n        if not search_results:\n            return \"No relevant quotes found for this query.\"\n\n        formatted_results = []\n        for i, result in enumerate(search_results[:max_results], 1):\n            content = result.payload.get(\"content\", \"\")\n            author = result.payload.get(\"author\", \"Unknown\")\n            category = result.payload.get(\"category\", \"Unknown\")\n            score = result.score\n\n            formatted_results.append(f\"\"\"\nQuote {i}: \"{content}\"\nAuthor: {author}\nCategory: {category}\nRelevance Score: {score:.3f}\n\"\"\")\n\n        return \"\\n\".join(formatted_results)\n</code></pre>"},{"location":"corpus/Animals/#rag_to_riches.corpus.animals.Animals.get_collection_stats","title":"<code>get_collection_stats()</code>","text":"<p>Get comprehensive statistics and insights about your quote collection.</p> <p>Provides a detailed overview of your collection's size, content diversity, and database status. Perfect for monitoring, debugging, or presenting collection metrics to users.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary containing detailed statistics:</p> <code>Dict[str, Any]</code> <ul> <li>collection_name: Name of your quote collection</li> </ul> <code>Dict[str, Any]</code> <ul> <li>collection_exists: Whether the database collection exists</li> </ul> <code>Dict[str, Any]</code> <ul> <li>point_count: Total quotes stored in the database</li> </ul> <code>Dict[str, Any]</code> <ul> <li>loaded_quotes: Number of quotes currently loaded in memory</li> </ul> <code>Dict[str, Any]</code> <ul> <li>categories: List of all unique quote categories (sorted)</li> </ul> <code>Dict[str, Any]</code> <ul> <li>authors: List of all unique authors (sorted)</li> </ul> Example <pre><code>stats = animals.get_collection_stats()\n\nprint(f\"Collection: {stats['collection_name']}\")\nprint(f\"Total quotes in database: {stats['point_count']}\")\nprint(f\"Quotes loaded in memory: {stats['loaded_quotes']}\")\nprint(f\"Categories ({len(stats['categories'])}): {stats['categories']}\")\nprint(f\"Authors ({len(stats['authors'])}): {stats['authors'][:5]}...\")\n\n# Check if ready for search\nif stats['collection_exists'] and stats['point_count'] &gt; 0:\n    print(\"\u2705 Ready for semantic search!\")\nelse:\n    print(\"\u274c Need to load and index quotes first\")\n</code></pre> Use Cases <ul> <li>Verify successful data loading and indexing</li> <li>Display collection overview in user interfaces</li> <li>Debug database connectivity issues</li> <li>Monitor collection growth over time</li> <li>Validate data integrity after operations</li> </ul> Source code in <code>src/rag_to_riches/corpus/animals.py</code> <pre><code>def get_collection_stats(self) -&gt; Dict[str, Any]:\n    \"\"\"Get comprehensive statistics and insights about your quote collection.\n\n    Provides a detailed overview of your collection's size, content diversity,\n    and database status. Perfect for monitoring, debugging, or presenting\n    collection metrics to users.\n\n    Returns:\n        Dictionary containing detailed statistics:\n        - collection_name: Name of your quote collection\n        - collection_exists: Whether the database collection exists\n        - point_count: Total quotes stored in the database\n        - loaded_quotes: Number of quotes currently loaded in memory\n        - categories: List of all unique quote categories (sorted)\n        - authors: List of all unique authors (sorted)\n\n    Example:\n        ```python\n        stats = animals.get_collection_stats()\n\n        print(f\"Collection: {stats['collection_name']}\")\n        print(f\"Total quotes in database: {stats['point_count']}\")\n        print(f\"Quotes loaded in memory: {stats['loaded_quotes']}\")\n        print(f\"Categories ({len(stats['categories'])}): {stats['categories']}\")\n        print(f\"Authors ({len(stats['authors'])}): {stats['authors'][:5]}...\")\n\n        # Check if ready for search\n        if stats['collection_exists'] and stats['point_count'] &gt; 0:\n            print(\"\u2705 Ready for semantic search!\")\n        else:\n            print(\"\u274c Need to load and index quotes first\")\n        ```\n\n    Use Cases:\n        - Verify successful data loading and indexing\n        - Display collection overview in user interfaces\n        - Debug database connectivity issues\n        - Monitor collection growth over time\n        - Validate data integrity after operations\n    \"\"\"\n    stats = {\n        \"collection_name\": self.collection_name,\n        \"collection_exists\": self.semantic_search.vector_db.collection_exists(self.collection_name),\n        \"point_count\": 0,\n        \"loaded_quotes\": 0,\n        \"categories\": [],\n        \"authors\": []\n    }\n\n    if stats[\"collection_exists\"]:\n        stats[\"point_count\"] = self.semantic_search.vector_db.count_points(self.collection_name)\n\n    if self.wisdom:\n        stats[\"loaded_quotes\"] = len(self.wisdom)\n        stats[\"categories\"] = self.wisdom.get_categories()\n        stats[\"authors\"] = self.wisdom.get_authors()\n\n    return stats\n</code></pre>"},{"location":"corpus/Animals/#rag_to_riches.corpus.animals.Animals.index_all_quotes","title":"<code>index_all_quotes()</code>","text":"<p>Transform all loaded quotes into searchable vector embeddings.</p> <p>This method takes your loaded quotes and creates high-dimensional vector representations that enable semantic search. The process uses advanced sentence transformers to understand the meaning and context of each quote, not just keyword matching.</p> <p>The indexing process: 1. Extracts text content from each quote 2. Generates semantic embeddings using the configured model 3. Stores vectors in the database with rich metadata 4. Creates searchable points for instant retrieval</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of unique point IDs for each indexed quote. These IDs can be used</p> <code>List[str]</code> <p>for direct retrieval, debugging, or managing specific quotes.</p> <p>Raises:</p> Type Description <code>InvalidPointsError</code> <p>When indexing fails due to embedding errors, database issues, or missing quote data.</p> Example <pre><code># Load quotes first\nwisdom = animals.load_from_jsonl(\"quotes.jsonl\")\n\n# Index for semantic search\npoint_ids = animals.index_all_quotes()\nprint(f\"Successfully indexed {len(point_ids)} quotes\")\n\n# Now you can search semantically\nresults = animals.search(\"loyalty and friendship\")\n</code></pre> Performance Notes <ul> <li>Batch processing is used for efficiency with large collections</li> <li>Indexing time scales with collection size and model complexity</li> <li>Typical speed: ~100-500 quotes per second depending on hardware</li> <li>GPU acceleration automatically used if available</li> </ul> Note <p>You must call load_from_jsonl() before indexing. The method will fail gracefully if no quotes are loaded, providing clear error messages.</p> Source code in <code>src/rag_to_riches/corpus/animals.py</code> <pre><code>@require(lambda self: self.wisdom is not None,\n         \"Animal wisdom must be loaded before indexing\")\ndef index_all_quotes(self) -&gt; List[str]:\n    \"\"\"Transform all loaded quotes into searchable vector embeddings.\n\n    This method takes your loaded quotes and creates high-dimensional vector\n    representations that enable semantic search. The process uses advanced\n    sentence transformers to understand the meaning and context of each quote,\n    not just keyword matching.\n\n    The indexing process:\n    1. Extracts text content from each quote\n    2. Generates semantic embeddings using the configured model\n    3. Stores vectors in the database with rich metadata\n    4. Creates searchable points for instant retrieval\n\n    Returns:\n        List of unique point IDs for each indexed quote. These IDs can be used\n        for direct retrieval, debugging, or managing specific quotes.\n\n    Raises:\n        InvalidPointsError: When indexing fails due to embedding errors,\n            database issues, or missing quote data.\n\n    Example:\n        ```python\n        # Load quotes first\n        wisdom = animals.load_from_jsonl(\"quotes.jsonl\")\n\n        # Index for semantic search\n        point_ids = animals.index_all_quotes()\n        print(f\"Successfully indexed {len(point_ids)} quotes\")\n\n        # Now you can search semantically\n        results = animals.search(\"loyalty and friendship\")\n        ```\n\n    Performance Notes:\n        - Batch processing is used for efficiency with large collections\n        - Indexing time scales with collection size and model complexity\n        - Typical speed: ~100-500 quotes per second depending on hardware\n        - GPU acceleration automatically used if available\n\n    Note:\n        You must call load_from_jsonl() before indexing. The method will\n        fail gracefully if no quotes are loaded, providing clear error messages.\n    \"\"\"\n    if not self.wisdom:\n        raise InvalidPointsError(\n            issue=\"No animal wisdom loaded. Call load_from_jsonl() first.\",\n            points_count=0\n        )\n\n    try:\n        # Prepare texts and metadata for batch indexing\n        texts = [quote.text for quote in self.wisdom.quotes]\n        metadata_list = [quote.to_payload() for quote in self.wisdom.quotes]\n\n        # Use SemanticSearch's batch indexing capability\n        indexed_ids = self.semantic_search.index_all_text(\n            texts=texts,\n            metadata_list=metadata_list\n        )\n\n        logger.info(f\"Successfully indexed {len(indexed_ids)} animal quotes into collection '{self.collection_name}'\")\n        return indexed_ids\n\n    except Exception as e:\n        raise InvalidPointsError(\n            issue=f\"Failed to index animal quotes: {str(e)}\",\n            points_count=len(self.wisdom.quotes) if self.wisdom else 0\n        )\n</code></pre>"},{"location":"corpus/Animals/#rag_to_riches.corpus.animals.Animals.index_single_quote","title":"<code>index_single_quote(quote)</code>","text":"<p>Index a single animal quote.</p> <p>Parameters:</p> Name Type Description Default <code>quote</code> <code>AnimalQuote</code> <p>AnimalQuote instance to index.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Point ID of the indexed quote.</p> Source code in <code>src/rag_to_riches/corpus/animals.py</code> <pre><code>def index_single_quote(self, quote: AnimalQuote) -&gt; str:\n    \"\"\"Index a single animal quote.\n\n    Args:\n        quote: AnimalQuote instance to index.\n\n    Returns:\n        Point ID of the indexed quote.\n    \"\"\"\n    return self.semantic_search.index_text(\n        text=quote.text,\n        metadata=quote.to_payload()\n    )\n</code></pre>"},{"location":"corpus/Animals/#rag_to_riches.corpus.animals.Animals.load_and_index","title":"<code>load_and_index(jsonl_path)</code>","text":"<p>One-step solution: load quotes from file and make them instantly searchable.</p> <p>This convenience method combines loading and indexing in a single call, perfect for getting up and running quickly. It handles the complete pipeline from raw JSONL file to searchable vector database.</p> <p>Parameters:</p> Name Type Description Default <code>jsonl_path</code> <code>Path</code> <p>Path to your JSONL file containing animal quotes.</p> required <p>Returns:</p> Type Description <code>AnimalWisdom</code> <p>A tuple containing:</p> <code>List[str]</code> <ul> <li>AnimalWisdom: Your loaded and validated quote collection</li> </ul> <code>tuple[AnimalWisdom, List[str]]</code> <ul> <li>List[str]: Point IDs for all indexed quotes</li> </ul> Example <pre><code># Complete setup in one line\nwisdom, point_ids = animals.load_and_index(\"my_quotes.jsonl\")\n\nprint(f\"Ready to search {len(wisdom)} quotes!\")\n\n# Immediately start searching\nresults = animals.search(\"courage and bravery\")\n</code></pre> Note <p>This method is equivalent to calling load_from_jsonl() followed by index_all_quotes(), but more convenient for common workflows.</p> Source code in <code>src/rag_to_riches/corpus/animals.py</code> <pre><code>def load_and_index(self, jsonl_path: Path) -&gt; tuple[AnimalWisdom, List[str]]:\n    \"\"\"One-step solution: load quotes from file and make them instantly searchable.\n\n    This convenience method combines loading and indexing in a single call,\n    perfect for getting up and running quickly. It handles the complete\n    pipeline from raw JSONL file to searchable vector database.\n\n    Args:\n        jsonl_path: Path to your JSONL file containing animal quotes.\n\n    Returns:\n        A tuple containing:\n        - AnimalWisdom: Your loaded and validated quote collection\n        - List[str]: Point IDs for all indexed quotes\n\n    Example:\n        ```python\n        # Complete setup in one line\n        wisdom, point_ids = animals.load_and_index(\"my_quotes.jsonl\")\n\n        print(f\"Ready to search {len(wisdom)} quotes!\")\n\n        # Immediately start searching\n        results = animals.search(\"courage and bravery\")\n        ```\n\n    Note:\n        This method is equivalent to calling load_from_jsonl() followed by\n        index_all_quotes(), but more convenient for common workflows.\n    \"\"\"\n    wisdom = self.load_from_jsonl(jsonl_path)\n    point_ids = self.index_all_quotes()\n    return wisdom, point_ids\n</code></pre>"},{"location":"corpus/Animals/#rag_to_riches.corpus.animals.Animals.load_from_jsonl","title":"<code>load_from_jsonl(jsonl_path)</code>","text":"<p>Load and validate animal quotes from a JSONL (JSON Lines) file.</p> <p>Reads a file where each line contains a JSON object with quote data. The method performs comprehensive validation, skips malformed entries with helpful warnings, and returns a structured collection of quotes ready for indexing and search.</p> Expected JSONL Format <p>Each line should be a JSON object with these fields: - \"text\": The actual quote content (required) - \"author\": Who said or wrote the quote (required) - \"category\": Thematic classification like \"Wisdom\", \"Humor\" (required)</p> <p>Parameters:</p> Name Type Description Default <code>jsonl_path</code> <code>Path</code> <p>Path to your JSONL file containing animal quotes. Can be a string path or pathlib.Path object.</p> required <p>Returns:</p> Type Description <code>AnimalWisdom</code> <p>AnimalWisdom object containing all successfully loaded quotes with</p> <code>AnimalWisdom</code> <p>convenient methods for filtering and analysis.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>When the specified file doesn't exist at the given path.</p> <code>InvalidPointsError</code> <p>When no valid quotes are found in the file, indicating format issues or empty content.</p> Example <pre><code># Load quotes from file\nquotes_path = Path(\"data/animal_wisdom.jsonl\")\nwisdom = animals.load_from_jsonl(quotes_path)\n\nprint(f\"Loaded {len(wisdom)} quotes\")\nprint(f\"Categories: {wisdom.get_categories()}\")\nprint(f\"Authors: {wisdom.get_authors()}\")\n\n# Access individual quotes\nfor quote in wisdom.quotes[:3]:\n    print(f'\"{quote.text}\" - {quote.author}')\n</code></pre> File Format Example <pre><code>{\"text\": \"Dogs are not our whole life, but they make our lives whole.\", \"author\": \"Roger Caras\", \"category\": \"Pets and Companionship\"}\n{\"text\": \"The greatness of a nation can be judged by the way its animals are treated.\", \"author\": \"Mahatma Gandhi\", \"category\": \"Ethics and Compassion\"}\n</code></pre> Note <ul> <li>Empty lines in the file are automatically skipped</li> <li>Malformed JSON lines generate warnings but don't stop the process</li> <li>The loaded quotes are stored in self.wisdom for later use</li> <li>All text fields are automatically stripped of whitespace</li> </ul> Source code in <code>src/rag_to_riches/corpus/animals.py</code> <pre><code>@require(lambda jsonl_path: isinstance(jsonl_path, (str, Path)),\n         \"JSONL path must be a string or Path object\")\n@ensure(lambda result: isinstance(result, AnimalWisdom),\n        \"Must return an AnimalWisdom instance\")\ndef load_from_jsonl(self, jsonl_path: Path) -&gt; AnimalWisdom:\n    \"\"\"Load and validate animal quotes from a JSONL (JSON Lines) file.\n\n    Reads a file where each line contains a JSON object with quote data. The method\n    performs comprehensive validation, skips malformed entries with helpful warnings,\n    and returns a structured collection of quotes ready for indexing and search.\n\n    Expected JSONL Format:\n        Each line should be a JSON object with these fields:\n        - \"text\": The actual quote content (required)\n        - \"author\": Who said or wrote the quote (required)  \n        - \"category\": Thematic classification like \"Wisdom\", \"Humor\" (required)\n\n    Args:\n        jsonl_path: Path to your JSONL file containing animal quotes.\n            Can be a string path or pathlib.Path object.\n\n    Returns:\n        AnimalWisdom object containing all successfully loaded quotes with\n        convenient methods for filtering and analysis.\n\n    Raises:\n        FileNotFoundError: When the specified file doesn't exist at the given path.\n        InvalidPointsError: When no valid quotes are found in the file, indicating\n            format issues or empty content.\n\n    Example:\n        ```python\n        # Load quotes from file\n        quotes_path = Path(\"data/animal_wisdom.jsonl\")\n        wisdom = animals.load_from_jsonl(quotes_path)\n\n        print(f\"Loaded {len(wisdom)} quotes\")\n        print(f\"Categories: {wisdom.get_categories()}\")\n        print(f\"Authors: {wisdom.get_authors()}\")\n\n        # Access individual quotes\n        for quote in wisdom.quotes[:3]:\n            print(f'\"{quote.text}\" - {quote.author}')\n        ```\n\n    File Format Example:\n        ```\n        {\"text\": \"Dogs are not our whole life, but they make our lives whole.\", \"author\": \"Roger Caras\", \"category\": \"Pets and Companionship\"}\n        {\"text\": \"The greatness of a nation can be judged by the way its animals are treated.\", \"author\": \"Mahatma Gandhi\", \"category\": \"Ethics and Compassion\"}\n        ```\n\n    Note:\n        - Empty lines in the file are automatically skipped\n        - Malformed JSON lines generate warnings but don't stop the process\n        - The loaded quotes are stored in self.wisdom for later use\n        - All text fields are automatically stripped of whitespace\n    \"\"\"\n    jsonl_path = Path(jsonl_path)\n\n    if not jsonl_path.exists():\n        raise FileNotFoundError(f\"JSONL file not found: {jsonl_path}\")\n\n    try:\n        quotes = []\n        with open(jsonl_path, 'r', encoding='utf-8') as file:\n            for line_num, line in enumerate(file, 1):\n                line = line.strip()\n                if not line:  # Skip empty lines\n                    continue\n\n                try:\n                    data = json.loads(line)\n                    quote = AnimalQuote(**data)\n                    quotes.append(quote)\n                except (json.JSONDecodeError, ValueError) as e:\n                    logger.warning(f\"Skipped invalid line {line_num} in {jsonl_path}: {e}\")\n                    continue\n\n        if not quotes:\n            raise InvalidPointsError(\n                issue=f\"No valid quotes found in {jsonl_path}\",\n                points_count=0\n            )\n\n        self.wisdom = AnimalWisdom(quotes=quotes, source_file=jsonl_path)\n        logger.info(f\"Loaded {len(quotes)} animal quotes from {jsonl_path}\")\n        return self.wisdom\n\n    except Exception as e:\n        raise InvalidPointsError(\n            issue=f\"Failed to load animal quotes from {jsonl_path}: {str(e)}\",\n            points_count=0\n        )\n</code></pre>"},{"location":"corpus/Animals/#rag_to_riches.corpus.animals.Animals.rag","title":"<code>rag(user_query, limit=5, score_threshold=None, author=None, category=None, model='gpt-4o', response_type='structured')</code>","text":"<p>\ud83d\ude80 Complete AI-powered question answering in one powerful method call.</p> <p>This is your one-stop solution for getting intelligent answers about animals. It automatically searches your quote collection, finds the most relevant content, and generates comprehensive AI responses with full transparency into the process.</p> <p>Perfect for building chatbots, educational tools, or research applications where you need both the AI answer and access to the underlying source material.</p> <p>The Complete RAG Pipeline: 1. \ud83d\udd0d Semantic search finds relevant quotes from your collection 2. \ud83d\udcdd Context generation creates optimized prompts for the AI 3. \ud83e\udd16 AI reasoning produces thoughtful, grounded responses 4. \ud83d\udcca Full transparency with all intermediate results returned</p> <p>Parameters:</p> Name Type Description Default <code>user_query</code> <code>str</code> <p>Your question about animals. Use natural, conversational language like \"How do animals show love?\" or \"What can pets teach children about responsibility?\"</p> required <code>limit</code> <code>int</code> <p>Number of quotes to use as context (default: 5). More context can improve answer quality but increases cost and response time.</p> <code>5</code> <code>score_threshold</code> <code>Optional[float]</code> <p>Minimum relevance score for quotes (0.0-1.0). Higher values ensure only highly relevant quotes are used as context.</p> <code>None</code> <code>author</code> <code>Optional[str]</code> <p>Limit context to quotes from this author only. Great for exploring specific perspectives or philosophies.</p> <code>None</code> <code>category</code> <code>Optional[str]</code> <p>Focus on quotes from this category only. Useful for domain- specific questions like \"Ethics\" or \"Pet Care\".</p> <code>None</code> <code>model</code> <code>str</code> <p>OpenAI model for AI responses. \"gpt-4o\" gives the best quality, \"gpt-3.5-turbo\" is faster and more economical.</p> <code>'gpt-4o'</code> <code>response_type</code> <code>str</code> <p>Format of AI response: - \"structured\": Rich AnimalWisdomResponse with insights and follow-ups - \"simple\": Plain text response for basic use cases</p> <code>'structured'</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Complete results dictionary containing:</p> <code>Dict[str, Any]</code> <ul> <li>llm_response: AI answer (structured object or simple string)</li> </ul> <code>Dict[str, Any]</code> <ul> <li>search_results: List of relevant quotes found (with scores)</li> </ul> <code>Dict[str, Any]</code> <ul> <li>rag_context: Full prompt sent to AI (for debugging/transparency)</li> </ul> <code>Dict[str, Any]</code> <ul> <li>query_info: Metadata about the query and processing parameters</li> </ul> <p>Raises:</p> Type Description <code>InvalidPointsError</code> <p>When any step fails (search, context generation, or AI response). Error messages indicate which step failed.</p> Example <pre><code># Complete RAG in one call\nresult = animals.rag(\n    \"What do animals teach us about unconditional love?\",\n    limit=7,\n    score_threshold=0.6,\n    response_type=\"structured\"\n)\n\n# Access the AI response\nai_answer = result[\"llm_response\"]\nprint(\"AI Answer:\", ai_answer.answer)\n\n# See what quotes were used\nquotes_used = result[\"search_results\"]\nprint(f\"Based on {len(quotes_used)} relevant quotes\")\n\n# Inspect the full context (for debugging)\nfull_prompt = result[\"rag_context\"]\n\n# Get query metadata\ninfo = result[\"query_info\"]\nprint(f\"Model: {info['model']}, Results: {info['results_count']}\")\n</code></pre> Advanced Usage <pre><code># Domain-specific question\nethics_result = animals.rag(\n    \"How should humans treat wild animals?\",\n    category=\"Ethics and Compassion\",\n    limit=10\n)\n\n# Author-focused inquiry\ngandhi_result = animals.rag(\n    \"What did Gandhi believe about animals?\",\n    author=\"Mahatma Gandhi\",\n    response_type=\"simple\"\n)\n</code></pre> Use Cases <ul> <li>Educational Q&amp;A systems about animals and nature</li> <li>Research tools for exploring animal-human relationships</li> <li>Content generation for blogs, articles, or presentations</li> <li>Interactive chatbots with grounded, source-backed responses</li> <li>Philosophical exploration of animal wisdom and ethics</li> </ul> Performance Tips <ul> <li>Start with limit=5 for good balance of quality and speed</li> <li>Use score_threshold=0.7+ for highly focused questions</li> <li>Choose \"simple\" response_type for faster, lower-cost interactions</li> <li>Cache results for frequently asked questions</li> </ul> Source code in <code>src/rag_to_riches/corpus/animals.py</code> <pre><code>@require(lambda user_query: isinstance(user_query, str) and len(user_query.strip()) &gt; 0,\n         \"User query must be a non-empty string\")\n@require(lambda limit: isinstance(limit, int) and limit &gt; 0, \"Limit must be a positive integer\")\ndef rag(self, user_query: str, limit: int = 5, \n        score_threshold: Optional[float] = None,\n        author: Optional[str] = None,\n        category: Optional[str] = None,\n        model: str = \"gpt-4o\",\n        response_type: str = \"structured\") -&gt; Dict[str, Any]:\n    \"\"\"\ud83d\ude80 Complete AI-powered question answering in one powerful method call.\n\n    This is your one-stop solution for getting intelligent answers about animals.\n    It automatically searches your quote collection, finds the most relevant content,\n    and generates comprehensive AI responses with full transparency into the process.\n\n    Perfect for building chatbots, educational tools, or research applications where\n    you need both the AI answer and access to the underlying source material.\n\n    The Complete RAG Pipeline:\n    1. \ud83d\udd0d Semantic search finds relevant quotes from your collection\n    2. \ud83d\udcdd Context generation creates optimized prompts for the AI\n    3. \ud83e\udd16 AI reasoning produces thoughtful, grounded responses\n    4. \ud83d\udcca Full transparency with all intermediate results returned\n\n    Args:\n        user_query: Your question about animals. Use natural, conversational\n            language like \"How do animals show love?\" or \"What can pets teach\n            children about responsibility?\"\n        limit: Number of quotes to use as context (default: 5). More context\n            can improve answer quality but increases cost and response time.\n        score_threshold: Minimum relevance score for quotes (0.0-1.0). Higher\n            values ensure only highly relevant quotes are used as context.\n        author: Limit context to quotes from this author only. Great for\n            exploring specific perspectives or philosophies.\n        category: Focus on quotes from this category only. Useful for domain-\n            specific questions like \"Ethics\" or \"Pet Care\".\n        model: OpenAI model for AI responses. \"gpt-4o\" gives the best quality,\n            \"gpt-3.5-turbo\" is faster and more economical.\n        response_type: Format of AI response:\n            - \"structured\": Rich AnimalWisdomResponse with insights and follow-ups\n            - \"simple\": Plain text response for basic use cases\n\n    Returns:\n        Complete results dictionary containing:\n        - llm_response: AI answer (structured object or simple string)\n        - search_results: List of relevant quotes found (with scores)\n        - rag_context: Full prompt sent to AI (for debugging/transparency)\n        - query_info: Metadata about the query and processing parameters\n\n    Raises:\n        InvalidPointsError: When any step fails (search, context generation,\n            or AI response). Error messages indicate which step failed.\n\n    Example:\n        ```python\n        # Complete RAG in one call\n        result = animals.rag(\n            \"What do animals teach us about unconditional love?\",\n            limit=7,\n            score_threshold=0.6,\n            response_type=\"structured\"\n        )\n\n        # Access the AI response\n        ai_answer = result[\"llm_response\"]\n        print(\"AI Answer:\", ai_answer.answer)\n\n        # See what quotes were used\n        quotes_used = result[\"search_results\"]\n        print(f\"Based on {len(quotes_used)} relevant quotes\")\n\n        # Inspect the full context (for debugging)\n        full_prompt = result[\"rag_context\"]\n\n        # Get query metadata\n        info = result[\"query_info\"]\n        print(f\"Model: {info['model']}, Results: {info['results_count']}\")\n        ```\n\n    Advanced Usage:\n        ```python\n        # Domain-specific question\n        ethics_result = animals.rag(\n            \"How should humans treat wild animals?\",\n            category=\"Ethics and Compassion\",\n            limit=10\n        )\n\n        # Author-focused inquiry\n        gandhi_result = animals.rag(\n            \"What did Gandhi believe about animals?\",\n            author=\"Mahatma Gandhi\",\n            response_type=\"simple\"\n        )\n        ```\n\n    Use Cases:\n        - Educational Q&amp;A systems about animals and nature\n        - Research tools for exploring animal-human relationships\n        - Content generation for blogs, articles, or presentations\n        - Interactive chatbots with grounded, source-backed responses\n        - Philosophical exploration of animal wisdom and ethics\n\n    Performance Tips:\n        - Start with limit=5 for good balance of quality and speed\n        - Use score_threshold=0.7+ for highly focused questions\n        - Choose \"simple\" response_type for faster, lower-cost interactions\n        - Cache results for frequently asked questions\n    \"\"\"\n    try:\n        # Step 1: Perform semantic search\n        search_results = self.search(\n            query=user_query,\n            limit=limit,\n            score_threshold=score_threshold,\n            author=author,\n            category=category\n        )\n\n        # Step 2: Generate RAG context\n        rag_context = self.create_rag_context(\n            user_query=user_query,\n            search_results=search_results\n        )\n\n        # Step 3: Get LLM response based on type\n        if response_type.lower() == \"structured\":\n            llm_response = self.ask_llm(\n                user_query=user_query,\n                limit=limit,\n                score_threshold=score_threshold,\n                author=author,\n                category=category,\n                model=model\n            )\n        elif response_type.lower() == \"simple\":\n            llm_response = self.ask_llm_simple(\n                user_query=user_query,\n                limit=limit,\n                model=model\n            )\n        else:\n            raise ValueError(f\"Invalid response_type: {response_type}. Must be 'structured' or 'simple'\")\n\n        # Step 4: Prepare query info\n        query_info = {\n            \"user_query\": user_query,\n            \"limit\": limit,\n            \"score_threshold\": score_threshold,\n            \"author_filter\": author,\n            \"category_filter\": category,\n            \"model\": model,\n            \"response_type\": response_type,\n            \"results_count\": len(search_results)\n        }\n\n        # Step 5: Return complete RAG result\n        result = {\n            \"llm_response\": llm_response,\n            \"search_results\": search_results,\n            \"rag_context\": rag_context,\n            \"query_info\": query_info\n        }\n\n        logger.info(f\"Complete RAG pipeline executed for query: '{user_query[:50]}...' \"\n                   f\"with {len(search_results)} results and {response_type} response\")\n\n        return result\n\n    except Exception as e:\n        logger.error(f\"RAG pipeline failed: {str(e)}\")\n        raise InvalidPointsError(\n            issue=f\"RAG pipeline failed: {str(e)}\",\n            points_count=1\n        )\n</code></pre>"},{"location":"corpus/Animals/#rag_to_riches.corpus.animals.Animals.recreate_collection","title":"<code>recreate_collection()</code>","text":"<p>Completely reset your quote collection with a fresh, empty database.</p> <p>This is a powerful cleanup method that removes all existing quotes and creates a brand new collection. Use this when you need to start over, fix corruption issues, or completely change your quote dataset.</p> <p>What this method does: 1. Safely deletes the existing collection if it exists 2. Creates a new empty collection with optimal settings 3. Clears all loaded quote data from memory 4. Prepares the system for fresh data loading</p> <p>Raises:</p> Type Description <code>InvalidPointsError</code> <p>If the recreation process fails due to database connection issues or permission problems.</p> Example <pre><code># Reset everything and start fresh\nanimals.recreate_collection()\n\n# Now load new data\nnew_wisdom = animals.load_from_jsonl(\"updated_quotes.jsonl\")\nanimals.index_all_quotes()\n</code></pre> Warning <p>This operation is irreversible! All existing quotes in the collection will be permanently deleted. Make sure you have backups of important data before calling this method.</p> Use Cases <ul> <li>Switching to a completely different quote dataset</li> <li>Fixing corrupted vector data</li> <li>Changing embedding models (requires reindexing)</li> <li>Cleaning up test data before production deployment</li> </ul> Source code in <code>src/rag_to_riches/corpus/animals.py</code> <pre><code>def recreate_collection(self) -&gt; None:\n    \"\"\"Completely reset your quote collection with a fresh, empty database.\n\n    This is a powerful cleanup method that removes all existing quotes and\n    creates a brand new collection. Use this when you need to start over,\n    fix corruption issues, or completely change your quote dataset.\n\n    What this method does:\n    1. Safely deletes the existing collection if it exists\n    2. Creates a new empty collection with optimal settings\n    3. Clears all loaded quote data from memory\n    4. Prepares the system for fresh data loading\n\n    Raises:\n        InvalidPointsError: If the recreation process fails due to database\n            connection issues or permission problems.\n\n    Example:\n        ```python\n        # Reset everything and start fresh\n        animals.recreate_collection()\n\n        # Now load new data\n        new_wisdom = animals.load_from_jsonl(\"updated_quotes.jsonl\")\n        animals.index_all_quotes()\n        ```\n\n    Warning:\n        This operation is irreversible! All existing quotes in the collection\n        will be permanently deleted. Make sure you have backups of important\n        data before calling this method.\n\n    Use Cases:\n        - Switching to a completely different quote dataset\n        - Fixing corrupted vector data\n        - Changing embedding models (requires reindexing)\n        - Cleaning up test data before production deployment\n    \"\"\"\n    try:\n        # Delete existing collection if it exists\n        if self.semantic_search.vector_db.collection_exists(self.collection_name):\n            logger.info(f\"Deleting existing collection '{self.collection_name}'\")\n            self.semantic_search.vector_db.delete_collection(self.collection_name)\n\n        # Create new empty collection\n        logger.info(f\"Creating new empty collection '{self.collection_name}'\")\n        self.semantic_search.vector_db.create_collection(\n            collection_name=self.collection_name,\n            vector_size=self.semantic_search.embedder.get_vector_size(),\n            distance=self.semantic_search.embedder.get_distance_metric()\n        )\n\n        # Clear loaded wisdom data\n        self.wisdom = None\n\n        logger.info(f\"Successfully recreated empty collection '{self.collection_name}'\")\n\n    except Exception as e:\n        raise InvalidPointsError(\n            issue=f\"Failed to recreate collection: {str(e)}\",\n            points_count=0\n        )\n</code></pre>"},{"location":"corpus/Animals/#rag_to_riches.corpus.animals.Animals.search","title":"<code>search(query, limit=10, score_threshold=None, author=None, category=None)</code>","text":"<p>Find the most relevant animal quotes using intelligent semantic search.</p> <p>This powerful search method goes beyond simple keyword matching to understand the meaning and context of your query. It finds quotes that are conceptually similar, even if they don't share exact words with your search terms.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Your search question or topic. Use natural language like \"what do animals teach us about love?\" or \"quotes about courage\".</p> required <code>limit</code> <code>int</code> <p>Maximum number of results to return (default: 10). Higher values give more options but may include less relevant results.</p> <code>10</code> <code>score_threshold</code> <code>Optional[float]</code> <p>Minimum similarity score (0.0-1.0). Only quotes with similarity above this threshold will be returned. Use 0.7+ for highly relevant results, 0.5+ for broader matches.</p> <code>None</code> <code>author</code> <code>Optional[str]</code> <p>Filter results to only include quotes by this specific author. Case-insensitive matching (e.g., \"Gandhi\" matches \"Mahatma Gandhi\").</p> <code>None</code> <code>category</code> <code>Optional[str]</code> <p>Filter results to only include quotes from this category. Case-insensitive matching (e.g., \"wisdom\" matches \"Wisdom and Philosophy\").</p> <code>None</code> <p>Returns:</p> Type Description <code>List[ScoredPoint]</code> <p>List of ScoredPoint objects, each containing:</p> <code>List[ScoredPoint]</code> <ul> <li>score: Similarity score (higher = more relevant)</li> </ul> <code>List[ScoredPoint]</code> <ul> <li>payload: Quote metadata (content, author, category)</li> </ul> <code>List[ScoredPoint]</code> <p>Results are automatically sorted by relevance (highest scores first).</p> <p>Raises:</p> Type Description <code>InvalidPointsError</code> <p>When search fails due to database issues or invalid query parameters.</p> Example <pre><code># Basic semantic search\nresults = animals.search(\"loyalty and friendship\")\n\n# Precise search with high threshold\nresults = animals.search(\n    \"courage in difficult times\",\n    limit=5,\n    score_threshold=0.8\n)\n\n# Search within specific author's quotes\ngandhi_quotes = animals.search(\n    \"compassion\",\n    author=\"Mahatma Gandhi\",\n    limit=3\n)\n\n# Browse by category\nwisdom_quotes = animals.search(\n    \"life lessons\",\n    category=\"Wisdom and Philosophy\"\n)\n\n# Process results\nfor result in results:\n    print(f\"Score: {result.score:.3f}\")\n    print(f\"Quote: {result.payload['content']}\")\n    print(f\"Author: {result.payload['author']}\")\n    print(\"---\")\n</code></pre> Search Tips <ul> <li>Use descriptive phrases rather than single keywords</li> <li>Try different phrasings if you don't find what you're looking for</li> <li>Lower the score_threshold to see more diverse results</li> <li>Combine filters to narrow down to specific types of quotes</li> </ul> Performance <ul> <li>Search is typically very fast (&lt; 100ms for most collections)</li> <li>Larger collections may take slightly longer but remain responsive</li> <li>Filtering by author/category happens after vector search for efficiency</li> </ul> Source code in <code>src/rag_to_riches/corpus/animals.py</code> <pre><code>@require(lambda query: isinstance(query, str) and len(query.strip()) &gt; 0,\n         \"Query must be a non-empty string\")\n@require(lambda limit: isinstance(limit, int) and limit &gt; 0,\n         \"Limit must be a positive integer\")\n@require(lambda author: author is None or (isinstance(author, str) and len(author.strip()) &gt; 0),\n         \"Author filter must be None or a non-empty string\")\n@require(lambda category: category is None or (isinstance(category, str) and len(category.strip()) &gt; 0),\n         \"Category filter must be None or a non-empty string\")\n@ensure(lambda result: isinstance(result, list), \"Must return a list\")\ndef search(self, query: str, limit: int = 10, \n          score_threshold: Optional[float] = None,\n          author: Optional[str] = None,\n          category: Optional[str] = None) -&gt; List[models.ScoredPoint]:\n    \"\"\"Find the most relevant animal quotes using intelligent semantic search.\n\n    This powerful search method goes beyond simple keyword matching to understand\n    the meaning and context of your query. It finds quotes that are conceptually\n    similar, even if they don't share exact words with your search terms.\n\n    Args:\n        query: Your search question or topic. Use natural language like\n            \"what do animals teach us about love?\" or \"quotes about courage\".\n        limit: Maximum number of results to return (default: 10).\n            Higher values give more options but may include less relevant results.\n        score_threshold: Minimum similarity score (0.0-1.0). Only quotes with\n            similarity above this threshold will be returned. Use 0.7+ for\n            highly relevant results, 0.5+ for broader matches.\n        author: Filter results to only include quotes by this specific author.\n            Case-insensitive matching (e.g., \"Gandhi\" matches \"Mahatma Gandhi\").\n        category: Filter results to only include quotes from this category.\n            Case-insensitive matching (e.g., \"wisdom\" matches \"Wisdom and Philosophy\").\n\n    Returns:\n        List of ScoredPoint objects, each containing:\n        - score: Similarity score (higher = more relevant)\n        - payload: Quote metadata (content, author, category)\n        Results are automatically sorted by relevance (highest scores first).\n\n    Raises:\n        InvalidPointsError: When search fails due to database issues or\n            invalid query parameters.\n\n    Example:\n        ```python\n        # Basic semantic search\n        results = animals.search(\"loyalty and friendship\")\n\n        # Precise search with high threshold\n        results = animals.search(\n            \"courage in difficult times\",\n            limit=5,\n            score_threshold=0.8\n        )\n\n        # Search within specific author's quotes\n        gandhi_quotes = animals.search(\n            \"compassion\",\n            author=\"Mahatma Gandhi\",\n            limit=3\n        )\n\n        # Browse by category\n        wisdom_quotes = animals.search(\n            \"life lessons\",\n            category=\"Wisdom and Philosophy\"\n        )\n\n        # Process results\n        for result in results:\n            print(f\"Score: {result.score:.3f}\")\n            print(f\"Quote: {result.payload['content']}\")\n            print(f\"Author: {result.payload['author']}\")\n            print(\"---\")\n        ```\n\n    Search Tips:\n        - Use descriptive phrases rather than single keywords\n        - Try different phrasings if you don't find what you're looking for\n        - Lower the score_threshold to see more diverse results\n        - Combine filters to narrow down to specific types of quotes\n\n    Performance:\n        - Search is typically very fast (&lt; 100ms for most collections)\n        - Larger collections may take slightly longer but remain responsive\n        - Filtering by author/category happens after vector search for efficiency\n    \"\"\"\n    try:\n        # Use SemanticSearch for the core search functionality\n        # Request more results than needed to allow for filtering\n        search_limit = limit * 3 if (author or category) else limit\n\n        initial_results = self.semantic_search.search_with_text(\n            query_text=query.strip(),\n            limit=search_limit,\n            score_threshold=score_threshold\n        )\n\n        # Apply metadata filters if specified\n        filtered_results = self._apply_metadata_filters(\n            results=initial_results,\n            author_filter=author,\n            category_filter=category\n        )\n\n        # Limit to requested number of results\n        final_results = filtered_results[:limit]\n\n        logger.info(f\"Animal quotes search for '{query[:50]}...' returned {len(final_results)} results\"\n                   f\"{' (filtered by author)' if author else ''}\"\n                   f\"{' (filtered by category)' if category else ''}\")\n\n        return final_results\n\n    except Exception as e:\n        raise InvalidPointsError(\n            issue=f\"Failed to search animal quotes: {str(e)}\",\n            points_count=1\n        )\n</code></pre>"},{"location":"corpus/Animals/#rag_to_riches.corpus.animals.Animals.search_and_create_rag_context","title":"<code>search_and_create_rag_context(user_query, limit=5, score_threshold=None, author=None, category=None, system_prompt=None)</code>","text":"<p>Search for quotes and create RAG context in one convenient method.</p> <p>Parameters:</p> Name Type Description Default <code>user_query</code> <code>str</code> <p>The user's question</p> required <code>limit</code> <code>int</code> <p>Maximum number of search results to include</p> <code>5</code> <code>score_threshold</code> <code>Optional[float]</code> <p>Minimum similarity score threshold</p> <code>None</code> <code>author</code> <code>Optional[str]</code> <p>Optional filter to only return quotes by this author</p> <code>None</code> <code>category</code> <code>Optional[str]</code> <p>Optional filter to only return quotes in this category</p> <code>None</code> <code>system_prompt</code> <code>Optional[str]</code> <p>System prompt to use (defaults to comprehensive prompt)</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>Complete RAG context string</p> Source code in <code>src/rag_to_riches/corpus/animals.py</code> <pre><code>@require(lambda user_query: isinstance(user_query, str) and len(user_query.strip()) &gt; 0,\n         \"User query must be a non-empty string\")\n@require(lambda limit: isinstance(limit, int) and limit &gt; 0, \"Limit must be a positive integer\")\ndef search_and_create_rag_context(self, user_query: str, limit: int = 5,\n                                score_threshold: Optional[float] = None,\n                                author: Optional[str] = None,\n                                category: Optional[str] = None,\n                                system_prompt: Optional[str] = None) -&gt; str:\n    \"\"\"Search for quotes and create RAG context in one convenient method.\n\n    Args:\n        user_query: The user's question\n        limit: Maximum number of search results to include\n        score_threshold: Minimum similarity score threshold\n        author: Optional filter to only return quotes by this author\n        category: Optional filter to only return quotes in this category\n        system_prompt: System prompt to use (defaults to comprehensive prompt)\n\n    Returns:\n        Complete RAG context string\n    \"\"\"\n    # Search for relevant quotes\n    search_results = self.search(\n        query=user_query,\n        limit=limit,\n        score_threshold=score_threshold,\n        author=author,\n        category=category\n    )\n\n    # Create RAG context\n    return self.create_rag_context(user_query, search_results, system_prompt)\n</code></pre>"},{"location":"examples/","title":"Examples Package","text":""},{"location":"examples/#overview","title":"Overview","text":"<p>The <code>examples</code> package provides comprehensive, real-world demonstrations of the RAG to Riches framework. This package contains complete, runnable examples that showcase different aspects of building production-ready RAG systems, from simple usage patterns to advanced implementations.</p>"},{"location":"examples/#key-components","title":"Key Components","text":""},{"location":"examples/#simple-rag-usage","title":"Simple RAG Usage","text":"<p>File: <code>simple_rag_usage.py</code></p> <p>A straightforward demonstration of basic RAG functionality, perfect for understanding core concepts and getting started quickly.</p>"},{"location":"examples/#rag-context-demo","title":"RAG Context Demo","text":"<p>File: <code>rag_context_demo.py</code></p> <p>An advanced example showing how to manage and optimize context in RAG systems, including context windowing, relevance filtering, and context assembly strategies.</p>"},{"location":"examples/#rag-facade-demo","title":"RAG Facade Demo","text":"<p>File: <code>rag_facade_demo.py</code></p> <p>A comprehensive demonstration of the Facade pattern implementation, showing how to create simplified interfaces for complex RAG pipelines.</p>"},{"location":"examples/#rag-with-animals-example","title":"RAG with Animals Example","text":"<p>File: <code>rag_with_animals_example.py</code></p> <p>A complete, domain-specific example using the animal quotes corpus, demonstrating how to build specialized RAG systems for particular domains.</p>"},{"location":"examples/#architecture","title":"Architecture","text":"graph TB     subgraph \"Example Types\"         Simple[Simple RAG UsageBasic Concepts]         Context[Context ManagementAdvanced Retrieval]         Facade[Facade PatternClean Interfaces]         Domain[Domain-SpecificAnimals Example]     end      subgraph \"Learning Path\"         Simple --&gt; Context         Context --&gt; Facade         Facade --&gt; Domain     end      subgraph \"Core Components Used\"         VectorDB[Vector Database]         Search[Semantic Search]         LLM[Language Models]         Corpus[Domain Corpus]     end      Simple --&gt; VectorDB     Context --&gt; Search     Facade --&gt; LLM     Domain --&gt; Corpus      style Simple fill:#e1f5fe     style Context fill:#f3e5f5     style Facade fill:#e8f5e8     style Domain fill:#fff3e0"},{"location":"examples/#getting-started","title":"Getting Started","text":""},{"location":"examples/#running-the-examples","title":"Running the Examples","text":"<p>All examples are designed to be runnable out-of-the-box with minimal setup:</p> <pre><code># Navigate to the project root\ncd rag_to_riches\n\n# Run simple RAG example\npython src/rag_to_riches/examples/simple_rag_usage.py\n\n# Run context management demo\npython src/rag_to_riches/examples/rag_context_demo.py\n\n# Run facade pattern demo\npython src/rag_to_riches/examples/rag_facade_demo.py\n\n# Run animals domain example\npython src/rag_to_riches/examples/rag_with_animals_example.py\n</code></pre>"},{"location":"examples/#prerequisites","title":"Prerequisites","text":"<p>Ensure you have the required environment setup:</p> <pre><code># Install dependencies\nuv sync\n\n# Set up environment variables (copy from sample.env)\ncp sample.env .env\n# Edit .env with your API keys\n\n# Verify setup\npython -c \"from rag_to_riches import __version__; print(f'RAG to Riches v{__version__}')\"\n</code></pre>"},{"location":"examples/#example-walkthroughs","title":"Example Walkthroughs","text":""},{"location":"examples/#simple-rag-usage-example","title":"Simple RAG Usage Example","text":"<p>This example demonstrates the most basic RAG pipeline:</p> <pre><code>from rag_to_riches.start_simply.basic_rag import BasicRAG\nfrom pathlib import Path\n\ndef main():\n    \"\"\"Simple demonstration of RAG functionality.\"\"\"\n\n    # Initialize RAG system\n    rag = BasicRAG(collection_name=\"simple_demo\")\n\n    # Sample documents\n    documents = [\n        \"The Earth orbits around the Sun in approximately 365.25 days.\",\n        \"Python is a high-level programming language known for its simplicity.\",\n        \"Machine learning algorithms can identify patterns in large datasets.\",\n        \"The human brain contains approximately 86 billion neurons.\"\n    ]\n\n    # Add documents to the system\n    print(\"\ud83d\udcda Indexing documents...\")\n    rag.add_documents(documents)\n    print(f\"\u2705 Indexed {len(documents)} documents\")\n\n    # Perform searches and generate answers\n    queries = [\n        \"How long does Earth take to orbit the Sun?\",\n        \"What programming language is known for simplicity?\",\n        \"How many neurons are in the human brain?\"\n    ]\n\n    for query in queries:\n        print(f\"\\n\u2753 Query: {query}\")\n        answer = rag.ask(query)\n        print(f\"\ud83d\udca1 Answer: {answer}\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Key Learning Points: - Basic RAG initialization - Document indexing workflow - Simple query-answer pattern - Understanding retrieval + generation</p>"},{"location":"examples/#context-management-demo","title":"Context Management Demo","text":"<p>This advanced example shows sophisticated context handling:</p> <pre><code>from rag_to_riches.search.semantic_search import SemanticSearch\nfrom rag_to_riches.vectordb.embedded_vectordb import EmbeddedVectorDB\nimport openai\n\ndef demonstrate_context_management():\n    \"\"\"Advanced context management techniques.\"\"\"\n\n    # Initialize components\n    vector_db = EmbeddedVectorDB()\n    search_engine = SemanticSearch(vector_db, collection_name=\"context_demo\")\n\n    # Load extensive document collection\n    documents = load_large_document_collection()  # Your loading function\n    search_engine.index_documents(documents)\n\n    # Context optimization strategies\n    def optimize_context(query: str, max_tokens: int = 2000):\n        \"\"\"Demonstrate context optimization techniques.\"\"\"\n\n        # Strategy 1: Relevance-based filtering\n        initial_results = search_engine.search(query, limit=20)\n        high_relevance = [r for r in initial_results if r['score'] &gt; 0.7]\n\n        # Strategy 2: Diversity sampling\n        diverse_results = select_diverse_documents(high_relevance)\n\n        # Strategy 3: Token-aware assembly\n        context = assemble_context_within_limits(diverse_results, max_tokens)\n\n        return context\n\n    # Demonstrate different context strategies\n    query = \"What are the environmental impacts of renewable energy?\"\n\n    # Basic context\n    basic_context = search_engine.search(query, limit=3)\n    print(\"\ud83d\udcc4 Basic context (3 documents):\")\n    display_context(basic_context)\n\n    # Optimized context\n    optimized_context = optimize_context(query)\n    print(\"\\n\ud83c\udfaf Optimized context:\")\n    display_context(optimized_context)\n\n    # Generate answers with different contexts\n    basic_answer = generate_answer(query, basic_context)\n    optimized_answer = generate_answer(query, optimized_context)\n\n    print(f\"\\n\ud83d\udca1 Basic Answer: {basic_answer}\")\n    print(f\"\ud83d\ude80 Optimized Answer: {optimized_answer}\")\n</code></pre> <p>Key Learning Points: - Context relevance filtering - Document diversity sampling - Token-aware context assembly - Comparing context strategies</p>"},{"location":"examples/#facade-pattern-demo","title":"Facade Pattern Demo","text":"<p>Shows how to create clean, simple interfaces for complex RAG systems:</p> <pre><code>from rag_to_riches.corpus.animals import Animals\nfrom rag_to_riches.vectordb.embedded_vectordb import EmbeddedVectorDB\n\nclass RAGFacade:\n    \"\"\"Simplified interface for complex RAG operations.\"\"\"\n\n    def __init__(self, domain: str = \"general\"):\n        \"\"\"Initialize RAG system for specific domain.\"\"\"\n        self.vector_db = EmbeddedVectorDB()\n\n        if domain == \"animals\":\n            self.corpus = Animals(self.vector_db, collection_name=\"animals_facade\")\n        else:\n            # Initialize general-purpose corpus\n            self.corpus = self._initialize_general_corpus()\n\n    def quick_setup(self, data_source: str):\n        \"\"\"One-line setup for RAG system.\"\"\"\n        print(\"\ud83d\udd27 Setting up RAG system...\")\n\n        # Automatic data loading and indexing\n        if data_source.endswith('.jsonl'):\n            self.corpus.load_and_index(Path(data_source))\n        elif data_source.endswith('.txt'):\n            self._load_text_file(data_source)\n        else:\n            raise ValueError(f\"Unsupported data source: {data_source}\")\n\n        print(\"\u2705 RAG system ready!\")\n\n    def ask(self, question: str) -&gt; str:\n        \"\"\"Simple question-answering interface.\"\"\"\n        return self.corpus.rag(question, response_type=\"conversational\")\n\n    def explore(self, topic: str, num_examples: int = 3):\n        \"\"\"Explore a topic with examples.\"\"\"\n        results = self.corpus.search(topic, limit=num_examples)\n        self.corpus.display_search_results(results, f\"Exploring: {topic}\")\n        return results\n\n    def get_insights(self, query: str) -&gt; dict:\n        \"\"\"Get structured insights about a query.\"\"\"\n        return self.corpus.rag(query, response_type=\"structured\")\n\ndef main():\n    \"\"\"Demonstrate the facade pattern.\"\"\"\n\n    # One-line setup\n    rag = RAGFacade(domain=\"animals\")\n    rag.quick_setup(\"data/corpus/animals/animals.jsonl\")\n\n    # Simple interactions\n    answer = rag.ask(\"What do elephants teach us about memory?\")\n    print(f\"\ud83d\udca1 {answer}\")\n\n    # Topic exploration\n    examples = rag.explore(\"wisdom about friendship\")\n\n    # Structured insights\n    insights = rag.get_insights(\"How do animals show courage?\")\n    print(f\"\ud83e\udde0 Insights: {insights}\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Key Learning Points: - Facade pattern implementation - Simplified API design - Domain-specific customization - Progressive feature exposure</p>"},{"location":"examples/#animals-domain-example","title":"Animals Domain Example","text":"<p>Complete domain-specific implementation using the animal quotes corpus:</p> <pre><code>from rag_to_riches.corpus.animals import Animals\nfrom rag_to_riches.vectordb.embedded_vectordb import EmbeddedVectorDB\nfrom pathlib import Path\nimport rich\n\ndef build_animal_wisdom_assistant():\n    \"\"\"Build a specialized assistant for animal wisdom.\"\"\"\n\n    # Initialize components\n    vector_db = EmbeddedVectorDB()\n    animals = Animals(vector_db, collection_name=\"wisdom_assistant\")\n\n    # Load the animal quotes corpus\n    quotes_file = Path(\"data/corpus/animals/animals.jsonl\")\n    print(\"\ud83d\udcd6 Loading animal wisdom corpus...\")\n\n    wisdom_data, point_ids = animals.load_and_index(quotes_file)\n    print(f\"\u2705 Loaded {len(wisdom_data)} pieces of animal wisdom\")\n\n    # Display corpus statistics\n    animals.display_collection_info()\n\n    return animals\n\ndef interactive_wisdom_session(animals: Animals):\n    \"\"\"Interactive session for exploring animal wisdom.\"\"\"\n\n    print(\"\\n\ud83d\udc3e Welcome to the Animal Wisdom Assistant!\")\n    print(\"Ask questions about what animals can teach us.\\n\")\n\n    sample_queries = [\n        \"What do cats teach us about independence?\",\n        \"How do wolves demonstrate leadership?\",\n        \"What wisdom do elephants offer about memory?\",\n        \"How do birds inspire us about freedom?\",\n        \"What can dogs teach us about loyalty?\"\n    ]\n\n    print(\"\ud83d\udca1 Try these example questions:\")\n    for i, query in enumerate(sample_queries, 1):\n        print(f\"  {i}. {query}\")\n    print()\n\n    while True:\n        user_query = input(\"\ud83e\udd14 Your question (or 'quit' to exit): \").strip()\n\n        if user_query.lower() in ['quit', 'exit', 'q']:\n            print(\"\ud83d\udc4b Thank you for exploring animal wisdom!\")\n            break\n\n        if not user_query:\n            continue\n\n        # Perform RAG query\n        print(f\"\\n\ud83d\udd0d Searching for wisdom about: {user_query}\")\n\n        # Show retrieved context\n        search_results = animals.search(user_query, limit=3)\n        animals.display_search_results(search_results, \"Relevant Wisdom\")\n\n        # Generate AI response\n        response = animals.ask_llm(user_query)\n        animals.display_llm_response(response, user_query)\n\n        print(\"\\n\" + \"=\"*60 + \"\\n\")\n\ndef demonstrate_advanced_features(animals: Animals):\n    \"\"\"Show advanced features of the animals corpus.\"\"\"\n\n    print(\"\ud83d\ude80 Advanced Features Demonstration\\n\")\n\n    # 1. Structured responses\n    print(\"1\ufe0f\u20e3 Structured Response:\")\n    structured = animals.rag(\n        \"What are the key lessons about courage from animals?\",\n        response_type=\"structured\"\n    )\n    rich.print(structured)\n\n    # 2. Batch processing\n    print(\"\\n2\ufe0f\u20e3 Batch Processing:\")\n    questions = [\n        \"wisdom about patience\",\n        \"lessons about courage\", \n        \"teachings about friendship\"\n    ]\n\n    for question in questions:\n        results = animals.search(question, limit=2)\n        print(f\"\ud83d\udcdd {question.title()}: {len(results)} results found\")\n\n    # 3. Metadata filtering (if available)\n    print(\"\\n3\ufe0f\u20e3 Filtering by Animal Type:\")\n    cat_wisdom = animals.search(\n        \"independence and self-reliance\",\n        limit=5,\n        metadata_filter={\"animal_type\": \"cat\"}  # If this field exists\n    )\n\n    if cat_wisdom:\n        print(f\"\ud83d\udc31 Found {len(cat_wisdom)} cat-specific wisdom quotes\")\n\n    # 4. Context analysis\n    print(\"\\n4\ufe0f\u20e3 Context Analysis:\")\n    analysis = animals.analyze_corpus_themes()\n    if analysis:\n        print(f\"\ud83d\udcca Main themes: {', '.join(analysis.get('themes', []))}\")\n\ndef main():\n    \"\"\"Main execution function.\"\"\"\n\n    try:\n        # Build the assistant\n        animals = build_animal_wisdom_assistant()\n\n        # Demonstrate features\n        demonstrate_advanced_features(animals)\n\n        # Interactive session\n        interactive_wisdom_session(animals)\n\n    except Exception as e:\n        print(f\"\u274c Error: {e}\")\n        print(\"Make sure you have the animal quotes data file and API keys configured.\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Key Learning Points: - Domain-specific corpus usage - Interactive RAG applications - Advanced feature demonstration - Production-ready error handling</p>"},{"location":"examples/#example-categories","title":"Example Categories","text":""},{"location":"examples/#educational-examples","title":"\ud83d\udcda Educational Examples","text":"<p>Perfect for learning and understanding concepts:</p> <ul> <li>simple_rag_usage.py: Basic concepts and workflow</li> <li>context_management_basics.py: Understanding retrieval</li> <li>generation_patterns.py: LLM integration patterns</li> </ul>"},{"location":"examples/#architectural-examples","title":"\ud83c\udfd7\ufe0f Architectural Examples","text":"<p>Demonstrate design patterns and architecture:</p> <ul> <li>rag_facade_demo.py: Facade pattern implementation</li> <li>component_integration.py: How components work together</li> <li>scalability_patterns.py: Building for scale</li> </ul>"},{"location":"examples/#domain-specific-examples","title":"\ud83c\udfaf Domain-Specific Examples","text":"<p>Real-world, specialized applications:</p> <ul> <li>rag_with_animals_example.py: Animal wisdom domain</li> <li>legal_document_rag.py: Legal document analysis</li> <li>technical_documentation_rag.py: Technical support system</li> </ul>"},{"location":"examples/#performance-examples","title":"\u26a1 Performance Examples","text":"<p>Optimization and production readiness:</p> <ul> <li>batch_processing_demo.py: Efficient batch operations</li> <li>caching_strategies.py: Performance optimization</li> <li>memory_management.py: Resource optimization</li> </ul>"},{"location":"examples/#usage-patterns","title":"Usage Patterns","text":""},{"location":"examples/#development-workflow","title":"Development Workflow","text":"<ol> <li>Start Simple: Begin with <code>simple_rag_usage.py</code></li> <li>Add Complexity: Move to context and facade examples  </li> <li>Specialize: Adapt patterns for your domain</li> <li>Optimize: Apply performance examples for production</li> </ol>"},{"location":"examples/#customization-guide","title":"Customization Guide","text":"<p>Each example includes customization points:</p> <pre><code># Configuration customization\nCONFIG = {\n    'model_name': 'gpt-4',  # Change LLM model\n    'embedding_model': 'all-MiniLM-L6-v2',  # Change embeddings\n    'collection_name': 'my_custom_collection',  # Custom collection\n    'max_context_length': 2000,  # Adjust context size\n    'temperature': 0.7  # Control creativity\n}\n\n# Data source customization\nDATA_SOURCES = {\n    'jsonl_files': ['my_data.jsonl'],\n    'text_files': ['documents.txt'],\n    'directories': [Path('my_docs/')],\n    'apis': ['custom_api_endpoint']\n}\n\n# Feature customization\nFEATURES = {\n    'enable_caching': True,\n    'use_metadata_filtering': True,\n    'enable_batch_processing': True,\n    'rich_display': True\n}\n</code></pre>"},{"location":"examples/#integration-patterns","title":"Integration Patterns","text":"<p>Examples show how to integrate with existing systems:</p> <pre><code># Web application integration\nfrom flask import Flask, request, jsonify\n\napp = Flask(__name__)\nrag_system = initialize_rag_from_example()\n\n@app.route('/ask', methods=['POST'])\ndef ask_question():\n    query = request.json.get('question')\n    answer = rag_system.ask(query)\n    return jsonify({'answer': answer})\n\n# API service integration\nimport fastapi\n\napp = fastapi.FastAPI()\nrag_facade = RAGFacade.from_example_config()\n\n@app.post(\"/query\")\nasync def process_query(query: str):\n    return await rag_facade.async_ask(query)\n\n# Batch processing integration\nfrom celery import Celery\n\ncelery_app = Celery('rag_worker')\n\n@celery_app.task\ndef process_document_batch(documents):\n    return batch_process_example(documents)\n</code></pre>"},{"location":"examples/#troubleshooting-examples","title":"Troubleshooting Examples","text":""},{"location":"examples/#common-issues-and-solutions","title":"Common Issues and Solutions","text":"<p>Each example includes error handling and troubleshooting:</p> <pre><code>def safe_example_execution():\n    \"\"\"Example with comprehensive error handling.\"\"\"\n\n    try:\n        # Initialize RAG system\n        rag = setup_rag_system()\n\n    except ImportError as e:\n        print(f\"\u274c Missing dependency: {e}\")\n        print(\"\ud83d\udca1 Run: uv sync\")\n        return\n\n    except FileNotFoundError as e:\n        print(f\"\u274c Data file not found: {e}\")\n        print(\"\ud83d\udca1 Check data/ directory and file paths\")\n        return\n\n    except Exception as e:\n        print(f\"\u274c Setup error: {e}\")\n        print(\"\ud83d\udca1 Check your .env file and API keys\")\n        return\n\n    # Continue with example...\n</code></pre>"},{"location":"examples/#performance-debugging","title":"Performance Debugging","text":"<p>Examples include performance monitoring:</p> <pre><code>import time\nfrom contextlib import contextmanager\n\n@contextmanager\ndef timing_context(operation_name):\n    \"\"\"Time operations for performance analysis.\"\"\"\n    start = time.time()\n    yield\n    duration = time.time() - start\n    print(f\"\u23f1\ufe0f {operation_name}: {duration:.2f}s\")\n\n# Usage in examples\nwith timing_context(\"Document indexing\"):\n    rag.index_documents(documents)\n\nwith timing_context(\"Search query\"):\n    results = rag.search(query)\n</code></pre>"},{"location":"examples/#related-components","title":"Related Components","text":"<ul> <li><code>start_simply/</code>: Basic RAG implementation used in examples</li> <li><code>corpus/</code>: Domain-specific corpus used in animal examples</li> <li><code>search/</code>: Advanced search features demonstrated</li> <li><code>vectordb/</code>: Vector database operations shown in examples</li> </ul> <p>Part of the RAG to Riches framework - learn by example, build with confidence. </p>"},{"location":"exceptions/","title":"Exceptions Package","text":""},{"location":"exceptions/#overview","title":"Overview","text":"<p>The <code>exceptions</code> package provides a comprehensive, hierarchical exception system for the RAG to Riches framework. This package implements custom exceptions that provide clear, actionable error messages and enable robust error handling throughout the application.</p>"},{"location":"exceptions/#key-components","title":"Key Components","text":""},{"location":"exceptions/#exception-hierarchy","title":"Exception Hierarchy","text":"<p>File: <code>exceptions.py</code></p> <p>The exceptions package defines a well-structured hierarchy of custom exceptions that help identify and handle different types of errors that can occur during RAG operations.</p>"},{"location":"exceptions/#base-exception-classes","title":"Base Exception Classes","text":"<ul> <li><code>RAGException</code>: Base exception for all RAG-related errors</li> <li><code>ValidationError</code>: For input validation failures</li> <li><code>DatabaseError</code>: For vector database operation failures</li> <li><code>SearchError</code>: For semantic search operation failures</li> <li><code>EmbeddingError</code>: For text embedding operation failures</li> <li><code>LLMError</code>: For language model interaction failures</li> </ul>"},{"location":"exceptions/#specialized-exception-classes","title":"Specialized Exception Classes","text":"<ul> <li><code>CollectionNotFoundError</code>: When a vector collection doesn't exist</li> <li><code>InvalidQueryError</code>: For malformed or invalid search queries</li> <li><code>InsufficientDataError</code>: When not enough data is available for operations</li> <li><code>ConfigurationError</code>: For configuration and setup issues</li> <li><code>AuthenticationError</code>: For API key and authentication failures</li> </ul>"},{"location":"exceptions/#architecture","title":"Architecture","text":"graph TB     subgraph \"Exception Hierarchy\"         RAGException[RAGExceptionBase Exception]          RAGException --&gt; ValidationError         RAGException --&gt; DatabaseError         RAGException --&gt; SearchError         RAGException --&gt; EmbeddingError         RAGException --&gt; LLMError          DatabaseError --&gt; CollectionNotFoundError         SearchError --&gt; InvalidQueryError         ValidationError --&gt; InsufficientDataError         RAGException --&gt; ConfigurationError         LLMError --&gt; AuthenticationError     end      style RAGException fill:#e1f5fe     style ValidationError fill:#f3e5f5     style DatabaseError fill:#e8f5e8     style SearchError fill:#fff3e0"},{"location":"exceptions/#features","title":"Features","text":""},{"location":"exceptions/#design-by-contract-integration","title":"Design by Contract Integration","text":"<p>The exceptions package integrates seamlessly with the project's Design-by-Contract approach:</p> <ul> <li>Pre-condition Violations: Clear exceptions when input requirements aren't met</li> <li>Post-condition Failures: Exceptions when expected outputs can't be generated</li> <li>Invariant Violations: Exceptions when object state becomes invalid</li> <li>Fail-Fast Behavior: Immediate exception raising prevents error propagation</li> </ul>"},{"location":"exceptions/#rich-error-information","title":"Rich Error Information","text":"<p>Each exception provides comprehensive error context:</p> <ul> <li>Descriptive Messages: Clear, human-readable error descriptions</li> <li>Error Codes: Structured error identification for programmatic handling</li> <li>Context Data: Relevant data and state information when the error occurred</li> <li>Suggestions: Actionable recommendations for resolving the issue</li> </ul>"},{"location":"exceptions/#exception-chaining","title":"Exception Chaining","text":"<p>Proper exception chaining preserves the full error context:</p> <pre><code>try:\n    # Some vector database operation\n    result = vector_db.search(query)\nexcept QdrantError as e:\n    raise DatabaseError(\"Vector search failed\") from e\n</code></pre>"},{"location":"exceptions/#usage-examples","title":"Usage Examples","text":""},{"location":"exceptions/#basic-exception-handling","title":"Basic Exception Handling","text":"<pre><code>from rag_to_riches.exceptions import (\n    RAGException, \n    CollectionNotFoundError,\n    InvalidQueryError\n)\n\ntry:\n    # Perform RAG operations\n    results = animals.search(\"some query\")\nexcept CollectionNotFoundError as e:\n    print(f\"Collection setup required: {e}\")\n    # Handle collection creation\nexcept InvalidQueryError as e:\n    print(f\"Query validation failed: {e}\")\n    # Handle query refinement\nexcept RAGException as e:\n    print(f\"General RAG error: {e}\")\n    # Handle general errors\n</code></pre>"},{"location":"exceptions/#exception-with-context","title":"Exception with Context","text":"<pre><code>from rag_to_riches.exceptions import InsufficientDataError\n\ndef validate_corpus_size(corpus):\n    if len(corpus) &lt; 10:\n        raise InsufficientDataError(\n            \"Corpus too small for reliable search\",\n            min_required=10,\n            actual_size=len(corpus),\n            suggestion=\"Add more documents to improve search quality\"\n        )\n</code></pre>"},{"location":"exceptions/#custom-exception-handling","title":"Custom Exception Handling","text":"<pre><code>from rag_to_riches.exceptions import ValidationError\n\ndef safe_rag_operation(query: str):\n    try:\n        if not query.strip():\n            raise ValidationError(\"Query cannot be empty\")\n\n        return perform_rag(query)\n\n    except ValidationError:\n        return {\"error\": \"Invalid input\", \"results\": []}\n    except Exception as e:\n        logger.error(f\"Unexpected error: {e}\")\n        return {\"error\": \"Internal error\", \"results\": []}\n</code></pre>"},{"location":"exceptions/#integration-with-logging","title":"Integration with Logging","text":"<p>The exceptions package integrates with the project's logging system:</p> <pre><code>import logging\nfrom rag_to_riches.exceptions import DatabaseError\n\nlogger = logging.getLogger(__name__)\n\ntry:\n    # Database operation\n    pass\nexcept DatabaseError as e:\n    logger.error(f\"Database operation failed: {e}\", exc_info=True)\n    raise\n</code></pre>"},{"location":"exceptions/#exception-guidelines","title":"Exception Guidelines","text":""},{"location":"exceptions/#when-to-use-custom-exceptions","title":"When to Use Custom Exceptions","text":"<ol> <li>Domain-Specific Errors: Use custom exceptions for RAG-specific error conditions</li> <li>Error Classification: Use the hierarchy to classify errors by type and severity</li> <li>Error Recovery: Use specific exceptions to enable targeted error recovery</li> <li>User Communication: Use descriptive messages for user-facing error communication</li> </ol>"},{"location":"exceptions/#best-practices","title":"Best Practices","text":"<ul> <li>Specific over General: Use the most specific exception type available</li> <li>Context Preservation: Always include relevant context in exception messages</li> <li>Exception Chaining: Use <code>from</code> clause to preserve original exception context</li> <li>Early Validation: Validate inputs early and raise appropriate validation errors</li> <li>Graceful Degradation: Handle exceptions gracefully where possible</li> </ul>"},{"location":"exceptions/#error-handling-patterns","title":"Error Handling Patterns","text":""},{"location":"exceptions/#validation-pattern","title":"Validation Pattern","text":"<pre><code>from rag_to_riches.exceptions import ValidationError\n\ndef validate_search_params(query: str, limit: int):\n    if not query or not query.strip():\n        raise ValidationError(\"Search query cannot be empty\")\n\n    if limit &lt;= 0 or limit &gt; 100:\n        raise ValidationError(\n            f\"Limit must be between 1 and 100, got {limit}\"\n        )\n</code></pre>"},{"location":"exceptions/#resource-management-pattern","title":"Resource Management Pattern","text":"<pre><code>from rag_to_riches.exceptions import DatabaseError\n\ndef safe_database_operation():\n    try:\n        with vector_db.transaction():\n            # Perform database operations\n            return result\n    except Exception as e:\n        raise DatabaseError(\"Database transaction failed\") from e\n</code></pre>"},{"location":"exceptions/#related-components","title":"Related Components","text":"<ul> <li><code>utils/</code>: Logging configuration works with exception handling</li> <li><code>vectordb/</code>: Database exceptions for vector operations</li> <li><code>search/</code>: Search exceptions for semantic search failures</li> <li><code>corpus/</code>: Validation exceptions for data model integrity</li> </ul> <p>Part of the RAG to Riches framework - robust error handling for reliable applications. </p>"},{"location":"notebooks/examples/lesson-1/","title":"Lesson 1","text":"<pre><code>%run supportvectors-common.ipynb\n</code></pre>    \u00a9 SupportVectors. All rights reserved. This notebook is the intellectual property of SupportVectors, and part of its training material.  Only the participants in SupportVectors workshops are allowed to study the notebooks for educational purposes currently, but is prohibited from copying or using it for any other purposes without written permission.  <p> These notebooks are chapters and sections from Asif Qamar's textbook that he is writing on Data Science. So we request you to not circulate the material to others.</p> <pre>\n<code>\ud83c\udfaf Project root: /Users/asifqamar/github/rag_to_riches\n\ud83d\udcc1 Working directory: /Users/asifqamar/github/rag_to_riches\n\u2705 Ready to import rag_to_riches modules!\n</code>\n</pre> <pre><code># Import required modules\nfrom pathlib import Path\nimport json\nfrom rag_to_riches.corpus.animals import AnimalQuote, AnimalWisdom, Animals\nfrom rag_to_riches.vectordb.embedded_vectordb import EmbeddedVectorDB\nfrom rag_to_riches.vectordb.embedder import SimpleTextEmbedder\n\nprint(\"\ud83d\udc3e Modules imported successfully!\")\nprint(\"\ud83d\udcc1 Current working directory:\", Path.cwd())\n</code></pre> <pre>\n<code>WARNING:root:No configuration file specified. Trying the default location\nWARNING:root:Loading configuration from /Users/asifqamar/github/rag_to_riches/config.yaml if it exists\n</code>\n</pre> <pre>\n<code>\ud83d\udc3e Modules imported successfully!\n\ud83d\udcc1 Current working directory: /Users/asifqamar/github/rag_to_riches\n</code>\n</pre> <pre><code># \ud83d\ude80 Initialize Shared Components (Vector Database &amp;amp; Embedder)\n# ============================================================================\n# We initialize these components ONCE at the beginning to avoid database lock issues\n# and reuse them throughout the notebook for efficiency and consistency.\n\nprint(\"\ud83d\udd27 Initializing Shared Components for the Entire Notebook\")\nprint(\"=\" * 60)\n\n# Initialize Vector Database (shared instance)\nprint(\"1\ufe0f\u20e3 Initializing Vector Database (Qdrant)...\")\nvector_db = EmbeddedVectorDB()\nprint(\"   \u2705 Vector database connected and ready for reuse\")\n\n# Initialize Text Embedder (shared instance)  \nprint(\"\\n2\ufe0f\u20e3 Initializing Text Embedder (Sentence Transformers)...\")\nembedder = SimpleTextEmbedder(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\nprint(f\"   \u2705 Embedder loaded: {embedder.model_name}\")\nprint(f\"   \ud83d\udcd0 Vector dimensions: {embedder.get_vector_size()}\")\nprint(f\"   \ud83d\udccf Distance metric: {embedder.get_distance_metric()}\")\n\nprint(\"\\n\ud83c\udfaf Shared components ready! These will be reused throughout the notebook.\")\nprint(\"\ud83d\udca1 This prevents database lock issues and improves performance.\")\n\n# Set the data path\njsonl_path = Path(\"data/corpus/animals/animals.jsonl\")\n\nprint(\"\\n\ud83d\udcdd Note: If you encounter a database lock error, restart the notebook kernel.\")\nprint(\"   This ensures a clean start and releases any existing database connections.\")\n</code></pre> <pre>\n<code>2025-06-28 12:44:47 | INFO     | rag_to_riches.vectordb.embedded_vectordb:__init__:58 - Connected to embedded vector database at qdrant_db\n</code>\n</pre> <pre>\n<code>\ud83d\udd27 Initializing Shared Components for the Entire Notebook\n============================================================\n1\ufe0f\u20e3 Initializing Vector Database (Qdrant)...\n   \u2705 Vector database connected and ready for reuse\n\n2\ufe0f\u20e3 Initializing Text Embedder (Sentence Transformers)...\n</code>\n</pre> <pre>\n<code>2025-06-28 12:44:48 | INFO     | rag_to_riches.vectordb.embedder:__init__:115 - Initialized SimpleTextEmbedder with model 'sentence-transformers/all-MiniLM-L6-v2', vector size: 384\n</code>\n</pre> <pre>\n<code>   \u2705 Embedder loaded: sentence-transformers/all-MiniLM-L6-v2\n   \ud83d\udcd0 Vector dimensions: 384\n   \ud83d\udccf Distance metric: Cosine\n\n\ud83c\udfaf Shared components ready! These will be reused throughout the notebook.\n\ud83d\udca1 This prevents database lock issues and improves performance.\n\n\ud83d\udcdd Note: If you encounter a database lock error, restart the notebook kernel.\n   This ensures a clean start and releases any existing database connections.\n</code>\n</pre> <pre><code># Let's examine the structure of our animal quotes data\nprint(f\"\ud83d\udcc2 Reading from: {jsonl_path}\")\nprint(f\"\ud83d\udcc4 File exists: {jsonl_path.exists()}\")\n</code></pre> <pre>\n<code>\ud83d\udcc2 Reading from: data/corpus/animals/animals.jsonl\n\ud83d\udcc4 File exists: True\n</code>\n</pre> <pre><code># \ud83d\udcda Load and Index Animal Quotes Using Shared Components\nprint(\"\ud83d\udd27 Creating Animals corpus loader using shared components...\")\nanimals_loader = Animals(\n    vector_db=vector_db,  # Reusing shared vector_db instance\n    embedder=embedder,    # Reusing shared embedder instance\n)\n\nanimals_loader.recreate_collection()\n\nprint(\"\ud83d\udcca Loading and indexing animal quotes...\")\nwisdom, point_ids = animals_loader.load_and_index(jsonl_path)\n</code></pre> <pre>\n<code>2025-06-28 12:44:48 | INFO     | rag_to_riches.vectordb.embedded_vectordb:_ensure_existing_collection_matches:469 - Collection 'animals' exists with correct parameters\n2025-06-28 12:44:48 | INFO     | rag_to_riches.vectordb.embedded_vectordb:get_collection_info:295 - Retrieved info for collection 'animals'\n2025-06-28 12:44:48 | INFO     | rag_to_riches.search.semantic_search:consistency_check:233 - Consistency check passed for collection 'animals'\n2025-06-28 12:44:48 | INFO     | rag_to_riches.search.semantic_search:__init__:182 - Initialized SemanticSearch for collection 'animals' with SimpleTextEmbedder\n2025-06-28 12:44:48 | INFO     | rag_to_riches.corpus.animals:__init__:208 - Initialized Animals corpus loader for collection 'animals'\n2025-06-28 12:44:48 | INFO     | rag_to_riches.corpus.animals:recreate_collection:336 - Deleting existing collection 'animals'\n2025-06-28 12:44:48 | INFO     | rag_to_riches.vectordb.embedded_vectordb:delete_collection:185 - Deleted collection 'animals'\n2025-06-28 12:44:48 | INFO     | rag_to_riches.corpus.animals:recreate_collection:340 - Creating new empty collection 'animals'\n2025-06-28 12:44:48 | INFO     | rag_to_riches.vectordb.embedded_vectordb:create_collection:154 - Created collection 'animals' with vector size 384\n2025-06-28 12:44:48 | INFO     | rag_to_riches.corpus.animals:recreate_collection:350 - Successfully recreated empty collection 'animals'\n2025-06-28 12:44:48 | INFO     | rag_to_riches.corpus.animals:load_from_jsonl:268 - Loaded 100 animal quotes from data/corpus/animals/animals.jsonl\n</code>\n</pre> <pre>\n<code>\ud83d\udd27 Creating Animals corpus loader using shared components...\n\ud83d\udcca Loading and indexing animal quotes...\n</code>\n</pre> <pre>\n<code>2025-06-28 12:44:49 | INFO     | rag_to_riches.vectordb.embedded_vectordb:upsert_points:450 - Upserted 100 points to collection 'animals'\n2025-06-28 12:44:49 | INFO     | rag_to_riches.search.semantic_search:index_all_text:457 - Indexed 100 texts into collection 'animals'\n2025-06-28 12:44:49 | INFO     | rag_to_riches.corpus.animals:index_all_quotes:311 - Successfully indexed 100 animal quotes into collection 'animals'\n</code>\n</pre> <pre><code># Display information about what was loaded and indexed\nprint(f\"\u2705 Successfully loaded and indexed animal quotes!\")\nprint(f\"\ud83d\udcca Loaded {len(wisdom)} quotes from {wisdom.source_file}\")\nprint(f\"\ud83d\udd17 Indexed {len(point_ids)} points into collection '{animals_loader.collection_name}'\")\n\n# Show some statistics\nstats = animals_loader.get_collection_stats()\nprint(f\"\\n\ud83d\udcc8 Collection Statistics:\")\nprint(f\"   \u2022 Collection Name: {stats['collection_name']}\")\nprint(f\"   \u2022 Points in Database: {stats['point_count']}\")\nprint(f\"   \u2022 Unique Categories: {len(stats['categories'])}\")\nprint(f\"   \u2022 Unique Authors: {len(stats['authors'])}\")\n\nprint(f\"\\n\ud83c\udff7\ufe0f Sample Categories: {', '.join(stats['categories'][:3])}...\")\nprint(f\"\u270d\ufe0f Sample Authors: {', '.join(stats['authors'][:5])}...\")\n\nprint(f\"\\n\ud83c\udfaf Ready for semantic search!\")\n</code></pre> <pre>\n<code>2025-06-28 12:44:49 | INFO     | rag_to_riches.vectordb.embedded_vectordb:count_points:105 - Collection 'animals' contains 100 points\n</code>\n</pre> <pre>\n<code>\u2705 Successfully loaded and indexed animal quotes!\n\ud83d\udcca Loaded 100 quotes from data/corpus/animals/animals.jsonl\n\ud83d\udd17 Indexed 100 points into collection 'animals'\n\n\ud83d\udcc8 Collection Statistics:\n   \u2022 Collection Name: animals\n   \u2022 Points in Database: 100\n   \u2022 Unique Categories: 20\n   \u2022 Unique Authors: 85\n\n\ud83c\udff7\ufe0f Sample Categories: Animal Morality, Animals as Reflections, Animals in Narrative...\n\u270d\ufe0f Sample Authors: A.A. Milne, A.P.J. Abdul Kalam, Abraham Lincoln, African proverb, Albert Schweitzer...\n\n\ud83c\udfaf Ready for semantic search!\n</code>\n</pre> <pre><code># Helper function to display search results nicely\ndef display_search_results(results, search_description, max_text_length=120):\n    \"\"\"Display search results in a formatted way.\"\"\"\n    print(f\"\\n\ud83d\udd0d {search_description}\")\n    print(\"=\" * len(f\"\ud83d\udd0d {search_description}\"))\n\n    if not results:\n        print(\"   \u274c No results found.\")\n        return\n\n    print(f\"   \ud83d\udcca Found {len(results)} results\")\n    print()\n\n    for i, result in enumerate(results, 1):\n        content = result.payload.get(\"content\", \"\")\n        author = result.payload.get(\"author\", \"Unknown\")\n        category = result.payload.get(\"category\", \"Unknown\")\n\n        # Truncate long quotes for readability\n        display_content = content if len(content) &amp;lt;= max_text_length else content[:max_text_length-3] + \"...\"\n\n        print(f\"   {i}. \ud83d\udcca Score: {result.score:.3f}\")\n        print(f\"      \ud83d\udcac Quote: \\\"{display_content}\\\"\")\n        print(f\"      \u270d\ufe0f  Author: {author}\")\n        print(f\"      \ud83c\udff7\ufe0f  Category: {category}\")\n        print()\n\nprint(\"\ud83d\udee0\ufe0f Search helper function defined!\")\n</code></pre> <pre>\n<code>\ud83d\udee0\ufe0f Search helper function defined!\n</code>\n</pre> <pre><code># Example 1: Basic Semantic Search - The Power of Meaning\nprint(\"\ud83c\udfaf EXAMPLE 0: Basic Semantic Search\")\nprint(\"=\" * 50)\nprint(\"Query: 'a friendship with animals'\")\n\n\nresults = animals_loader.search(\"a friendship with animals\", limit=4)\ndisplay_search_results(results, \"Basic Semantic Search Results\")\n</code></pre> <pre>\n<code>2025-06-28 12:44:49 | INFO     | rag_to_riches.vectordb.embedded_vectordb:search_points:413 - Found 4 points in collection 'animals'\n2025-06-28 12:44:49 | INFO     | rag_to_riches.search.semantic_search:search_with_text:347 - Text search for 'a friendship with animals...' returned 4 results\n2025-06-28 12:44:49 | INFO     | rag_to_riches.corpus.animals:search:426 - Animal quotes search for 'a friendship with animals...' returned 4 results\n</code>\n</pre> <pre>\n<code>\ud83c\udfaf EXAMPLE 0: Basic Semantic Search\n==================================================\nQuery: 'a friendship with animals'\n\n\ud83d\udd0d Basic Semantic Search Results\n===============================\n   \ud83d\udcca Found 4 results\n\n   1. \ud83d\udcca Score: 0.625\n      \ud83d\udcac Quote: \"Animals are such agreeable friends\u2014they ask no questions; they pass no criticisms.\"\n      \u270d\ufe0f  Author: George Eliot\n      \ud83c\udff7\ufe0f  Category: Famous Literary Passages\n\n   2. \ud83d\udcca Score: 0.586\n      \ud83d\udcac Quote: \"The best thing about animals is that they don't talk much.\"\n      \u270d\ufe0f  Author: Thornton Wilder\n      \ud83c\udff7\ufe0f  Category: Famous Literary Passages\n\n   3. \ud83d\udcca Score: 0.548\n      \ud83d\udcac Quote: \"Some people talk to animals. Not many listen though. That's the problem.\"\n      \u270d\ufe0f  Author: A.A. Milne\n      \ud83c\udff7\ufe0f  Category: Proverbs and Sayings\n\n   4. \ud83d\udcca Score: 0.535\n      \ud83d\udcac Quote: \"Animals are reliable, many full of love, true in their affections, predictable in their actions, grateful and loyal. ...\"\n      \u270d\ufe0f  Author: Alfred A. Montapert\n      \ud83c\udff7\ufe0f  Category: Reflections and Lessons\n\n</code>\n</pre> <pre><code># Example 1: Basic Semantic Search - The Power of Meaning\nprint(\"\ud83c\udfaf EXAMPLE 1: Basic Semantic Search\")\nprint(\"=\" * 50)\nprint(\"Query: 'loyal companions and friendship'\")\nprint(\"\ud83d\udd0d This should find quotes about loyalty, friendship, and companionship\")\nprint(\"   even if they don't contain these exact words!\")\n\nresults = animals_loader.search(\"loyal companions and friendship\", limit=4)\ndisplay_search_results(results, \"Basic Semantic Search Results\")\n</code></pre> <pre>\n<code>2025-06-28 12:44:49 | INFO     | rag_to_riches.vectordb.embedded_vectordb:search_points:413 - Found 4 points in collection 'animals'\n2025-06-28 12:44:49 | INFO     | rag_to_riches.search.semantic_search:search_with_text:347 - Text search for 'loyal companions and friendship...' returned 4 results\n2025-06-28 12:44:49 | INFO     | rag_to_riches.corpus.animals:search:426 - Animal quotes search for 'loyal companions and friendship...' returned 4 results\n</code>\n</pre> <pre>\n<code>\ud83c\udfaf EXAMPLE 1: Basic Semantic Search\n==================================================\nQuery: 'loyal companions and friendship'\n\ud83d\udd0d This should find quotes about loyalty, friendship, and companionship\n   even if they don't contain these exact words!\n\n\ud83d\udd0d Basic Semantic Search Results\n===============================\n   \ud83d\udcca Found 4 results\n\n   1. \ud83d\udcca Score: 0.476\n      \ud83d\udcac Quote: \"If you want loyalty, get a dog. If you want loyalty and attention, get a smart dog.\"\n      \u270d\ufe0f  Author: Grant Fairley\n      \ud83c\udff7\ufe0f  Category: Animal Morality\n\n   2. \ud83d\udcca Score: 0.428\n      \ud83d\udcac Quote: \"Animals are reliable, many full of love, true in their affections, predictable in their actions, grateful and loyal. ...\"\n      \u270d\ufe0f  Author: Alfred A. Montapert\n      \ud83c\udff7\ufe0f  Category: Reflections and Lessons\n\n   3. \ud83d\udcca Score: 0.368\n      \ud83d\udcac Quote: \"Animals share with us the privilege of having a soul.\"\n      \u270d\ufe0f  Author: Pythagoras\n      \ud83c\udff7\ufe0f  Category: Literary and Poetic Imagery\n\n   4. \ud83d\udcca Score: 0.359\n      \ud83d\udcac Quote: \"Animals are such agreeable friends\u2014they ask no questions; they pass no criticisms.\"\n      \u270d\ufe0f  Author: George Eliot\n      \ud83c\udff7\ufe0f  Category: Famous Literary Passages\n\n</code>\n</pre> <pre><code># Example 2: Concept-Based Search - Abstract Ideas\nprint(\"\ud83c\udfaf EXAMPLE 2: Concept-Based Search\")\nprint(\"=\" * 50)\nprint(\"Query: 'wisdom and life lessons'\")\nprint(\"\ud83d\udd0d Searching for philosophical insights and wisdom\")\nprint(\"   Notice how we find deep concepts, not just keyword matches!\")\n\nresults = animals_loader.search(\"wisdom and life lessons\", limit=4)\ndisplay_search_results(results, \"Concept-Based Search Results\")\n</code></pre> <pre>\n<code>2025-06-28 12:44:49 | INFO     | rag_to_riches.vectordb.embedded_vectordb:search_points:413 - Found 4 points in collection 'animals'\n2025-06-28 12:44:49 | INFO     | rag_to_riches.search.semantic_search:search_with_text:347 - Text search for 'wisdom and life lessons...' returned 4 results\n2025-06-28 12:44:49 | INFO     | rag_to_riches.corpus.animals:search:426 - Animal quotes search for 'wisdom and life lessons...' returned 4 results\n</code>\n</pre> <pre>\n<code>\ud83c\udfaf EXAMPLE 2: Concept-Based Search\n==================================================\nQuery: 'wisdom and life lessons'\n\ud83d\udd0d Searching for philosophical insights and wisdom\n   Notice how we find deep concepts, not just keyword matches!\n\n\ud83d\udd0d Concept-Based Search Results\n==============================\n   \ud83d\udcca Found 4 results\n\n   1. \ud83d\udcca Score: 0.297\n      \ud83d\udcac Quote: \"Animals share with us the privilege of having a soul.\"\n      \u270d\ufe0f  Author: Pythagoras\n      \ud83c\udff7\ufe0f  Category: Literary and Poetic Imagery\n\n   2. \ud83d\udcca Score: 0.296\n      \ud83d\udcac Quote: \"To my mind, the life of a lamb is no less precious than that of a human being.\"\n      \u270d\ufe0f  Author: Mahatma Gandhi\n      \ud83c\udff7\ufe0f  Category: Literary Masterpieces\n\n   3. \ud83d\udcca Score: 0.293\n      \ud83d\udcac Quote: \"Hold fast to dreams, for if dreams die, life is a broken-winged bird that cannot fly.\"\n      \u270d\ufe0f  Author: Langston Hughes\n      \ud83c\udff7\ufe0f  Category: Symbolism and Allegory\n\n   4. \ud83d\udcca Score: 0.288\n      \ud83d\udcac Quote: \"Dogs teach us a very important lesson in life: The mailman is not to be trusted.\"\n      \u270d\ufe0f  Author: Sian Ford\n      \ud83c\udff7\ufe0f  Category: Literary Masterpieces\n\n</code>\n</pre> <pre><code># Example 3: Emotional Search - Finding Feelings\nprint(\"\ud83c\udfaf EXAMPLE 3: Emotional Search\")\nprint(\"=\" * 50)\nprint(\"Query: 'sadness and loss'\")\nprint(\"\ud83d\udd0d Searching for quotes that deal with sad emotions\")\nprint(\"   Semantic search can understand emotional concepts!\")\n\nresults = animals_loader.search(\"sadness and loss\", limit=4)\ndisplay_search_results(results, \"Emotional Search Results\")\n</code></pre> <pre>\n<code>2025-06-28 12:44:49 | INFO     | rag_to_riches.vectordb.embedded_vectordb:search_points:413 - Found 4 points in collection 'animals'\n2025-06-28 12:44:49 | INFO     | rag_to_riches.search.semantic_search:search_with_text:347 - Text search for 'sadness and loss...' returned 4 results\n2025-06-28 12:44:49 | INFO     | rag_to_riches.corpus.animals:search:426 - Animal quotes search for 'sadness and loss...' returned 4 results\n</code>\n</pre> <pre>\n<code>\ud83c\udfaf EXAMPLE 3: Emotional Search\n==================================================\nQuery: 'sadness and loss'\n\ud83d\udd0d Searching for quotes that deal with sad emotions\n   Semantic search can understand emotional concepts!\n\n\ud83d\udd0d Emotional Search Results\n==========================\n   \ud83d\udcca Found 4 results\n\n   1. \ud83d\udcca Score: 0.472\n      \ud83d\udcac Quote: \"There are two means of refuge from the misery of life\u2014music and cats.\"\n      \u270d\ufe0f  Author: Albert Schweitzer\n      \ud83c\udff7\ufe0f  Category: Powerful Analogies\n\n   2. \ud83d\udcca Score: 0.462\n      \ud83d\udcac Quote: \"Like a bird singing in the rain, let grateful memories survive in time of sorrow.\"\n      \u270d\ufe0f  Author: Robert Louis Stevenson\n      \ud83c\udff7\ufe0f  Category: Symbolism and Allegory\n\n   3. \ud83d\udcca Score: 0.342\n      \ud83d\udcac Quote: \"Until one has loved an animal, a part of one's soul remains unawakened.\"\n      \u270d\ufe0f  Author: Anatole France\n      \ud83c\udff7\ufe0f  Category: Wisdom and Philosophy\n\n   4. \ud83d\udcca Score: 0.342\n      \ud83d\udcac Quote: \"Until one has loved an animal, a part of one's soul remains unawakened.\"\n      \u270d\ufe0f  Author: Anatole France\n      \ud83c\udff7\ufe0f  Category: Famous Literary Passages\n\n</code>\n</pre> <pre><code># Example 4: Filtered Search - Author-Specific\nprint(\"\ud83c\udfaf EXAMPLE 4: Author-Filtered Search\")\nprint(\"=\" * 50)\nprint(\"Query: 'animals' filtered by author: 'Mark Twain'\")\nprint(\"\ud83d\udd0d This combines semantic search with metadata filtering\")\nprint(\"   We're looking for Mark Twain's thoughts on animals specifically\")\n\nresults = animals_loader.search(\"animals\", limit=4, author=\"Mark Twain\")\ndisplay_search_results(results, \"Author-Filtered Search Results\")\n\n# Let's also try a different author\nprint(\"\\n\" + \"\ud83c\udfaf BONUS: Same query, different author\")\nprint(\"Query: 'animals' filtered by author: 'Albert Schweitzer'\")\n\nresults = animals_loader.search(\"animals\", limit=3, author=\"Albert Schweitzer\")\ndisplay_search_results(results, \"Albert Schweitzer's Animal Quotes\")\n</code></pre> <pre>\n<code>2025-06-28 12:44:49 | INFO     | rag_to_riches.vectordb.embedded_vectordb:search_points:413 - Found 12 points in collection 'animals'\n2025-06-28 12:44:49 | INFO     | rag_to_riches.search.semantic_search:search_with_text:347 - Text search for 'animals...' returned 12 results\n2025-06-28 12:44:49 | INFO     | rag_to_riches.corpus.animals:search:426 - Animal quotes search for 'animals...' returned 1 results (filtered by author)\n2025-06-28 12:44:49 | INFO     | rag_to_riches.vectordb.embedded_vectordb:search_points:413 - Found 9 points in collection 'animals'\n2025-06-28 12:44:49 | INFO     | rag_to_riches.search.semantic_search:search_with_text:347 - Text search for 'animals...' returned 9 results\n2025-06-28 12:44:49 | INFO     | rag_to_riches.corpus.animals:search:426 - Animal quotes search for 'animals...' returned 0 results (filtered by author)\n</code>\n</pre> <pre>\n<code>\ud83c\udfaf EXAMPLE 4: Author-Filtered Search\n==================================================\nQuery: 'animals' filtered by author: 'Mark Twain'\n\ud83d\udd0d This combines semantic search with metadata filtering\n   We're looking for Mark Twain's thoughts on animals specifically\n\n\ud83d\udd0d Author-Filtered Search Results\n================================\n   \ud83d\udcca Found 1 results\n\n   1. \ud83d\udcca Score: 0.459\n      \ud83d\udcac Quote: \"If animals could speak, the dog would be a blundering outspoken fellow; but the cat would have the rare grace of neve...\"\n      \u270d\ufe0f  Author: Mark Twain\n      \ud83c\udff7\ufe0f  Category: Literary and Poetic Imagery\n\n\n\ud83c\udfaf BONUS: Same query, different author\nQuery: 'animals' filtered by author: 'Albert Schweitzer'\n\n\ud83d\udd0d Albert Schweitzer's Animal Quotes\n===================================\n   \u274c No results found.\n</code>\n</pre> <pre><code># Example 5: Category-Filtered Search\nprint(\"\ud83c\udfaf EXAMPLE 5: Category-Filtered Search\")\nprint(\"=\" * 50)\nprint(\"Query: 'love and compassion' in category: 'Wisdom and Philosophy'\")\nprint(\"\ud83d\udd0d Finding philosophical quotes about love and compassion\")\n\nresults = animals_loader.search(\"love and compassion\", limit=4, category=\"Wisdom and Philosophy\")\ndisplay_search_results(results, \"Philosophy Category Search Results\")\n\n# Let's see what categories we have available\nprint(f\"\\n\ud83d\udcda Available categories in our corpus:\")\nall_categories = animals_loader.get_collection_stats()['categories']\nfor i, category in enumerate(sorted(all_categories), 1):\n    print(f\"   {i:2d}. {category}\")\n    if i &amp;gt;= 10:  # Show first 10 categories\n        print(f\"   ... and {len(all_categories) - 10} more\")\n        break\n</code></pre> <pre>\n<code>2025-06-28 12:44:49 | INFO     | rag_to_riches.vectordb.embedded_vectordb:search_points:413 - Found 12 points in collection 'animals'\n2025-06-28 12:44:49 | INFO     | rag_to_riches.search.semantic_search:search_with_text:347 - Text search for 'love and compassion...' returned 12 results\n2025-06-28 12:44:49 | INFO     | rag_to_riches.corpus.animals:search:426 - Animal quotes search for 'love and compassion...' returned 1 results (filtered by category)\n2025-06-28 12:44:49 | INFO     | rag_to_riches.vectordb.embedded_vectordb:count_points:105 - Collection 'animals' contains 100 points\n</code>\n</pre> <pre>\n<code>\ud83c\udfaf EXAMPLE 5: Category-Filtered Search\n==================================================\nQuery: 'love and compassion' in category: 'Wisdom and Philosophy'\n\ud83d\udd0d Finding philosophical quotes about love and compassion\n\n\ud83d\udd0d Philosophy Category Search Results\n====================================\n   \ud83d\udcca Found 1 results\n\n   1. \ud83d\udcca Score: 0.398\n      \ud83d\udcac Quote: \"Until one has loved an animal, a part of one's soul remains unawakened.\"\n      \u270d\ufe0f  Author: Anatole France\n      \ud83c\udff7\ufe0f  Category: Wisdom and Philosophy\n\n\n\ud83d\udcda Available categories in our corpus:\n    1. Animal Morality\n    2. Animals as Reflections\n    3. Animals in Narrative\n    4. Evocative Descriptions\n    5. Famous Literary Passages\n    6. Humorous Quotes\n    7. Humorous Yet Profound\n    8. Insightful Observations\n    9. Literary Classics\n   10. Literary Masterpieces\n   ... and 10 more\n</code>\n</pre> <pre><code># Example 6: High-Confidence Search with Score Threshold\nprint(\"\ud83c\udfaf EXAMPLE 6: High-Confidence Search\")\nprint(\"=\" * 50)\nprint(\"Query: 'faithful dogs' with score threshold &amp;gt; 0.6\")\nprint(\"\ud83d\udd0d Only returning results with high semantic similarity\")\nprint(\"   This filters out loosely related results\")\n\nresults = animals_loader.search(\"faithful dogs\", limit=5, score_threshold=0.6)\ndisplay_search_results(results, \"High-Confidence Search Results\")\n\n# Compare with no threshold\nprint(\"\\n\ud83d\udd04 COMPARISON: Same query without score threshold\")\nresults_all = animals_loader.search(\"faithful dogs\", limit=5)\ndisplay_search_results(results_all, \"All Results (No Threshold)\")\n\nprint(f\"\\n\ud83d\udcca Insight: Threshold filtering removed {len(results_all) - len(results)} lower-quality results\")\n</code></pre> <pre>\n<code>2025-06-28 12:44:49 | INFO     | rag_to_riches.vectordb.embedded_vectordb:search_points:413 - Found 0 points in collection 'animals'\n2025-06-28 12:44:49 | INFO     | rag_to_riches.search.semantic_search:search_with_text:347 - Text search for 'faithful dogs...' returned 0 results\n2025-06-28 12:44:49 | INFO     | rag_to_riches.corpus.animals:search:426 - Animal quotes search for 'faithful dogs...' returned 0 results\n2025-06-28 12:44:49 | INFO     | rag_to_riches.vectordb.embedded_vectordb:search_points:413 - Found 5 points in collection 'animals'\n2025-06-28 12:44:49 | INFO     | rag_to_riches.search.semantic_search:search_with_text:347 - Text search for 'faithful dogs...' returned 5 results\n2025-06-28 12:44:49 | INFO     | rag_to_riches.corpus.animals:search:426 - Animal quotes search for 'faithful dogs...' returned 5 results\n</code>\n</pre> <pre>\n<code>\ud83c\udfaf EXAMPLE 6: High-Confidence Search\n==================================================\nQuery: 'faithful dogs' with score threshold &gt; 0.6\n\ud83d\udd0d Only returning results with high semantic similarity\n   This filters out loosely related results\n\n\ud83d\udd0d High-Confidence Search Results\n================================\n   \u274c No results found.\n\n\ud83d\udd04 COMPARISON: Same query without score threshold\n\n\ud83d\udd0d All Results (No Threshold)\n============================\n   \ud83d\udcca Found 5 results\n\n   1. \ud83d\udcca Score: 0.513\n      \ud83d\udcac Quote: \"Dogs are our link to paradise.\"\n      \u270d\ufe0f  Author: Milan Kundera\n      \ud83c\udff7\ufe0f  Category: Proverbs and Sayings\n\n   2. \ud83d\udcca Score: 0.502\n      \ud83d\udcac Quote: \"Every dog has his day.\"\n      \u270d\ufe0f  Author: Jonathan Swift\n      \ud83c\udff7\ufe0f  Category: Symbolism and Allegory\n\n   3. \ud83d\udcca Score: 0.492\n      \ud83d\udcac Quote: \"Animals are reliable, many full of love, true in their affections, predictable in their actions, grateful and loyal. ...\"\n      \u270d\ufe0f  Author: Alfred A. Montapert\n      \ud83c\udff7\ufe0f  Category: Reflections and Lessons\n\n   4. \ud83d\udcca Score: 0.480\n      \ud83d\udcac Quote: \"I wonder if other dogs think poodles are members of a weird religious cult.\"\n      \u270d\ufe0f  Author: Rita Rudner\n      \ud83c\udff7\ufe0f  Category: Humorous Quotes\n\n   5. \ud83d\udcca Score: 0.475\n      \ud83d\udcac Quote: \"Dogs have boundless enthusiasm but no sense of shame. I should have a dog as a life coach.\"\n      \u270d\ufe0f  Author: Moby\n      \ud83c\udff7\ufe0f  Category: Animal Morality\n\n\n\ud83d\udcca Insight: Threshold filtering removed 5 lower-quality results\n</code>\n</pre> <pre><code># Example 7: Demonstrating Semantic vs Keyword Search\nprint(\"\ud83c\udfaf EXAMPLE 7: Semantic vs Keyword Search Comparison\")\nprint(\"=\" * 55)\nprint(\"\ud83d\udd0d Let's compare semantic search with what keyword search would find\")\n\n# Semantic search for concepts\nquery = \"creatures that bring joy and happiness\"\nprint(f\"\\nQuery: '{query}'\")\nprint(\"\ud83e\udde0 SEMANTIC SEARCH: Finds quotes about the CONCEPT of joy from animals\")\n\nsemantic_results = animals_loader.search(query, limit=3)\ndisplay_search_results(semantic_results, \"Semantic Search Results\")\n\n# Simulate what keyword search might miss\nprint(\"\\n\ud83d\udd11 KEYWORD SEARCH would look for:\")\nprint(\"   - Documents containing 'creatures' AND 'joy' AND 'happiness'\")\nprint(\"   - Would miss quotes about 'pets', 'animals', 'delight', 'bliss', etc.\")\nprint(\"   - Would miss conceptually related but differently worded content\")\n\nprint(\"\\n\ud83d\udca1 SEMANTIC ADVANTAGE:\")\nprint(\"   \u2705 Understands synonyms and related concepts\")\nprint(\"   \u2705 Captures intent, not just keywords\") \nprint(\"   \u2705 Finds relevant content with different vocabulary\")\nprint(\"   \u2705 More natural, human-like understanding\")\n</code></pre> <pre>\n<code>2025-06-28 12:44:49 | INFO     | rag_to_riches.vectordb.embedded_vectordb:search_points:413 - Found 3 points in collection 'animals'\n2025-06-28 12:44:49 | INFO     | rag_to_riches.search.semantic_search:search_with_text:347 - Text search for 'creatures that bring joy and happiness...' returned 3 results\n2025-06-28 12:44:49 | INFO     | rag_to_riches.corpus.animals:search:426 - Animal quotes search for 'creatures that bring joy and happiness...' returned 3 results\n</code>\n</pre> <pre>\n<code>\ud83c\udfaf EXAMPLE 7: Semantic vs Keyword Search Comparison\n=======================================================\n\ud83d\udd0d Let's compare semantic search with what keyword search would find\n\nQuery: 'creatures that bring joy and happiness'\n\ud83e\udde0 SEMANTIC SEARCH: Finds quotes about the CONCEPT of joy from animals\n\n\ud83d\udd0d Semantic Search Results\n=========================\n   \ud83d\udcca Found 3 results\n\n   1. \ud83d\udcca Score: 0.505\n      \ud83d\udcac Quote: \"Whoever said you can\u2019t buy happiness forgot little puppies.\"\n      \u270d\ufe0f  Author: Gene Hill\n      \ud83c\udff7\ufe0f  Category: Animals as Reflections\n\n   2. \ud83d\udcca Score: 0.498\n      \ud83d\udcac Quote: \"The only creatures that are evolved enough to convey pure love are dogs and infants.\"\n      \u270d\ufe0f  Author: Johnny Depp\n      \ud83c\udff7\ufe0f  Category: Proverbs and Sayings\n\n   3. \ud83d\udcca Score: 0.468\n      \ud83d\udcac Quote: \"Animals share with us the privilege of having a soul.\"\n      \u270d\ufe0f  Author: Pythagoras\n      \ud83c\udff7\ufe0f  Category: Literary and Poetic Imagery\n\n\n\ud83d\udd11 KEYWORD SEARCH would look for:\n   - Documents containing 'creatures' AND 'joy' AND 'happiness'\n   - Would miss quotes about 'pets', 'animals', 'delight', 'bliss', etc.\n   - Would miss conceptually related but differently worded content\n\n\ud83d\udca1 SEMANTIC ADVANTAGE:\n   \u2705 Understands synonyms and related concepts\n   \u2705 Captures intent, not just keywords\n   \u2705 Finds relevant content with different vocabulary\n   \u2705 More natural, human-like understanding\n</code>\n</pre> <pre><code># BONUS: Exploring the Enhanced Animals Class\nprint(\"\ud83c\udfaf BONUS: Enhanced Animals Class Features\")\nprint(\"=\" * 50)\nprint(\"\ud83d\udd27 The Animals class now leverages SemanticSearch internally!\")\n\n# Show the new consistency check feature\nprint(\"\\n1\ufe0f\u20e3 Collection Consistency Check:\")\nis_consistent = animals_loader.consistency_check()\nprint(f\"   \u2705 Collection parameters consistent with embedder: {is_consistent}\")\n\n# Show access to the underlying semantic search engine\nprint(\"\\n2\ufe0f\u20e3 Access to Underlying SemanticSearch:\")\nprint(f\"   \ud83d\udd0d SemanticSearch instance: {type(animals_loader.semantic_search).__name__}\")\nprint(f\"   \ud83d\udcca Embedder type: {type(animals_loader.semantic_search.embedder).__name__}\")\nprint(f\"   \ud83d\uddc4\ufe0f Vector DB type: {type(animals_loader.semantic_search.vector_db).__name__}\")\n\n# Demonstrate single quote indexing\nprint(\"\\n3\ufe0f\u20e3 Single Quote Indexing (New Feature):\")\nsample_quote = AnimalQuote(\n    text=\"The greatness of a nation can be judged by the way its animals are treated.\",\n    author=\"Mahatma Gandhi\", \n    category=\"Wisdom and Philosophy\"\n)\ntry:\n    point_id = animals_loader.index_single_quote(sample_quote)\n    print(f\"   \u2705 Successfully indexed single quote with ID: {point_id[:8]}...\")\nexcept Exception as e:\n    print(f\"   \u2139\ufe0f Single quote indexing: {e}\")\n\nprint(\"\\n\ud83d\udca1 Benefits of the Refactoring:\")\nprint(\"   \ud83d\ude80 Reduced code duplication by ~60 lines\")\nprint(\"   \ud83d\udee0\ufe0f Better maintainability and consistency\")\nprint(\"   \ud83d\udd27 Access to full SemanticSearch capabilities\")\nprint(\"   \u2728 Enhanced functionality while keeping the same API\")\nprint(\"   \ud83c\udfaf Composition over duplication design pattern\")\n</code></pre> <pre>\n<code>2025-06-28 12:44:49 | INFO     | rag_to_riches.vectordb.embedded_vectordb:get_collection_info:295 - Retrieved info for collection 'animals'\n2025-06-28 12:44:49 | INFO     | rag_to_riches.search.semantic_search:consistency_check:233 - Consistency check passed for collection 'animals'\n2025-06-28 12:44:49 | INFO     | rag_to_riches.vectordb.embedded_vectordb:upsert_points:450 - Upserted 1 points to collection 'animals'\n</code>\n</pre> <pre>\n<code>\ud83c\udfaf BONUS: Enhanced Animals Class Features\n==================================================\n\ud83d\udd27 The Animals class now leverages SemanticSearch internally!\n\n1\ufe0f\u20e3 Collection Consistency Check:\n   \u2705 Collection parameters consistent with embedder: True\n\n2\ufe0f\u20e3 Access to Underlying SemanticSearch:\n   \ud83d\udd0d SemanticSearch instance: SemanticSearch\n   \ud83d\udcca Embedder type: SimpleTextEmbedder\n   \ud83d\uddc4\ufe0f Vector DB type: EmbeddedVectorDB\n\n3\ufe0f\u20e3 Single Quote Indexing (New Feature):\n   \u2705 Successfully indexed single quote with ID: 8117cdf3...\n\n\ud83d\udca1 Benefits of the Refactoring:\n   \ud83d\ude80 Reduced code duplication by ~60 lines\n   \ud83d\udee0\ufe0f Better maintainability and consistency\n   \ud83d\udd27 Access to full SemanticSearch capabilities\n   \u2728 Enhanced functionality while keeping the same API\n   \ud83c\udfaf Composition over duplication design pattern\n</code>\n</pre>"},{"location":"notebooks/examples/lesson-1/#rag-to-riches-lesson-1-the-power-of-semantic-search","title":"RAG to Riches: Lesson 1 - The Power of Semantic Search","text":""},{"location":"notebooks/examples/lesson-1/#learning-objectives","title":"\ud83c\udfaf Learning Objectives","text":"<p>By the end of this lesson, you will understand:</p> <ol> <li>What semantic search is and how it differs from traditional keyword search</li> <li>Why semantic search is revolutionary for information retrieval</li> <li>Where semantic search excels and its best use cases</li> <li>How to implement semantic search with embeddings and vector databases</li> </ol>"},{"location":"notebooks/examples/lesson-1/#table-of-contents","title":"\ud83d\udcda Table of Contents","text":"<ol> <li> <p>The Intuition Behind Semantic Search</p> </li> <li> <p>The Three W's of Semantic Search</p> </li> <li>What is Semantic Search?</li> <li>Why Semantic Search? </li> <li> <p>Where to Use Semantic Search?</p> </li> <li> <p>The HOW: Implementation Deep Dive</p> </li> <li>Data Structure: AnimalQuote Examples</li> <li>The Indexing Pipeline</li> <li>The Search Process</li> <li> <p>Hands-on Examples</p> </li> <li> <p>Key Takeaways</p> </li> </ol>"},{"location":"notebooks/examples/lesson-1/#the-intuition-behind-semantic-search-intuition","title":"The Intuition Behind Semantic Search {#intuition}","text":""},{"location":"notebooks/examples/lesson-1/#semantic-search","title":"Semantic search","text":"<p>Traditionally, one would search through a corpus of documents using a keywords-based search engine like Lucene, Solr, ElasticSearch, etc. While the technology has matured, the basic underlying approach behind keyword search engines is to maintain an inverted-index mapping keywords to a list of documents that contain them, with associated relevances.</p> <p>In general, the keywords-based search approach has been quite successful over the years, and have matured with added features and linguistic capabilities.</p> <p>However, this approach has had its limitations. The principal cause of it goes to the fact that when we enter keywords, it is a human tendency to describe the intent of what we are looking for. For example, if we enter \"breakfast places\", we implicitly also mean restaurants, cafe, etc that serve items appropriate for breakfast. There may be a restaurant described as a shop for expresso, or crepe, that a keywords-search will likely miss, since its keywords do not match the query terms. And yet, we would hope to see it near the top of the search results.</p> <p>Semantic search is an NLP approach largely relying on deep-neural networks, and in particular, the transformers that make it possible to more closely infer the human intent behind the search terms, the relationship between the words, and the underlying context. It allows for entire sentences -- and even paragraphs -- describing what the searcher's intent is, and retrieves results more relevant or aligned to it.</p>"},{"location":"notebooks/examples/lesson-1/#how-would-we-do-this-nlp-task-with-ai","title":"How would we do this NLP task with AI?","text":"<p>Let us represent the functional behavior we expect: </p> <p></p>"},{"location":"notebooks/examples/lesson-1/#magic-happens-breaking-it-down-into-steps","title":"Magic happens: breaking it down into steps","text":"<p>We recall that machine-learning algorithms work with vectors (\\(\\mathbf{X}\\)) representation of data.</p> <p>So the first order of business would be to map each of the document texts \\(D_i\\) to its corresponding vector \\(X_i\\) in an appropriate \\(d\\)-dimensional space, \\(\\mathbb{R}^d\\), i.e.</p> \\[\\begin{equation} D_i \\longrightarrow X_i \\in \\mathbb{R}^d \\end{equation}\\] <p>This resulting vectors are called sentence embeddings. Once these embeddings are for each of the documents, we can store the collection of tuples \\([&lt;d_1, x_1=\"\"&gt;, &lt;d_2, x_2=\"\"&gt;, ..., &lt;d_n, x_n=\"\"&gt;]\\). Here each tuple corresponds to a document and its sentence embedding.</p> <p>This collection of tuples, therefore, becomes our search index.</p>"},{"location":"notebooks/examples/lesson-1/#search","title":"Search","text":"<p>Now, when the user described what she is looking for, we consider the entire text as a \"sentence\".</p> <p> </p> Caveat Emptor  &gt; Note that we have a rather relaxed definition of a *sentence* in NLP: it diverges from a grammmatical definition of a sentence somewhat.  For example, in the English language, we would consider a sentence to be terminated with a punctuation, such as a period, question-mark or exclamation. However, in NLP, we loosely consider the entire text -- whether it is just a word, or a few keywords, or an english sentence, or a few sentences together -- as one **sentence** for the purposes of natual language processing task.  <p> </p> <p>Therefore, it is common to consider an entire document text as a sentence if the text is relatively short. Alternatively, it is partitioned into smaller chunks (of say 512-tokens each), and each such chunk is considered an NLP sentence.</p> <p>Since we consider the entire query text as a sentence, we can map it to its sentence embedding vector, \\({Q}\\).</p>"},{"location":"notebooks/examples/lesson-1/#vector-similarity","title":"Vector Similarity","text":"<p>Once we have this, we simply need to compare the query vector \\({Q}\\) with each of the document vectors \\(X_i\\), and sort the document vectors in descending order of similarity.</p> <p>The rest is trivial: pick the top-k  in the sorted document vectors list. Then for each vector, look up its corresponding document, and return the list as sorted search result of relevant document.</p> <p>We expect that these documents will exhibit high semantic similarity with the search query, assuming that the search index did contain such documents.</p>  Semantic similarity as vector proximity in the embedding space.      (Figure source: Sbert.net documentation)."},{"location":"notebooks/examples/lesson-1/#similarity-measures","title":"Similarity measures","text":"<p>The sentence embedding vectors typically exist in very large dimensional space (e.g., 300 dimensions). In such large dimensional spaces, the notion of euclidean distance is not as effective. Therefore, it is far more common to use one of the two below measures for vector similarity:</p> <ul> <li>dot-product, the (inner) dot-product between the embedding vectors.</li> </ul> \\[\\begin{equation} \\text{dot-similarity} = \\langle X_i, X_j \\rangle \\end{equation}\\] <ul> <li>cosine-similarity, the \\(\\cos \\left(\\theta_{ij}\\right)\\) gives degree of directional alignment between the vectors, but ignores their magnitudes. Here, \\(\\theta_{ij}\\) is the angle between \\(X_i\\) and \\(X_j\\) (embedding) vectors.</li> </ul> \\[\\begin{equation}  \\text{cosine-similarity} = \\frac{\\langle X_i, X_j \\rangle} {\\| X_i \\| \\| X_j \\|} \\end{equation}\\]   **Important**  &gt;  Sentence transformer models trained with cosine-similarity tend to favor the shorter document texts in the search results, whereas the models trained on the dot-product similarity tend to favor longer texts.  <p></p>"},{"location":"notebooks/examples/lesson-1/#the-three-ws-of-semantic-search-the-three-ws","title":"\ud83d\udd0d The Three W's of Semantic Search {#the-three-ws}","text":""},{"location":"notebooks/examples/lesson-1/#what-is-semantic-search-what","title":"What is Semantic Search? {#what}","text":"<p>Semantic search is an information retrieval technique that understands the meaning and context of queries and documents, rather than just matching exact keywords.</p>"},{"location":"notebooks/examples/lesson-1/#traditional-keyword-search-vs-semantic-search","title":"Traditional Keyword Search vs. Semantic Search","text":"Aspect Keyword Search Semantic Search Matching Exact text matches Conceptual similarity Understanding Lexical (word-level) Semantic (meaning-level) Query \"dog loyalty\" \"dog loyalty\" Finds Documents containing \"dog\" AND \"loyalty\" Documents about faithful pets, even without exact words Technology TF-IDF, BM25, Boolean logic Neural embeddings, vector similarity"},{"location":"notebooks/examples/lesson-1/#key-concepts","title":"Key Concepts","text":"<ul> <li>Embeddings: Dense vector representations of text that capture semantic meaning</li> <li>Vector Space: High-dimensional space where similar concepts are positioned close together</li> <li>Cosine Similarity: Mathematical measure of how similar two vectors (meanings) are</li> <li>Dense Retrieval: Finding relevant information based on semantic similarity rather than keyword overlap</li> </ul>"},{"location":"notebooks/examples/lesson-1/#why-semantic-search-why","title":"Why Semantic Search? {#why}","text":"<p>Semantic search has revolutionized information retrieval in several fundamental ways:</p>"},{"location":"notebooks/examples/lesson-1/#1-intent-understanding","title":"\ud83c\udfaf 1. Intent Understanding","text":"<ul> <li>Problem: User searches \"best friend\" but documents say \"loyal companion\"</li> <li>Solution: Semantic search understands these concepts are related</li> <li>Impact: 40-60% improvement in search relevance</li> </ul>"},{"location":"notebooks/examples/lesson-1/#2-language-flexibility","title":"\ud83c\udf10 2. Language Flexibility","text":"<ul> <li>Synonyms: \"automobile\" matches \"car\", \"vehicle\", \"auto\"</li> <li>Paraphrasing: \"How to cook pasta\" matches \"pasta preparation methods\"</li> <li>Multilingual: Can work across languages with multilingual embeddings</li> </ul>"},{"location":"notebooks/examples/lesson-1/#3-context-awareness","title":"\ud83e\udde0 3. Context Awareness","text":"<ul> <li>Polysemy: \"bank\" (financial) vs \"bank\" (river) - context determines meaning</li> <li>Nuanced queries: \"sad movie that makes you cry\" vs \"sad movie with bad reviews\"</li> <li>Conceptual search: Find documents about concepts, not just keywords</li> </ul>"},{"location":"notebooks/examples/lesson-1/#4-transformational-impact-on-industries","title":"\ud83d\udcc8 4. Transformational Impact on Industries","text":"<ul> <li>Search Engines: Google's BERT (2019) improved 10% of search queries</li> <li>E-commerce: Amazon's semantic search increased conversion rates by 15-25%</li> <li>Enterprise: Microsoft's semantic search in Office 365 improved productivity</li> <li>Legal: Semantic search helps lawyers find relevant case law beyond keyword matches</li> </ul>"},{"location":"notebooks/examples/lesson-1/#where-to-use-semantic-search-where","title":"Where to Use Semantic Search? {#where}","text":""},{"location":"notebooks/examples/lesson-1/#best-use-cases","title":"\ud83c\udfc6 Best Use Cases","text":"<ol> <li>Document Collections with Rich Content</li> <li>Research papers, articles, books</li> <li>Legal documents, contracts</li> <li>Medical records, patient notes</li> <li> <p>Our use case: Animal wisdom quotes</p> </li> <li> <p>Customer Support &amp; FAQ</p> </li> <li>Users ask questions in natural language</li> <li>Need to find relevant answers regardless of exact wording</li> <li> <p>Example: \"My order is late\" \u2192 finds \"delivery delays\" content</p> </li> <li> <p>Product Discovery</p> </li> <li>E-commerce: \"comfortable running shoes for flat feet\"</li> <li>Real estate: \"cozy family home near good schools\"</li> <li> <p>Content: \"funny movies for date night\"</p> </li> <li> <p>Knowledge Management</p> </li> <li>Corporate wikis and documentation</li> <li>Research databases</li> <li>Personal note-taking systems (Obsidian, Notion)</li> </ol>"},{"location":"notebooks/examples/lesson-1/#when-not-to-use-semantic-search","title":"\u26a0\ufe0f When NOT to Use Semantic Search","text":"<ol> <li>Exact Match Requirements</li> <li>Legal document numbers, product SKUs</li> <li>Code search (variable names, function signatures)</li> <li> <p>Database queries with specific criteria</p> </li> <li> <p>Very Small Datasets</p> </li> <li>&lt; 100 documents: keyword search may be sufficient</li> <li> <p>Overhead of embeddings not justified</p> </li> <li> <p>Highly Technical/Domain-Specific</p> </li> <li>Without domain-specific embeddings</li> <li>Very specialized jargon that general models don't understand</li> </ol>"},{"location":"notebooks/examples/lesson-1/#the-how-implementation-deep-dive-implementation","title":"\ud83d\udee0\ufe0f The HOW: Implementation Deep Dive {#implementation}","text":"<p>Now that we understand the what, why, and where of semantic search, let's dive into the how. We'll use our Animals Wisdom Quotes corpus to demonstrate a complete semantic search implementation.</p>"},{"location":"notebooks/examples/lesson-1/#data-structure-animalquote-examples-data-structure","title":"\ud83d\udcca Data Structure: AnimalQuote Examples {#data-structure}","text":"<p>Let's first examine the structure of our data and see some example quotes to understand what we're working with.</p>"},{"location":"notebooks/examples/lesson-1/#the-indexing-pipeline-indexing-pipeline","title":"\ud83d\udd27 The Indexing Pipeline {#indexing-pipeline}","text":"<p>The semantic search indexing pipeline consists of several key steps:</p> <pre><code>Raw Data (JSONL) \u2192 AnimalQuote Objects \u2192 AnimalWisdom Collection \u2192 Embeddings \u2192 Vector Database\n</code></pre>"},{"location":"notebooks/examples/lesson-1/#step-by-step-process","title":"Step-by-Step Process:","text":"<ol> <li>Data Loading: Parse JSONL into validated <code>AnimalQuote</code> objects</li> <li>Collection Creation: Group quotes into <code>AnimalWisdom</code> container</li> <li>Embedding Generation: Convert text to dense vectors using neural models</li> <li>Vector Storage: Store embeddings + metadata in Qdrant vector database</li> <li>Indexing: Create efficient search indices for fast retrieval</li> </ol>"},{"location":"notebooks/examples/lesson-1/#key-components","title":"Key Components:","text":"<ul> <li>\ud83d\udcdd AnimalQuote: Individual quote with validation</li> <li>\ud83d\udcda AnimalWisdom: Collection of quotes with analysis methods  </li> <li>\ud83e\udde0 Embedder: Neural model that converts text \u2192 vectors</li> <li>\ud83d\uddc4\ufe0f VectorDB: Qdrant database for storing and searching vectors</li> <li>\ud83d\udd0d Animals: Orchestrator class that manages the entire pipeline</li> </ul>"},{"location":"notebooks/examples/lesson-1/#understanding-embeddings-the-magic-behind-semantic-search","title":"\ud83d\udd0d Understanding Embeddings: The Magic Behind Semantic Search","text":"<p>Before we dive into search examples, let's understand what happens when we convert text to embeddings.</p>"},{"location":"notebooks/examples/lesson-1/#what-are-embeddings","title":"What are Embeddings?","text":"<p>Embeddings are dense vector representations of text that capture semantic meaning in a high-dimensional space. Each dimension represents some aspect of meaning that the neural model has learned.</p>"},{"location":"notebooks/examples/lesson-1/#key-properties","title":"Key Properties:","text":"<ul> <li>Dense: Every dimension has a meaningful value (vs sparse keyword vectors)</li> <li>Semantic: Similar meanings \u2192 similar vectors  </li> <li>High-dimensional: Our model uses 384 dimensions</li> <li>Learned: Trained on massive text corpora to understand language</li> </ul>"},{"location":"notebooks/examples/lesson-1/#the-search-process-search-process","title":"\ud83c\udfaf The Search Process {#search-process}","text":"<p>Now let's explore how semantic search works in practice. The search process involves:</p> <ol> <li>Query Embedding: Convert the search query into a vector</li> <li>Similarity Calculation: Compare query vector with all stored vectors  </li> <li>Ranking: Sort results by similarity score (cosine similarity)</li> <li>Filtering: Apply metadata filters (author, category, score threshold)</li> <li>Return Results: Present top-k most similar documents</li> </ol>"},{"location":"notebooks/examples/lesson-1/#search-types-well-demonstrate","title":"Search Types We'll Demonstrate:","text":"<ol> <li>Basic Semantic Search: Find conceptually similar quotes</li> <li>Author-Filtered Search: Search within specific author's quotes  </li> <li>Category-Filtered Search: Search within specific categories</li> <li>High-Confidence Search: Only return very similar results</li> <li>Combined Filters: Multiple criteria simultaneously</li> </ol>"},{"location":"notebooks/examples/lesson-1/#hands-on-search-examples-examples","title":"\ud83c\udfaa Hands-on Search Examples {#examples}","text":"<p>Now for the exciting part! Let's demonstrate the power of semantic search with various examples that showcase different capabilities.</p>"},{"location":"notebooks/examples/lesson-1/#key-takeaways-takeaways","title":"\ud83c\udfaf Key Takeaways {#takeaways}","text":""},{"location":"notebooks/examples/lesson-1/#what-weve-learned","title":"\ud83d\udd11 What We've Learned","text":"<ol> <li>Semantic Search Revolution</li> <li>Goes beyond keyword matching to understand meaning</li> <li>Uses neural embeddings to capture semantic relationships</li> <li> <p>Transforms how we find and discover information</p> </li> <li> <p>Technical Implementation</p> </li> <li>Embeddings: Dense vectors that represent semantic meaning</li> <li>Vector Database: Efficient storage and similarity search</li> <li>Pipeline: Data \u2192 Validation \u2192 Embeddings \u2192 Indexing \u2192 Search</li> <li> <p>Architecture: Composition pattern with SemanticSearch for code reuse</p> </li> <li> <p>Practical Benefits</p> </li> <li>Intent Understanding: Finds what you mean, not just what you say</li> <li>Language Flexibility: Works with synonyms, paraphrases, concepts</li> <li>Better Relevance: 40-60% improvement over keyword search</li> <li> <p>Natural Queries: Search like you think and speak</p> </li> <li> <p>Real-World Applications</p> </li> <li>Document search and knowledge management</li> <li>E-commerce product discovery  </li> <li>Customer support and FAQ systems</li> <li>Research and academic databases</li> </ol>"},{"location":"notebooks/examples/lesson-1/#next-steps","title":"\ud83d\ude80 Next Steps","text":"<p>In future lessons, we'll explore: - RAG (Retrieval-Augmented Generation): Combining search with LLMs - Advanced Embeddings: Domain-specific and multimodal models - Vector Database Optimization: Performance and scaling - Evaluation Metrics: Measuring search quality and relevance</p>"},{"location":"notebooks/examples/lesson-1/#remember","title":"\ud83d\udca1 Remember","text":"<p>&gt; \"Semantic search doesn't just find documents that match your keywords\u2014it finds documents that match your thoughts.\"</p> <p>The power of semantic search lies in its ability to bridge the gap between human intent and information retrieval, making search more intuitive, effective, and intelligent.</p> <p>\ud83c\udf89 Congratulations! You've completed Lesson 1 and now understand the fundamentals of semantic search. You're ready to build more sophisticated RAG applications!</p>"},{"location":"notebooks/examples/lesson-2/","title":"Lesson 2","text":"<pre><code>%run supportvectors-common.ipynb\n</code></pre>    \u00a9 SupportVectors. All rights reserved. This notebook is the intellectual property of SupportVectors, and part of its training material.  Only the participants in SupportVectors workshops are allowed to study the notebooks for educational purposes currently, but is prohibited from copying or using it for any other purposes without written permission.  <p> These notebooks are chapters and sections from Asif Qamar's textbook that he is writing on Data Science. So we request you to not circulate the material to others.</p> <pre>\n<code>\ud83c\udfaf Project root: /Users/asifqamar/github/rag_to_riches\n\ud83d\udcc1 Working directory: /Users/asifqamar/github/rag_to_riches\n\u2705 Ready to import rag_to_riches modules!\n</code>\n</pre> <pre><code># Import required modules\nfrom pathlib import Path\nimport json\nfrom rag_to_riches.corpus.animals import AnimalQuote, AnimalWisdom, Animals\nfrom rag_to_riches.vectordb.embedded_vectordb import EmbeddedVectorDB\nfrom rag_to_riches.vectordb.embedder import SimpleTextEmbedder\n\nprint(\"\ud83d\udc3e Modules imported successfully!\")\nprint(\"\ud83d\udcc1 Current working directory:\", Path.cwd())\n</code></pre> <pre>\n<code>WARNING:root:No configuration file specified. Trying the default location\nWARNING:root:Loading configuration from /Users/asifqamar/github/rag_to_riches/config.yaml if it exists\n</code>\n</pre> <pre>\n<code>\ud83d\udc3e Modules imported successfully!\n\ud83d\udcc1 Current working directory: /Users/asifqamar/github/rag_to_riches\n</code>\n</pre> <pre><code># \ud83d\ude80 Initialize Shared Components (Vector Database &amp;amp; Embedder)\n# ============================================================================\n# We initialize these components ONCE at the beginning to avoid database lock issues\n# and reuse them throughout the notebook for efficiency and consistency.\n\nprint(\"\ud83d\udd27 Initializing Shared Components for the Entire Notebook\")\nprint(\"=\" * 60)\n\n# Initialize Vector Database (shared instance)\nprint(\"1\ufe0f\u20e3 Initializing Vector Database (Qdrant)...\")\nvector_db = EmbeddedVectorDB()\nprint(\"   \u2705 Vector database connected and ready for reuse\")\n\n# Initialize Text Embedder (shared instance)  \nprint(\"\\n2\ufe0f\u20e3 Initializing Text Embedder (Sentence Transformers)...\")\nembedder = SimpleTextEmbedder(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\nprint(f\"   \u2705 Embedder loaded: {embedder.model_name}\")\nprint(f\"   \ud83d\udcd0 Vector dimensions: {embedder.get_vector_size()}\")\nprint(f\"   \ud83d\udccf Distance metric: {embedder.get_distance_metric()}\")\n\n# \ud83d\udcda Load and Index Animal Quotes Using Shared Components\nprint(\"\ud83d\udd27 Creating Animals corpus loader using shared components...\")\nanimals = Animals(\n    vector_db=vector_db,  # Reusing shared vector_db instance\n    embedder=embedder,    # Reusing shared embedder instance\n)\n</code></pre> <pre>\n<code>2025-06-21 09:26:29 | INFO     | rag_to_riches.vectordb.embedded_vectordb:__init__:58 - Connected to embedded vector database at qdrant_db\n</code>\n</pre> <pre>\n<code>\ud83d\udd27 Initializing Shared Components for the Entire Notebook\n============================================================\n1\ufe0f\u20e3 Initializing Vector Database (Qdrant)...\n   \u2705 Vector database connected and ready for reuse\n\n2\ufe0f\u20e3 Initializing Text Embedder (Sentence Transformers)...\n</code>\n</pre> <pre>\n<code>2025-06-21 09:26:30 | INFO     | rag_to_riches.vectordb.embedder:__init__:115 - Initialized SimpleTextEmbedder with model 'sentence-transformers/all-MiniLM-L6-v2', vector size: 384\n2025-06-21 09:26:30 | INFO     | rag_to_riches.vectordb.embedded_vectordb:_ensure_existing_collection_matches:464 - Collection 'animals' exists with correct parameters\n2025-06-21 09:26:30 | INFO     | rag_to_riches.vectordb.embedded_vectordb:get_collection_info:295 - Retrieved info for collection 'animals'\n2025-06-21 09:26:30 | INFO     | rag_to_riches.search.semantic_search:consistency_check:233 - Consistency check passed for collection 'animals'\n2025-06-21 09:26:30 | INFO     | rag_to_riches.search.semantic_search:__init__:182 - Initialized SemanticSearch for collection 'animals' with SimpleTextEmbedder\n2025-06-21 09:26:30 | INFO     | rag_to_riches.corpus.animals:__init__:208 - Initialized Animals corpus loader for collection 'animals'\n</code>\n</pre> <pre>\n<code>   \u2705 Embedder loaded: sentence-transformers/all-MiniLM-L6-v2\n   \ud83d\udcd0 Vector dimensions: 384\n   \ud83d\udccf Distance metric: Cosine\n\ud83d\udd27 Creating Animals corpus loader using shared components...\n</code>\n</pre> <pre><code>results = animals.search(\"a friendship with animals\", limit=4)\nanimals.display_search_results(results, \"Basic Semantic Search Results\", max_text_length=120)\n</code></pre> <pre>\n<code>2025-06-21 09:26:30 | INFO     | rag_to_riches.vectordb.embedded_vectordb:search_points:408 - Found 4 points in collection 'animals'\n2025-06-21 09:26:30 | INFO     | rag_to_riches.search.semantic_search:search_with_text:347 - Text search for 'a friendship with animals...' returned 4 results\n2025-06-21 09:26:30 | INFO     | rag_to_riches.corpus.animals:search:416 - Animal quotes search for 'a friendship with animals...' returned 4 results\n</code>\n</pre> <pre>                                         \ud83d\udd0d Basic Semantic Search Results                                          \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503        \u2503             \u2503                                                     \u2503                 \u2503                  \u2503\n\u2503   #    \u2503    Score    \u2503  Quote                                              \u2503  Author         \u2503  Category        \u2503\n\u2503        \u2503             \u2503                                                     \u2503                 \u2503                  \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502        \u2502             \u2502                                                     \u2502                 \u2502                  \u2502\n\u2502   1    \u2502    0.625    \u2502  \"Animals are such agreeable friends\u2014they ask no    \u2502  George Eliot   \u2502  Famous          \u2502\n\u2502        \u2502             \u2502  questions; they pass no criticisms.\"               \u2502                 \u2502  Literary        \u2502\n\u2502        \u2502             \u2502                                                     \u2502                 \u2502  Passages        \u2502\n\u2502        \u2502             \u2502                                                     \u2502                 \u2502                  \u2502\n\u2502        \u2502             \u2502                                                     \u2502                 \u2502                  \u2502\n\u2502   2    \u2502    0.586    \u2502  \"The best thing about animals is that they don't   \u2502  Thornton       \u2502  Famous          \u2502\n\u2502        \u2502             \u2502  talk much.\"                                        \u2502  Wilder         \u2502  Literary        \u2502\n\u2502        \u2502             \u2502                                                     \u2502                 \u2502  Passages        \u2502\n\u2502        \u2502             \u2502                                                     \u2502                 \u2502                  \u2502\n\u2502        \u2502             \u2502                                                     \u2502                 \u2502                  \u2502\n\u2502   3    \u2502    0.548    \u2502  \"Some people talk to animals. Not many listen      \u2502  A.A. Milne     \u2502  Proverbs and    \u2502\n\u2502        \u2502             \u2502  though. That's the problem.\"                       \u2502                 \u2502  Sayings         \u2502\n\u2502        \u2502             \u2502                                                     \u2502                 \u2502                  \u2502\n\u2502        \u2502             \u2502                                                     \u2502                 \u2502                  \u2502\n\u2502   4    \u2502    0.535    \u2502  \"Animals are reliable, many full of love, true in  \u2502  Alfred A.      \u2502  Reflections     \u2502\n\u2502        \u2502             \u2502  their affections, predictable in their actions,    \u2502  Montapert      \u2502  and Lessons     \u2502\n\u2502        \u2502             \u2502  grateful and loyal. ...\"                           \u2502                 \u2502                  \u2502\n\u2502        \u2502             \u2502                                                     \u2502                 \u2502                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre>\ud83d\udcca Found 4 results\n</pre> <pre><code>result = animals.rag(\n    user_query=\"What do animals teach us about love?\",\n    limit=3,\n    response_type=\"structured\"  # or \"simple\"\n)\nllm_response = result[\"llm_response\"]\nsearch_results = result[\"search_results\"]\n</code></pre> <pre>\n<code>2025-06-21 09:26:30 | INFO     | rag_to_riches.vectordb.embedded_vectordb:search_points:408 - Found 3 points in collection 'animals'\n2025-06-21 09:26:30 | INFO     | rag_to_riches.search.semantic_search:search_with_text:347 - Text search for 'What do animals teach us about love?...' returned 3 results\n2025-06-21 09:26:30 | INFO     | rag_to_riches.corpus.animals:search:416 - Animal quotes search for 'What do animals teach us about love?...' returned 3 results\n2025-06-21 09:26:30 | INFO     | rag_to_riches.vectordb.embedded_vectordb:search_points:408 - Found 3 points in collection 'animals'\n2025-06-21 09:26:30 | INFO     | rag_to_riches.search.semantic_search:search_with_text:347 - Text search for 'What do animals teach us about love?...' returned 3 results\n2025-06-21 09:26:30 | INFO     | rag_to_riches.corpus.animals:search:416 - Animal quotes search for 'What do animals teach us about love?...' returned 3 results\n2025-06-21 09:26:39 | INFO     | rag_to_riches.corpus.animals:ask_llm:884 - LLM response generated for query: 'What do animals teach us about love?...'\n2025-06-21 09:26:39 | INFO     | rag_to_riches.corpus.animals:rag:1118 - Complete RAG pipeline executed for query: 'What do animals teach us about love?...' with 3 results and structured response\n</code>\n</pre> <pre><code>print (llm_response)\n</code></pre> <pre>\n<code>answer=\"Animals teach us profound lessons about love, often exhibiting traits that humans strive to embody. Firstly, according to Johnny Depp, dogs and infants are among the few beings on Earth capable of conveying pure love. This suggests that animals, particularly dogs, possess an innate ability to express unconditional love\u2014a trait humans deeply admire and seek to replicate in their relationships.\\n\\nAlfred A. Montapert expands on this idea by highlighting several qualities of animals, such as being reliable, full of love, true in their affections, predictable, grateful, and loyal. These qualities set challenging yet aspirational standards for love and behavior that people often wish to emulate. Animals' ability to love without expectations serves as a reminder of the simplicity and depth of authentic connection.\\n\\nFurthermore, Pythagoras points out that animals share with us the privilege of having a soul. This philosophical insight underscores the spiritual and emotional capacities of animals, suggesting that their expressions of love resonate with a deep, soulful authenticity that can inspire humans to connect more deeply with their own spiritual and emotional natures.\" key_insights=['Animals display pure, unconditional love, especially evident in dogs.', \"Animals' loyalty, gratitude, and predictable nature make their love reliable and exemplary.\", 'The soulful presence of animals suggests a deep spiritual connection with humans.', \"Animals' simple expressions of love teach humans about authenticity in relationships.\"] recommended_quotes=['\"The only creatures that are evolved enough to convey pure love are dogs and infants.\" - Johnny Depp', '\"Animals are reliable, many full of love, true in their affections, predictable in their actions, grateful and loyal. Difficult standards for people to live up to.\" - Alfred A. Montapert', '\"Animals share with us the privilege of having a soul.\" - Pythagoras'] follow_up_questions=['How do animals express other emotions besides love?', \"What lessons can humans learn from animals' loyalty and reliability?\", 'How do different cultures view the spiritual connection between humans and animals?']\n</code>\n</pre> <pre><code>import textwrap\nfrom rich import print\n\ntext = str(llm_response)\n\nformatted_text = textwrap.fill(text, width=100)\n\n\nprint(formatted_text)\n</code></pre> <pre>answer=\"Animals teach us profound lessons about love, often exhibiting traits that humans strive to\nembody. Firstly, according to Johnny Depp, dogs and infants are among the few beings on Earth\ncapable of conveying pure love. This suggests that animals, particularly dogs, possess an innate\nability to express unconditional love\u2014a trait humans deeply admire and seek to replicate in their\nrelationships.\\n\\nAlfred A. Montapert expands on this idea by highlighting several qualities of\nanimals, such as being reliable, full of love, true in their affections, predictable, grateful, and\nloyal. These qualities set challenging yet aspirational standards for love and behavior that people\noften wish to emulate. Animals' ability to love without expectations serves as a reminder of the\nsimplicity and depth of authentic connection.\\n\\nFurthermore, Pythagoras points out that animals\nshare with us the privilege of having a soul. This philosophical insight underscores the spiritual\nand emotional capacities of animals, suggesting that their expressions of love resonate with a deep,\nsoulful authenticity that can inspire humans to connect more deeply with their own spiritual and\nemotional natures.\" key_insights=['Animals display pure, unconditional love, especially evident in\ndogs.', \"Animals' loyalty, gratitude, and predictable nature make their love reliable and\nexemplary.\", 'The soulful presence of animals suggests a deep spiritual connection with humans.',\n\"Animals' simple expressions of love teach humans about authenticity in relationships.\"]\nrecommended_quotes=['\"The only creatures that are evolved enough to convey pure love are dogs and\ninfants.\" - Johnny Depp', '\"Animals are reliable, many full of love, true in their affections,\npredictable in their actions, grateful and loyal. Difficult standards for people to live up to.\" -\nAlfred A. Montapert', '\"Animals share with us the privilege of having a soul.\" - Pythagoras']\nfollow_up_questions=['How do animals express other emotions besides love?', \"What lessons can humans\nlearn from animals' loyalty and reliability?\", 'How do different cultures view the spiritual\nconnection between humans and animals?']\n</pre>"},{"location":"notebooks/examples/lesson-2/#rag-to-riches-lesson-2-the-power-of-rag","title":"RAG to Riches: Lesson 2 - The Power of RAG","text":"<p>Let us see now this works.</p>"},{"location":"notebooks/examples/search-corpus/","title":"Search corpus","text":"<pre><code>#\n# From \"Through the looking Glass\" by Lewis Caroll\n#\njabberwocky = \"\"\"\n\u2019Twas brillig, and the slithy toves\n      Did gyre and gimble in the wabe:\nAll mimsy were the borogoves,\n      And the mome raths outgrabe.\n\n\u201cBeware the Jabberwock, my son!\n      The jaws that bite, the claws that catch!\nBeware the Jubjub bird, and shun\n      The frumious Bandersnatch!\u201d\n\nHe took his vorpal sword in hand;\n      Long time the manxome foe he sought\u2014\nSo rested he by the Tumtum tree\n      And stood awhile in thought.\n\nAnd, as in uffish thought he stood,\n      The Jabberwock, with eyes of flame,\nCame whiffling through the tulgey wood,\n      And burbled as it came!\n\nOne, two! One, two! And through and through\n      The vorpal blade went snicker-snack!\nHe left it dead, and with its head\n      He went galumphing back.\n\n\u201cAnd hast thou slain the Jabberwock?\n      Come to my arms, my beamish boy!\nO frabjous day! Callooh! Callay!\u201d\n      He chortled in his joy.\n\n\u2019Twas brillig, and the slithy toves\n      Did gyre and gimble in the wabe:\nAll mimsy were the borogoves,\n      And the mome raths outgrabe.\n\n\"\"\"\n</code></pre> <pre><code>#\n# The beginning of the \"Tale of two cities\", by Charles Dickens\n#\nbest_of_times = \"\"\"\nIt was the best of times, it was the worst of times, \nit was the age of wisdom, it was the age of foolishness, \nit was the epoch of belief, it was the epoch of incredulity, \nit was the season of light, it was the season of darkness, \nit was the spring of hope, it was the winter of despair, \nwe had everything before us, we had nothing before us, \nwe were all going direct to heaven, \nwe were all going direct the other way\u2013in short, \nthe period was so far like the present period, \nthat some of its noisiest authorities insisted on its being received, \nfor good or for evil, in the superlative degree of comparison only.\n\"\"\"\n</code></pre> <pre><code>#\n# From the \"Tale of two cities\" by Charles Dickens\n#\nmystery = \"\"\"\nA wonderful fact to reflect upon, that every human creature is \nconstituted to be that profound secret and mystery to every other. \n\"\"\"\n</code></pre> <pre><code>#\n# A poignant passage from the \"Tale of two cities\", by Charles Dickens\n#\nlast_dream = \"\"\"\nI wish you to know that you have been the last dream of my soul. \nIn my degradation I have not been so degraded but that the sight \nof you with your father, and of this home made such a home by you, \nhas stirred old shadows that I thought had died out of me. \nSince I knew you, I have been troubled by a remorse that I \nthought would never reproach me again, and have heard whispers \nfrom old voices impelling me upward, that I thought were silent \nfor ever. I have had unformed ideas of striving afresh, beginning anew, \nshaking off sloth and sensuality, and fighting out the abandoned fight. \nA dream, all a dream, that ends in nothing, and leaves the sleeper \nwhere he lay down, but I wish you to know that you inspired it.\n\"\"\"\n</code></pre> <pre><code>mark_twain_dog = \"\"\"\nThe dog is a gentleman; I hope to go to his heaven not man's.\n\"\"\"\n</code></pre> <pre><code>einstein = \"\"\"If a man aspires towards a righteous life, his first act of abstinence is from injury to animals.\"\"\"\n</code></pre> <pre><code>tweedledee  = \"\"\"\nTweedledum and Tweedledee: She then meets the fat twin brothers \nTweedledum and Tweedledee, whom she knows from the nursery rhyme. \nAfter reciting the long poem \"The Walrus and the Carpenter\", \nthey draw Alice's attention to the Red King\u2014loudly snoring away \nunder a nearby tree\u2014and maliciously provoke her with idle philosophical \nbanter that she exists only as an imaginary figure in the Red King's dreams. \nFinally, the brothers begin suiting up for battle, only to be frightened \naway by an enormous crow, as the nursery rhyme about them predicts.\n\"\"\"\n</code></pre> <pre><code>goldens_1 = \"\"\"\nGolden retrievers are not bred to be guard dogs, and considering the size of their hearts and their irrepressible joy and life, they are less likely to bite than to bark, less likely to bark than to lick a hand in greeting. In spite of their size, they think they are lap dogs, and in spite of being dogs, they think they\u2019re also human, and nearly every human they meet is judged to have the potential to be a boon companion who might at any moment, cry, \u201cLet\u2019s go!\u201d and lead them on a great adventure.\n\"\"\"\n\ngoldens_2 = \"\"\"\nIf you\u2019re lucky, a golden retriever will come into your life, steal your heart, and change everything\n\"\"\"\n\ngoldens_3 = \"\"\"\nMy friend Phil has a theory that the Lord, having made teenagers, felt constrained to make amends and so created the golden retriever.\n\"\"\"\n\ndog_soul = \"\"\"\nIf you don\u2019t believe that dogs have souls, you haven\u2019t looked into their eyes long enough.\n\"\"\"\n</code></pre> <pre><code>keats = \"\"\"\nA thing of beauty is a joy for ever:\nIts loveliness increases; it will never\nPass into nothingness; but still will keep\nA bower quiet for us, and a sleep\nFull of sweet dreams, and health, and quiet breathing.\nTherefore, on every morrow, are we wreathing\nA flowery band to bind us to the earth,\nSpite of despondence, of the inhuman dearth\nOf noble natures, of the gloomy days,\nOf all the unhealthy and o'er-darkn'd ways\nMade for our searching: yes, in spite of all,\nSome shape of beauty moves away the pall\nFrom our dark spirits. Such the sun, the moon,\nTrees old and young, sprouting a shady boon\nFor simple sheep; and such are daffodils\nWith the green world they live in; and clear rills\nThat for themselves a cooling covert make\n'Gainst the hot season; the mid-forest brake,\nRich with a sprinkling of fair musk-rose blooms:\nAnd such too is the grandeur of the dooms\nWe have imagined for the mighty dead;\nAn endless fountain of immortal drink,\nPouring unto us from the heaven's brink\n\"\"\"\n</code></pre> <pre><code>attention = \"\"\"\nThe dominant sequence transduction models are based on \ncomplex recurrent or convolutional neural networks in an encoder-decoder configuration. \nThe best performing models also connect the encoder and decoder through \nan attention mechanism. We propose a new simple network architecture, \nthe Transformer, based solely on attention mechanisms, \ndispensing with recurrence and convolutions entirely. \nExperiments on two machine translation tasks show these models \nto be superior in quality while being more parallelizable \nand requiring significantly less time to train. \nOur model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, \nimproving over the existing best results, including ensembles by over 2 BLEU. \nOn the WMT 2014 English-to-French translation task, our model establishes \na new single-model state-of-the-art BLEU score of 41.8 after training for \n3.5 days on eight GPUs, a small fraction of the training costs of the \nbest models from the literature. We show that the Transformer \ngeneralizes well to other tasks by applying it successfully to \nEnglish constituency parsing both with large and limited training data.\n\n\"\"\"\n</code></pre> <pre><code>backprop = \"\"\"\nIn machine learning, backpropagation\n(backprop,[1] BP) is a widely used\nalgorithm for training feedforward\nartificial neural networks.\nGeneralizations of backpropagation\nexist for other artificial neural\nnetworks (ANNs), and for functions\ngenerally. These classes of algorithms\nare all referred to generically as\n\"backpropagation\".[2] In fitting a\nneural network, backpropagation\ncomputes the gradient of the loss\nfunction with respect to the weights of\nthe network for a single input\u2013output\nexample, and does so efficiently,\nunlike a naive direct computation of\nthe gradient with respect to each\nweight individually. This efficiency\nmakes it feasible to use gradient\nmethods for training multilayer\nnetworks, updating weights to minimize\nloss; gradient descent, or variants\nsuch as stochastic gradient descent,\nare commonly used. The backpropagation\nalgorithm works by computing the\ngradient of the loss function with\nrespect to each weight by the chain\nrule, computing the gradient one layer\nat a time, iterating backward from the\nlast layer to avoid redundant\ncalculations of intermediate terms in\nthe chain rule; this is an example of\ndynamic programming.[3]\n\"\"\"\n</code></pre> <pre><code># Wordsworth\nlucy = \"\"\"\nShe dwelt among the untrodden ways\nBeside the springs of Dove,\nA Maid whom there were none to praise\nAnd very few to love:\n\nA violet by a mossy stone\nHalf hidden from the eye!\n\u2014Fair as a star, when only one\nIs shining in the sky.\n\nShe lived unknown, and few could know\nWhen Lucy ceased to be;\nBut she is in her grave, and, oh,\nThe difference to me!\n\n\"\"\"\n\n# Davies\nfull_of_cares = \"\"\"\nWhat is this life if, full of care,\nWe have no time to stand and stare.\n\nNo time to stand beneath the boughs\nAnd stare as long as sheep or cows.\n\nNo time to see, when woods we pass,\nWhere squirrels hide their nuts in grass.\n\nNo time to see, in broad daylight,\nStreams full of stars, like skies at night.\n\nNo time to turn at Beauty's glance,\nAnd watch her feet, how they can dance.\n\nNo time to wait till her mouth can\nEnrich that smile her eyes began.\n\nA poor life this if, full of care,\nWe have no time to stand and stare.\n\n\n\"\"\"\n</code></pre> <pre><code>sentences = [\n    jabberwocky, best_of_times, last_dream, mystery, mark_twain_dog, einstein,\n    tweedledee, goldens_1, goldens_2, goldens_3, dog_soul, keats, attention, backprop, lucy, full_of_cares\n]\n</code></pre> <pre><code>\n</code></pre>"},{"location":"notebooks/examples/search-corpus/#toy-corpus-for-semantic-search","title":"Toy corpus for semantic search","text":"<p>Here, we create a toy corpus comprising of a few small document texts. Then we will make this the context of semantic search.</p>"},{"location":"notebooks/examples/semantic-search/","title":"Semantic search","text":"<pre><code>%run supportvectors-common.ipynb\n</code></pre>    \u00a9 SupportVectors. All rights reserved. This notebook is the intellectual property of SupportVectors, and part of its training material.  Only the participants in SupportVectors workshops are allowed to study the notebooks for educational purposes currently, but is prohibited from copying or using it for any other purposes without written permission.  <p> These notebooks are chapters and sections from Asif Qamar's textbook that he is writing on Data Science. So we request you to not circulate the material to others.</p> <pre>\n<code>\ud83c\udfaf Project root: /Users/asifqamar/github/rag_to_riches\n\ud83d\udcc1 Working directory: /Users/asifqamar/github/rag_to_riches\n\u2705 Ready to import rag_to_riches modules!\n</code>\n</pre> <pre><code>from sentence_transformers import SentenceTransformer\n\nMODEL = 'msmarco-distilbert-base-v4'\nembedder = SentenceTransformer(MODEL)\n</code></pre> <pre><code>%run docs/notebooks/examples/search-corpus.ipynb\n</code></pre> <pre><code>embeddings = embedder.encode(sentences, convert_to_tensor=True)\n</code></pre> <p>Note that we chose to get the embeddings as <code>pytorch</code> tensors -- this will help us later in doing high-performance searches over the GPU/TPU hardware. What do these embeddings look like? </p> <pre><code>embeddings.shape\n</code></pre> <pre>\n<code>torch.Size([16, 768])</code>\n</pre> <p>Clearly, there are 16 embeddings, each of a 768 dimensional vector. Let us glance at a sentence, and its embedding:</p> <pre><code>print (f'{sentences[0]}  {embeddings[0]}')\n</code></pre> <pre>\n<code>\n\u2019Twas brillig, and the slithy toves\n      Did gyre and gimble in the wabe:\nAll mimsy were the borogoves,\n      And the mome raths outgrabe.\n\n\u201cBeware the Jabberwock, my son!\n      The jaws that bite, the claws that catch!\nBeware the Jubjub bird, and shun\n      The frumious Bandersnatch!\u201d\n\nHe took his vorpal sword in hand;\n      Long time the manxome foe he sought\u2014\nSo rested he by the Tumtum tree\n      And stood awhile in thought.\n\nAnd, as in uffish thought he stood,\n      The Jabberwock, with eyes of flame,\nCame whiffling through the tulgey wood,\n      And burbled as it came!\n\nOne, two! One, two! And through and through\n      The vorpal blade went snicker-snack!\nHe left it dead, and with its head\n      He went galumphing back.\n\n\u201cAnd hast thou slain the Jabberwock?\n      Come to my arms, my beamish boy!\nO frabjous day! Callooh! Callay!\u201d\n      He chortled in his joy.\n\n\u2019Twas brillig, and the slithy toves\n      Did gyre and gimble in the wabe:\nAll mimsy were the borogoves,\n      And the mome raths outgrabe.\n\n  tensor([ 1.7917e-02,  3.2575e-01, -5.2674e-01, -4.5594e-01, -1.9075e-01,\n         1.2122e-01,  6.5697e-01,  3.6187e-01, -3.1310e-01,  4.4082e-01,\n         1.4342e-02,  2.6244e-01,  5.3394e-01,  1.0590e-01, -4.5185e-01,\n         1.2903e-01, -6.4802e-02, -1.5091e-01,  7.3926e-01, -5.1614e-01,\n         2.7852e-01,  2.7217e-02,  1.5634e-01,  3.4818e-01,  5.5325e-01,\n         3.8035e-01,  1.8087e-01,  4.8250e-01, -2.6185e-01, -1.3253e-01,\n        -3.6970e-01,  3.3219e-01,  1.6746e-01,  2.1851e-02,  2.8724e-01,\n         7.9401e-02, -3.2609e-01, -2.0288e-01, -5.9856e-01,  8.8381e-02,\n         2.5152e-01,  3.5598e-01,  4.8215e-02, -7.2606e-02,  1.9663e-01,\n        -3.8164e-02,  4.1078e-01,  1.4597e-01,  3.5012e-01, -4.9210e-01,\n         4.4801e-01,  9.7347e-03,  5.4350e-01, -2.7849e-01, -2.8385e-01,\n        -7.2804e-02,  2.6930e-01, -9.2220e-03,  2.5226e-01,  3.9880e-01,\n        -4.8472e-01, -5.0370e-01,  2.1162e-01,  4.4003e-01, -5.7341e-01,\n         3.1301e-01, -1.4083e-01,  2.2410e-01, -4.4437e-01, -1.8528e-01,\n         1.4232e-01, -4.4814e-01, -5.3232e-02,  1.1122e-01, -3.7606e-02,\n        -3.6722e-01, -7.7723e-03, -4.3455e-01, -1.4202e-01,  1.2595e-01,\n        -7.6096e-02, -2.7487e-01,  2.0302e-01,  4.0621e-01, -4.9196e-02,\n        -7.9096e-01,  2.9097e-01,  6.0802e-01, -3.7323e-01,  2.4245e-01,\n        -6.5203e-02, -5.9707e-01, -1.9272e-01,  3.3305e-01, -2.1034e-01,\n         2.2604e-01, -5.0660e-01,  2.1707e-01,  1.8715e-01,  3.8112e-01,\n         2.5473e-01,  1.6069e-01,  2.1520e-01,  2.9177e-01, -4.9131e-01,\n         4.0516e-02, -2.2139e-01, -4.2588e-02,  1.2716e-01,  1.5987e-01,\n         2.5544e-01, -2.9770e-01, -1.3194e-01,  1.5549e-02,  5.0884e-01,\n         4.0749e-01, -2.1452e-01, -3.0160e-01, -3.1604e-01, -1.7183e-01,\n         8.1062e-01, -5.2953e-02,  2.7273e-01, -5.1342e-01,  4.2006e-01,\n        -3.6531e-01, -7.3516e-02, -1.2260e-02, -1.7089e-01, -1.3319e-01,\n         1.3879e-01,  9.8377e-01,  3.1317e-02,  1.2674e-01,  6.2551e-02,\n         1.0961e-02,  5.3247e-01, -1.7293e-01, -4.7855e-01, -1.8883e-01,\n        -3.1886e-02,  2.3251e-02, -6.8862e-02,  6.1711e-01,  3.1547e-01,\n        -1.0787e-01, -4.6169e-01, -3.2052e-01, -9.7469e-02,  5.3235e-01,\n        -1.9616e-01,  3.4646e-02, -3.6577e-01,  2.9087e-01,  2.2671e-01,\n         2.1960e-01,  1.8154e-01,  4.0864e-01,  3.7546e-01,  1.1521e-01,\n        -3.8926e-01, -1.4973e-01,  7.6049e-02, -6.7651e-02,  1.7376e-01,\n        -1.3123e-01, -3.1742e-01, -2.8624e-01, -1.5841e-02, -1.4196e-01,\n         1.0881e-01, -5.8047e-01,  4.4365e-01,  2.4115e-01,  5.4083e-02,\n        -5.3161e-01,  1.6474e-01, -2.9610e-01, -4.0890e-01, -2.1082e-01,\n        -5.2382e-01, -5.5760e-01,  1.2510e-01, -1.3824e-02,  4.2349e-02,\n         2.1822e-01, -7.5218e-02, -2.3979e-01, -5.7186e-01,  8.4367e-02,\n        -1.2576e-01, -4.2887e-02,  5.5928e-01,  1.0654e-01,  8.9991e-02,\n        -2.3590e-01,  1.9082e-01, -5.8835e-01,  1.7601e-01, -3.4115e-01,\n         2.2822e-02, -5.3441e-02, -3.5236e-01,  1.1238e-01,  6.1241e-02,\n         1.2119e-01, -3.2559e-01,  2.0884e-01,  3.3277e-02,  9.3340e-03,\n         4.4278e-01, -1.8672e-01, -1.2111e-01, -5.6136e-02, -1.2680e-01,\n         1.6150e-01,  2.3153e-01,  1.8705e-01,  1.1947e-01, -2.5572e-01,\n        -9.2670e-01, -6.9634e-02,  8.8565e-02, -5.9111e-01,  2.7490e-01,\n         8.0624e-01, -3.2596e-01, -6.9462e-02, -6.4609e-01,  1.6149e-01,\n        -3.6439e-01,  3.9385e-02, -7.1675e-02,  1.9714e-01,  4.1333e-01,\n        -2.1131e-01, -2.6286e-01, -2.9745e-01, -1.6346e-01, -1.1724e-01,\n        -4.7544e-01, -4.3545e-01,  3.7928e-02,  3.0695e-01, -1.3773e-02,\n        -2.0251e-02,  4.0708e-01, -1.1449e-03,  3.1819e-01,  1.8085e-01,\n         4.6539e-01,  2.1454e-02, -4.0807e-02, -2.8014e-01, -2.7622e-01,\n         6.6179e-02, -1.8675e-01, -7.5373e-01,  2.1418e-02,  3.1014e-01,\n         3.9646e-01,  4.0270e-01,  4.3578e-01,  1.8946e-01, -5.6522e-02,\n         7.1969e-01,  2.6049e-01,  1.7067e-01,  2.4791e-01, -2.3705e-01,\n        -5.5931e-02,  1.7301e-02,  1.6413e-01,  4.0594e-01,  1.6504e-01,\n         7.5399e-02, -1.1570e-01, -2.4189e-01, -7.6809e-02,  6.3858e-02,\n        -3.0081e-01,  7.4117e-01, -6.9915e-01, -1.4235e-01, -1.9157e-01,\n        -8.2039e-02,  5.7404e-01,  3.2158e-01,  2.7205e-01, -2.1700e-01,\n         2.9987e-02,  7.9279e-01,  6.1427e-01, -5.1989e-02, -5.8224e-01,\n        -8.6438e-04,  1.5717e-01,  1.0860e-01,  2.2685e-01,  3.0562e-01,\n        -2.3346e-01,  1.5908e-01, -5.7816e-01,  1.6771e-01, -3.8282e-01,\n        -2.4983e-01, -1.9433e-01, -1.5392e-01, -1.7070e+00,  2.6598e-01,\n         1.1801e-01, -2.2074e-01,  6.3294e-01,  3.6595e-01, -9.0836e-02,\n         1.1078e-01,  5.9197e-03, -1.8070e-02, -2.4574e-01, -5.4478e-01,\n         6.0092e-01, -2.2873e-01,  2.3063e-01, -6.8054e-01, -2.9629e-01,\n        -3.2019e-01,  3.4550e-01, -6.7519e-01,  1.9262e-01,  2.3385e-04,\n         9.4906e-02, -5.4170e-01, -2.9485e-01,  1.7789e-01,  4.3582e-01,\n        -1.5583e-01, -4.0829e-02,  1.7331e-01, -2.2900e-01,  4.2604e-01,\n         2.2739e-01,  2.9901e-02,  1.2950e-02, -3.8811e-02,  5.0931e-01,\n        -6.9910e-02, -6.8597e-02, -1.0675e-01, -6.8135e-03,  2.3347e-01,\n        -5.0954e-01,  2.2618e-01,  3.1839e-01, -4.5075e-02, -5.2840e-01,\n        -3.6180e-01,  6.9245e-01, -4.7528e-03, -3.2137e-01, -2.2106e-01,\n        -2.1965e-01, -1.4922e-01,  1.5394e-01, -3.2444e-02, -1.9035e-01,\n        -7.6164e-03,  5.0208e-02, -5.5047e-01, -3.2601e-02,  2.8282e-01,\n         2.7266e-02, -2.8430e-01,  4.8848e-02,  3.3134e-01,  3.7561e-02,\n         2.4394e-01,  8.3384e-03, -1.2271e-02, -1.4590e-02, -3.1226e-01,\n        -4.0161e-02, -5.0416e-01,  3.6569e-01,  1.0153e+00,  1.9811e-02,\n         7.8769e-04,  2.7361e-01, -4.2070e-01, -3.8222e-01, -4.2397e-01,\n         2.5626e-01, -5.2781e-01, -3.4484e-01, -5.6268e-01,  1.2261e-01,\n        -3.9935e-01,  5.1999e-02, -5.5470e-01,  8.0129e-02, -2.2590e-02,\n        -7.6713e-01,  7.7694e-01,  3.2428e-01,  1.9949e-01,  5.5646e-01,\n         2.2864e-02,  6.8620e-02,  4.1802e-01,  3.9969e-01, -6.4930e-02,\n        -3.4573e-02, -7.8673e-02,  4.0344e-01, -1.6961e-01, -2.0254e-03,\n        -3.9754e-02, -2.6265e-01,  2.7204e-01,  1.5872e-02, -2.3830e-01,\n         1.8041e-01,  5.5454e-01, -5.0322e-01, -2.1440e-01, -3.6038e-01,\n        -2.8141e-01,  2.3926e-01,  1.5952e-01,  1.3700e-01,  1.9691e-01,\n         1.0487e-01,  1.2944e-01,  1.6427e-01, -4.3116e-01, -1.4120e-01,\n        -1.9606e-01, -2.3791e-01, -2.8282e-01, -3.0180e-01, -2.0097e-01,\n        -2.8438e-01, -7.9646e-02,  4.1995e-01,  5.7060e-02, -7.0792e-01,\n        -6.1364e-01,  2.9859e-01, -3.2533e-01, -7.5628e-02, -3.6611e-02,\n         4.6359e-01,  2.8782e-01,  3.4186e-02,  3.3679e-01,  1.0767e-01,\n        -1.0526e-01, -2.7351e-01,  3.6651e-01, -5.9686e-01,  5.0702e-02,\n         2.0827e-01, -3.3547e-01,  1.3994e-01,  7.5079e-02, -2.9489e-01,\n        -1.8911e-01,  4.0929e-01,  5.2650e-01, -8.5071e-02,  3.8760e-01,\n         2.3798e-01,  7.0253e-01,  1.3223e-01, -4.7596e-01,  1.5318e-01,\n        -2.2118e-01, -2.0028e-02, -1.9628e-01, -2.6742e-01,  5.7637e-02,\n        -1.6170e-01,  8.3750e-01, -3.9614e-01,  4.1609e-01, -3.2807e-02,\n         5.1721e-02, -4.4778e-01,  3.5607e-01,  1.9781e-01,  3.0608e-01,\n        -4.2100e-01,  4.2799e-01,  3.2833e-01, -1.2995e-01, -2.2661e-01,\n        -1.9074e-01, -5.5467e-01,  2.6481e-01, -2.7469e-01,  5.6599e-02,\n         4.0208e-01, -1.7044e-01, -5.2993e-01,  6.1364e-02, -2.6243e-01,\n        -2.6289e-02, -2.4756e-01, -7.5067e-02,  4.9017e-01, -2.1801e-01,\n        -1.2747e-01, -3.4201e-02, -2.5892e-01, -3.5188e-01, -6.7000e-02,\n        -4.2172e-01,  1.4296e-01, -4.1184e-01, -9.4296e-04, -6.4984e-01,\n        -1.2443e-01, -2.2977e-02,  3.1080e-01, -5.3202e-01,  9.2309e-02,\n         5.1738e-01,  1.6357e-01,  4.1306e-02, -7.2864e-02, -1.8374e-01,\n        -9.1456e-02,  8.7033e-02, -5.2140e-01,  8.4393e-01, -2.6657e-01,\n         4.1124e-01,  2.2357e-01, -1.9583e-01,  3.4919e-01, -6.0420e-01,\n        -3.4275e-01,  1.7922e-01,  7.1702e-01, -6.5519e-02,  3.3226e-01,\n         1.9494e-01,  3.7075e-01,  4.8286e-01,  8.6542e-01,  1.9256e-01,\n         1.8797e-02,  8.1855e-01, -4.3893e-01,  2.1546e-01, -3.0848e-01,\n         2.5845e-01, -2.6430e-01,  2.7694e-01,  1.3315e-01,  9.5527e-01,\n         1.5193e-01, -1.4842e-01,  3.9241e-01,  3.5782e-01, -5.9792e-01,\n         1.1726e-01,  1.3109e-01, -3.5268e-01, -3.0282e-01,  4.1247e-02,\n         3.6656e-01, -1.8282e-02,  9.7260e-03, -2.4284e-01,  1.1514e-01,\n         1.3559e-01, -1.8612e-01,  3.1848e-01,  1.9259e-01, -3.0652e-01,\n        -5.2179e-01, -1.8819e-01, -1.0093e-01,  2.0414e-01, -3.2664e-01,\n        -3.6530e-01,  1.5873e-01, -5.5727e-01, -1.9240e-01,  4.5441e-02,\n        -1.7976e-01, -3.1875e-01, -7.1592e-01,  2.6829e-02,  2.9293e-01,\n         2.5408e-02, -9.0682e-02, -3.0221e-01,  1.2896e-01, -4.5249e-02,\n        -2.7396e-01,  2.4501e-02,  1.0130e-01,  1.0020e-01,  2.7701e-01,\n        -3.0467e-01, -1.0260e-01,  2.8172e-01,  2.3085e-02,  5.7836e-02,\n         6.0795e-01, -6.0961e-01, -2.4893e-02, -5.0576e-02,  5.5406e-02,\n         1.2906e-02, -2.0817e-01,  2.4534e-01, -2.2500e-01,  2.9426e-02,\n        -2.7480e-01,  7.4730e-01,  1.8980e-01,  2.5081e-01,  1.5851e-01,\n        -4.0235e-01, -1.6969e-01, -3.7136e-01,  7.6890e-02, -8.5676e-01,\n         1.2352e-01, -2.4541e-01,  1.3273e-01,  1.0319e-03, -1.5147e-01,\n         2.7888e-02, -2.3935e-02, -3.5993e-01, -3.2950e-01,  2.2789e-01,\n         2.5615e-02, -4.4394e-02, -1.2734e-01,  5.5925e-01,  2.4509e-01,\n        -3.9563e-01,  4.0246e-01,  8.5918e-02,  2.3930e-01,  5.5554e-02,\n         1.5976e-01,  3.1305e-01, -6.9706e-02, -2.4159e-01,  5.3633e-01,\n         2.5338e-02,  2.1870e-01,  7.3817e-02, -5.9284e-01,  3.9119e-01,\n        -2.6954e-01, -3.6437e-03,  4.2445e-01, -3.6671e-01, -2.2968e-01,\n         2.2761e-01,  2.0409e-01,  9.7983e-02,  3.0123e-01,  4.2016e-01,\n        -2.9227e-01,  1.8621e-01, -7.0845e-02,  5.2205e-02, -6.8265e-01,\n         2.2897e-01, -1.5891e-02,  2.4238e-01,  1.0389e+00,  6.2297e-01,\n         3.1147e-01, -3.1041e-01, -6.5775e-01,  8.6017e-02, -3.3830e-02,\n        -7.7502e-02, -1.6662e-01, -3.8203e-01,  5.9171e-02,  3.4376e-01,\n        -1.3236e-01,  3.9207e-01,  4.5186e-01, -2.7197e-01, -4.3461e-02,\n        -1.0711e-02,  1.9661e-01, -3.6862e-01,  3.2772e-02, -3.8254e-01,\n        -2.6337e-01,  7.3939e-02, -2.2048e-01, -3.3578e-01,  3.9128e-01,\n         5.8405e-01, -9.8724e-02,  6.2789e-01,  3.0186e-01,  2.6917e-01,\n        -6.3461e-01,  2.4154e-01,  4.7397e-01,  3.4264e-01,  6.6854e-02,\n        -1.0252e-01,  8.5942e-02, -1.4061e-01,  5.3254e-01,  5.5319e-01,\n        -3.1108e-03, -5.7683e-02, -9.4840e-02, -5.5374e-01, -1.0431e-01,\n        -6.4141e-01, -3.6586e-01,  3.1126e-02, -4.1912e-01, -8.1661e-02,\n         1.0081e-01,  4.0771e-02, -1.4054e-01, -1.4227e-01,  1.3890e-01,\n         3.7653e-01,  1.2723e-01, -4.6420e-01,  1.1746e-01,  7.3600e-02,\n         5.3363e-01, -6.5410e-01,  4.5491e-01,  3.2288e-01, -4.9433e-01,\n        -2.1253e-01,  2.3369e-01, -7.7339e-01,  5.9050e-01, -4.0324e-01,\n         3.8141e-01,  3.2117e-01, -9.5685e-01, -4.8296e-01,  5.1497e-01,\n        -2.8551e-02,  1.2886e-01, -2.1897e-02,  1.9964e-02,  5.5359e-02,\n        -4.9937e-01,  4.3293e-01,  2.4391e-01,  2.6040e-01, -4.2516e-02,\n         5.2210e-01,  4.4372e-01,  8.3467e-02], device='mps:0')\n</code>\n</pre> <pre><code>query_text = \"a friendship with animals\"\nquery = embedder.encode(query_text, convert_to_tensor=True)\n</code></pre> <pre><code>from sentence_transformers import util\nsearch_results = util.semantic_search(query, embeddings, top_k = 3)\nsearch_results\n</code></pre> <pre>\n<code>[[{'corpus_id': 7, 'score': 0.2550491392612457},\n  {'corpus_id': 8, 'score': 0.23244601488113403},\n  {'corpus_id': 5, 'score': 0.21887624263763428}]]</code>\n</pre> <pre><code>for index, result in enumerate(search_results[0]):\n    print('-'*80)\n    print(f'Search Rank: {index}, Relevance score: {result[\"score\"]} ')\n    print(sentences[result['corpus_id']])\n</code></pre> <pre>\n<code>--------------------------------------------------------------------------------\nSearch Rank: 0, Relevance score: 0.2550491392612457 \n\nGolden retrievers are not bred to be guard dogs, and considering the size of their hearts and their irrepressible joy and life, they are less likely to bite than to bark, less likely to bark than to lick a hand in greeting. In spite of their size, they think they are lap dogs, and in spite of being dogs, they think they\u2019re also human, and nearly every human they meet is judged to have the potential to be a boon companion who might at any moment, cry, \u201cLet\u2019s go!\u201d and lead them on a great adventure.\n\n--------------------------------------------------------------------------------\nSearch Rank: 1, Relevance score: 0.23244601488113403 \n\nIf you\u2019re lucky, a golden retriever will come into your life, steal your heart, and change everything\n\n--------------------------------------------------------------------------------\nSearch Rank: 2, Relevance score: 0.21887624263763428 \nIf a man aspires towards a righteous life, his first act of abstinence is from injury to animals.\n</code>\n</pre> <pre><code>from PIL import Image\n# Create the model\nCLIP_MODEL = 'clip-ViT-B-32'\nembedder = SentenceTransformer(CLIP_MODEL)\n\n# We need to take smaller text, for CLIP to work. (current limitation)\nshort_sentences = [\n    'A smiling dog', 'House with a chimney', 'Car on a highway',\n    'Elephant in the field', 'Attention is all you need',\n    'Golden retrievers are little children', 'A cat on the window sill',\n    'For the love of these furry dogs'\n]\n# Create the search index of embeddings\nembeddings = embedder.encode(short_sentences, convert_to_tensor=True)\nembeddings.shape\n</code></pre> <pre>\n<code>Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n</code>\n</pre> <pre>\n<code>torch.Size([8, 512])</code>\n</pre> <pre><code>query = embedder.encode(Image.open('docs/notebooks/examples/images/dog.jpeg'))\n</code></pre> <pre><code>from sentence_transformers import util\nsearch_results = util.semantic_search(query, embeddings, top_k = 3)\nsearch_results\n</code></pre> <pre>\n<code>[[{'corpus_id': 5, 'score': 0.26934415102005005},\n  {'corpus_id': 7, 'score': 0.250542014837265},\n  {'corpus_id': 0, 'score': 0.24075108766555786}]]</code>\n</pre> <pre><code>for index, result in enumerate(search_results[0]):\n    print('-'*80)\n    print(f'Search Rank: {index}, Relevance score: {result[\"score\"]} ')\n    print(short_sentences[result['corpus_id']])\n</code></pre> <pre>\n<code>--------------------------------------------------------------------------------\nSearch Rank: 0, Relevance score: 0.26934415102005005 \nGolden retrievers are little children\n--------------------------------------------------------------------------------\nSearch Rank: 1, Relevance score: 0.250542014837265 \nFor the love of these furry dogs\n--------------------------------------------------------------------------------\nSearch Rank: 2, Relevance score: 0.24075108766555786 \nA smiling dog\n</code>\n</pre> <pre><code># Taken almost verbatim from the above-mentioned resource.\nfrom PIL import Image\nimport glob\nimport torch\nimport pickle\nimport zipfile\nfrom IPython.display import display\nfrom IPython.display import Image as IPImage\nimport os\nfrom tqdm.autonotebook import tqdm\ntorch.set_num_threads(4)\n\nimg_folder = 'docs/notebooks/examples/photos/'\nif not os.path.exists(img_folder) or len(os.listdir(img_folder)) == 0:\n    os.makedirs(img_folder, exist_ok=True)\n\n    print(\"Path does not exist! Creating it...\")\n\n    photo_filename = 'unsplash-25k-photos.zip'\n    if not os.path.exists(photo_filename):   #Download dataset if does not exist\n        util.http_get('http://sbert.net/datasets/'+photo_filename, photo_filename)\n\n    #Extract all images\n    with zipfile.ZipFile(photo_filename, 'r') as zf:\n        for member in tqdm(zf.infolist(), desc='Extracting'):\n            zf.extract(member, img_folder)\n</code></pre> <pre><code># Once again, this code is taken from the sample notebook mentioned above.\n\nmodel = SentenceTransformer('clip-ViT-B-32')\nuse_precomputed_embeddings = True\n\nif use_precomputed_embeddings:\n    emb_filename = 'unsplash-25k-photos-embeddings.pkl'\n    if not os.path.exists(emb_filename):  #Download dataset if does not exist\n        util.http_get('http://sbert.net/datasets/' + emb_filename,\n                      emb_filename)\n\n    with open(emb_filename, 'rb') as fIn:\n        img_names, img_emb = pickle.load(fIn)\n    print(\"Images:\", len(img_names))\nelse:\n    img_names = list(glob.glob('unsplash/photos/*.jpg'))\n    print(\"Images:\", len(img_names))\n    img_emb = model.encode([Image.open(filepath) for filepath in img_names],\n                           batch_size=128,\n                           convert_to_tensor=True,\n                           show_progress_bar=True)\n</code></pre> <pre>\n<code>  0%|          | 0.00/51.8M [00:00&lt;?, ?B/s]</code>\n</pre> <pre>\n<code>Images: 24996\n</code>\n</pre> <pre><code>import ipyplot\n</code></pre> <pre><code># Let us define a search function\nfrom typing import Union\ndef search(query: str, is_image: bool = False, k:int = 8):    \n    raw = Image.open(query) if is_image else query\n    query_emb = model.encode([raw], convert_to_tensor=True, show_progress_bar=False)\n\n    # Then, we use the util.semantic_search function, which computes the cosine-similarity\n    # between the query embedding and all image embeddings.\n    # It then returns the top_k highest ranked images, which we output\n    hits = util.semantic_search(query_emb, img_emb, top_k=k)[0]\n\n    print(\"Query:\")\n    img_folder = \"photos/\"\n    print(img_folder)\n\n    display(raw) if is_image else display(query)\n    images = [os.path.join(img_folder, img_names[hit['corpus_id']]) for hit in hits]\n    ipyplot.plot_images(images, max_images=30, img_width=150, show_url=False)\n</code></pre> <pre><code>search('To love a dog')\n</code></pre> <pre>\n<code>Query:\nphotos/\n</code>\n</pre> <pre>\n<code>'To love a dog'</code>\n</pre> show html 0 <pre><code>&lt;div class=\"ipyplot-placeholder-div-dhWFgxPbjyEzjoRpTxdQ65\"&gt;\n    &lt;div class=\"ipyplot-content-div-dhWFgxPbjyEzjoRpTxdQ65\" id=\"ipyplot-content-div-dhWFgxPbjyEzjoRpTxdQ65-fp8ELge65UHoiqicuFwDSh\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;1&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/shlVdvnZIH0.jpg\"&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-dhWFgxPbjyEzjoRpTxdQ65-fp8ELge65UHoiqicuFwDSh\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/img&gt;\n</code></pre> <pre><code>\n</code></pre> <pre><code>&lt;div class=\"ipyplot-placeholder-div-dhWFgxPbjyEzjoRpTxdQ65\"&gt;\n    &lt;div class=\"ipyplot-content-div-dhWFgxPbjyEzjoRpTxdQ65\" id=\"ipyplot-content-div-dhWFgxPbjyEzjoRpTxdQ65-oSa2PuFDTFMg7r8S2wyAKS\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;2&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/p0SHEPp-xPI.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-dhWFgxPbjyEzjoRpTxdQ65-oSa2PuFDTFMg7r8S2wyAKS\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n</code></pre> <pre><code>\n</code></pre> <pre><code>&lt;div class=\"ipyplot-placeholder-div-dhWFgxPbjyEzjoRpTxdQ65\"&gt;\n    &lt;div class=\"ipyplot-content-div-dhWFgxPbjyEzjoRpTxdQ65\" id=\"ipyplot-content-div-dhWFgxPbjyEzjoRpTxdQ65-SGgh4HhzHCkM66JPDmaLSE\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;3&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/yCKKd37OsgI.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-dhWFgxPbjyEzjoRpTxdQ65-SGgh4HhzHCkM66JPDmaLSE\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div class=\"ipyplot-placeholder-div-dhWFgxPbjyEzjoRpTxdQ65\"&gt;\n    &lt;div class=\"ipyplot-content-div-dhWFgxPbjyEzjoRpTxdQ65\" id=\"ipyplot-content-div-dhWFgxPbjyEzjoRpTxdQ65-RUhKAMnpLVhHtzZ3yMxZKU\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;4&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/p_GQJIMtj4c.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-dhWFgxPbjyEzjoRpTxdQ65-RUhKAMnpLVhHtzZ3yMxZKU\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div class=\"ipyplot-placeholder-div-dhWFgxPbjyEzjoRpTxdQ65\"&gt;\n    &lt;div class=\"ipyplot-content-div-dhWFgxPbjyEzjoRpTxdQ65\" id=\"ipyplot-content-div-dhWFgxPbjyEzjoRpTxdQ65-QvfVeHvcreRHySWhHDTqcS\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;5&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/ClkQd4-ZfSQ.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-dhWFgxPbjyEzjoRpTxdQ65-QvfVeHvcreRHySWhHDTqcS\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div class=\"ipyplot-placeholder-div-dhWFgxPbjyEzjoRpTxdQ65\"&gt;\n    &lt;div class=\"ipyplot-content-div-dhWFgxPbjyEzjoRpTxdQ65\" id=\"ipyplot-content-div-dhWFgxPbjyEzjoRpTxdQ65-mVC4Ck8ATUfWgdQvNrNht8\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;6&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/rFvlfJCKqEU.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-dhWFgxPbjyEzjoRpTxdQ65-mVC4Ck8ATUfWgdQvNrNht8\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div class=\"ipyplot-placeholder-div-dhWFgxPbjyEzjoRpTxdQ65\"&gt;\n    &lt;div class=\"ipyplot-content-div-dhWFgxPbjyEzjoRpTxdQ65\" id=\"ipyplot-content-div-dhWFgxPbjyEzjoRpTxdQ65-6mmJZ6UaHRGyxnKFaH2kwf\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;7&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/Etobk5T7C_s.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-dhWFgxPbjyEzjoRpTxdQ65-6mmJZ6UaHRGyxnKFaH2kwf\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n    &lt;/textarea&gt;\n</code></pre> <p> </p>"},{"location":"notebooks/examples/semantic-search/#semantic-search","title":"Semantic search","text":"<p>Traditionally, one would search through a corpus of documents using a keywords-based search engine like Lucene, Solr, ElasticSearch, etc. While the technology has matured, the basic underlying approach behind keyword search engines is to maintain an inverted-index mapping keywords to a list of documents that contain them, with associated relevances.</p> <p>In general, the keywords-based search approach has been quite successful over the years, and have matured with added features and linguistic capabilities.</p> <p>However, this approach has had its limitations. The principal cause of it goes to the fact that when we enter keywords, it is a human tendency to describe the intent of what we are looking for. For example, if we enter \"breakfast places\", we implicitly also mean restaurants, cafe, etc that serve items appropriate for breakfast. There may be a restaurant described as a shop for expresso, or crepe, that a keywords-search will likely miss, since its keywords do not match the query terms. And yet, we would hope to see it near the top of the search results.</p> <p>Semantic search is an NLP approach largely relying on deep-neural networks, and in particular, the transformers that make it possible to more closely infer the human intent behind the search terms, the relationship between the words, and the underlying context. It allows for entire sentences -- and even paragraphs -- describing what the searcher's intent is, and retrieves results more relevant or aligned to it.</p>"},{"location":"notebooks/examples/semantic-search/#how-would-we-do-this-nlp-task-with-ai","title":"How would we do this NLP task with AI?","text":"<p>Let us represent the functional behavior we expect: </p> <p></p>"},{"location":"notebooks/examples/semantic-search/#magic-happens-breaking-it-down-into-steps","title":"Magic happens: breaking it down into steps","text":"<p>We recall that machine-learning algorithms work with vectors (\\(\\mathbf{X}\\)) representation of data.</p> <p>So the first order of business would be to map each of the document texts \\(D_i\\) to its corresponding vector \\(X_i\\) in an appropriate \\(d\\)-dimensional space, \\(\\mathbb{R}^d\\), i.e.</p> \\[\\begin{equation} D_i \\longrightarrow X_i \\in \\mathbb{R}^d \\end{equation}\\] <p>This resulting vectors are called sentence embeddings. Once these embeddings are for each of the documents, we can store the collection of tuples \\([&lt;d_1, x_1=\"\"&gt;, &lt;d_2, x_2=\"\"&gt;, ..., &lt;d_n, x_n=\"\"&gt;]\\). Here each tuple corresponds to a document and its sentence embedding.</p> <p>This collection of tuples, therefore, becomes our search index.</p>"},{"location":"notebooks/examples/semantic-search/#search","title":"Search","text":"<p>Now, when the user described what she is looking for, we consider the entire text as a \"sentence\".</p> <p> </p> Caveat Emptor  &gt; Note that we have a rather relaxed definition of a *sentence* in NLP: it diverges from a grammmatical definition of a sentence somewhat.  For example, in the English language, we would consider a sentence to be terminated with a punctuation, such as a period, question-mark or exclamation. However, in NLP, we loosely consider the entire text -- whether it is just a word, or a few keywords, or an english sentence, or a few sentences together -- as one **sentence** for the purposes of natual language processing task.  <p> </p> <p>Therefore, it is common to consider an entire document text as a sentence if the text is relatively short. Alternatively, it is partitioned into smaller chunks (of say 512-tokens each), and each such chunk is considered an NLP sentence.</p> <p>Since we consider the entire query text as a sentence, we can map it to its sentence embedding vector, \\({Q}\\).</p>"},{"location":"notebooks/examples/semantic-search/#vector-similarity","title":"Vector Similarity00000","text":"<p>Once we have this, we simply need to compare the query vector \\({Q}\\) with each of the document vectors \\(X_i\\), and sort the document vectors in descending order of similarity.</p> <p>The rest is trivial: pick the top-k  in the sorted document vectors list. Then for each vector, look up its corresponding document, and return the list as sorted search result of relevant document.</p> <p>We expect that these documents will exhibit high semantic similarity with the search query, assuming that the search index did contain such documents.</p>  Semantic similarity as vector proximity in the embedding space.      (Figure source: Sbert.net documentation).      <p> </p> <pre><code>search('House near a lake')\n</code></pre> <pre>\n<code>Query:\nphotos/\n</code>\n</pre> <pre>\n<code>'House near a lake'</code>\n</pre> show html <pre><code>&lt;div class=\"ipyplot-placeholder-div-5hexuq99jk4nxM6XX6E2DF\"&gt;\n    &lt;div class=\"ipyplot-content-div-5hexuq99jk4nxM6XX6E2DF\" id=\"ipyplot-content-div-5hexuq99jk4nxM6XX6E2DF-YG5CtTM9jWzW6FtufqvrxN\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;1&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/UvdzJDxcJg4.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-5hexuq99jk4nxM6XX6E2DF-YG5CtTM9jWzW6FtufqvrxN\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n</code></pre> <pre><code>\n</code></pre> <pre><code>&lt;div class=\"ipyplot-placeholder-div-5hexuq99jk4nxM6XX6E2DF\"&gt;\n    &lt;div class=\"ipyplot-content-div-5hexuq99jk4nxM6XX6E2DF\" id=\"ipyplot-content-div-5hexuq99jk4nxM6XX6E2DF-cqDe93QdCr3nX7dLTAUgjb\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;2&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/qRkXDXy0XWc.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-5hexuq99jk4nxM6XX6E2DF-cqDe93QdCr3nX7dLTAUgjb\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n</code></pre> <pre><code>\n</code></pre> <pre><code>&lt;div class=\"ipyplot-placeholder-div-5hexuq99jk4nxM6XX6E2DF\"&gt;\n    &lt;div class=\"ipyplot-content-div-5hexuq99jk4nxM6XX6E2DF\" id=\"ipyplot-content-div-5hexuq99jk4nxM6XX6E2DF-KDiD6QrQJJ32WapdCPSBfG\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;3&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/22o6p17bCtQ.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-5hexuq99jk4nxM6XX6E2DF-KDiD6QrQJJ32WapdCPSBfG\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div class=\"ipyplot-placeholder-div-5hexuq99jk4nxM6XX6E2DF\"&gt;\n    &lt;div class=\"ipyplot-content-div-5hexuq99jk4nxM6XX6E2DF\" id=\"ipyplot-content-div-5hexuq99jk4nxM6XX6E2DF-D7heqoiw3DvfXiFzn8kMMD\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;4&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/tb6bpUQhPv0.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-5hexuq99jk4nxM6XX6E2DF-D7heqoiw3DvfXiFzn8kMMD\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div class=\"ipyplot-placeholder-div-5hexuq99jk4nxM6XX6E2DF\"&gt;\n    &lt;div class=\"ipyplot-content-div-5hexuq99jk4nxM6XX6E2DF\" id=\"ipyplot-content-div-5hexuq99jk4nxM6XX6E2DF-mZBD2MvvhXo9iwr2ytfkzi\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;5&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/cyPqQXNJsG8.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-5hexuq99jk4nxM6XX6E2DF-mZBD2MvvhXo9iwr2ytfkzi\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div class=\"ipyplot-placeholder-div-5hexuq99jk4nxM6XX6E2DF\"&gt;\n    &lt;div class=\"ipyplot-content-div-5hexuq99jk4nxM6XX6E2DF\" id=\"ipyplot-content-div-5hexuq99jk4nxM6XX6E2DF-AqWTzphNScXLTjSVkNXFsH\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;6&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/DWCbM1b_PbY.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-5hexuq99jk4nxM6XX6E2DF-AqWTzphNScXLTjSVkNXFsH\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div class=\"ipyplot-placeholder-div-5hexuq99jk4nxM6XX6E2DF\"&gt;\n    &lt;div class=\"ipyplot-content-div-5hexuq99jk4nxM6XX6E2DF\" id=\"ipyplot-content-div-5hexuq99jk4nxM6XX6E2DF-UQHkdbnmHpNwrs3XjFGrzm\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;7&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/ISa76M6l2Gc.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-5hexuq99jk4nxM6XX6E2DF-UQHkdbnmHpNwrs3XjFGrzm\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n    &lt;/textarea&gt;\n</code></pre> <p> </p> <p> </p> <pre><code>search('jumping dog')\n</code></pre> <pre>\n<code>Query:\nphotos/\n</code>\n</pre> <pre>\n<code>'jumping dog'</code>\n</pre> show html <pre><code>&lt;div class=\"ipyplot-placeholder-div-B9oywYR5te9w79jHLhbTPi\"&gt;\n    &lt;div class=\"ipyplot-content-div-B9oywYR5te9w79jHLhbTPi\" id=\"ipyplot-content-div-B9oywYR5te9w79jHLhbTPi-kpbuBs4WJCjzffNU8PEfLY\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;1&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/0-mijZQHh9g.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-B9oywYR5te9w79jHLhbTPi-kpbuBs4WJCjzffNU8PEfLY\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n</code></pre> <pre><code>\n</code></pre> <pre><code>&lt;div class=\"ipyplot-placeholder-div-B9oywYR5te9w79jHLhbTPi\"&gt;\n    &lt;div class=\"ipyplot-content-div-B9oywYR5te9w79jHLhbTPi\" id=\"ipyplot-content-div-B9oywYR5te9w79jHLhbTPi-9c8BGsUMK83CKWUz4e3JoQ\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;2&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/09iA8GzINiI.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-B9oywYR5te9w79jHLhbTPi-9c8BGsUMK83CKWUz4e3JoQ\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n</code></pre> <pre><code>\n</code></pre> <pre><code>&lt;div class=\"ipyplot-placeholder-div-B9oywYR5te9w79jHLhbTPi\"&gt;\n    &lt;div class=\"ipyplot-content-div-B9oywYR5te9w79jHLhbTPi\" id=\"ipyplot-content-div-B9oywYR5te9w79jHLhbTPi-Wq8i9zJN7ZqSKM7caejDtZ\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;3&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/U_5ePt5_IaU.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-B9oywYR5te9w79jHLhbTPi-Wq8i9zJN7ZqSKM7caejDtZ\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div class=\"ipyplot-placeholder-div-B9oywYR5te9w79jHLhbTPi\"&gt;\n    &lt;div class=\"ipyplot-content-div-B9oywYR5te9w79jHLhbTPi\" id=\"ipyplot-content-div-B9oywYR5te9w79jHLhbTPi-nG3sCc8Zw72JTrPkF4SPzY\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;4&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/Z8xcUWGJ9-Y.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-B9oywYR5te9w79jHLhbTPi-nG3sCc8Zw72JTrPkF4SPzY\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div class=\"ipyplot-placeholder-div-B9oywYR5te9w79jHLhbTPi\"&gt;\n    &lt;div class=\"ipyplot-content-div-B9oywYR5te9w79jHLhbTPi\" id=\"ipyplot-content-div-B9oywYR5te9w79jHLhbTPi-Yx895fQNhRPdLZmt2sPJ7r\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;5&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/Rvs6IR8cX6I.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-B9oywYR5te9w79jHLhbTPi-Yx895fQNhRPdLZmt2sPJ7r\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div class=\"ipyplot-placeholder-div-B9oywYR5te9w79jHLhbTPi\"&gt;\n    &lt;div class=\"ipyplot-content-div-B9oywYR5te9w79jHLhbTPi\" id=\"ipyplot-content-div-B9oywYR5te9w79jHLhbTPi-GmNv6f7iFP4RMdU4HwTYnV\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;6&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/iuqsjQ_GhCo.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-B9oywYR5te9w79jHLhbTPi-GmNv6f7iFP4RMdU4HwTYnV\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div class=\"ipyplot-placeholder-div-B9oywYR5te9w79jHLhbTPi\"&gt;\n    &lt;div class=\"ipyplot-content-div-B9oywYR5te9w79jHLhbTPi\" id=\"ipyplot-content-div-B9oywYR5te9w79jHLhbTPi-WSFLnLwaNMAHhkM2ZfwEaQ\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;7&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/aZox57cA-eI.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-B9oywYR5te9w79jHLhbTPi-WSFLnLwaNMAHhkM2ZfwEaQ\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n    &lt;/textarea&gt;\n</code></pre> <p> </p> <p> </p> <pre><code>search('Pathways through the forest')\n</code></pre> <pre>\n<code>Query:\nphotos/\n</code>\n</pre> <pre>\n<code>'Pathways through the forest'</code>\n</pre> show html <pre><code>&lt;div class=\"ipyplot-placeholder-div-iAzhHrFen7R3WYcNKtaGUx\"&gt;\n    &lt;div class=\"ipyplot-content-div-iAzhHrFen7R3WYcNKtaGUx\" id=\"ipyplot-content-div-iAzhHrFen7R3WYcNKtaGUx-9DtJZogvrtp6cCk52v8iZn\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;1&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/IXPydBrIkW0.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-iAzhHrFen7R3WYcNKtaGUx-9DtJZogvrtp6cCk52v8iZn\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n</code></pre> <pre><code>\n</code></pre> <pre><code>&lt;div class=\"ipyplot-placeholder-div-iAzhHrFen7R3WYcNKtaGUx\"&gt;\n    &lt;div class=\"ipyplot-content-div-iAzhHrFen7R3WYcNKtaGUx\" id=\"ipyplot-content-div-iAzhHrFen7R3WYcNKtaGUx-ncDG3ebYw67iDEBdE4GgwG\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;2&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/D5Qx3AbcGuM.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-iAzhHrFen7R3WYcNKtaGUx-ncDG3ebYw67iDEBdE4GgwG\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n</code></pre> <pre><code>\n</code></pre> <pre><code>&lt;div class=\"ipyplot-placeholder-div-iAzhHrFen7R3WYcNKtaGUx\"&gt;\n    &lt;div class=\"ipyplot-content-div-iAzhHrFen7R3WYcNKtaGUx\" id=\"ipyplot-content-div-iAzhHrFen7R3WYcNKtaGUx-8p2gKrnh7ARp5gghmNSwVo\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;3&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/-wqCp_SZ7ls.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-iAzhHrFen7R3WYcNKtaGUx-8p2gKrnh7ARp5gghmNSwVo\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div class=\"ipyplot-placeholder-div-iAzhHrFen7R3WYcNKtaGUx\"&gt;\n    &lt;div class=\"ipyplot-content-div-iAzhHrFen7R3WYcNKtaGUx\" id=\"ipyplot-content-div-iAzhHrFen7R3WYcNKtaGUx-mdavWwoEryHgGJ6TVpkuJd\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;4&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/f0mazn5tZf8.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-iAzhHrFen7R3WYcNKtaGUx-mdavWwoEryHgGJ6TVpkuJd\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div class=\"ipyplot-placeholder-div-iAzhHrFen7R3WYcNKtaGUx\"&gt;\n    &lt;div class=\"ipyplot-content-div-iAzhHrFen7R3WYcNKtaGUx\" id=\"ipyplot-content-div-iAzhHrFen7R3WYcNKtaGUx-kkzBgBo5h3Abm4cd3sUkPY\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;5&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/QBXgsc0U0Rc.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-iAzhHrFen7R3WYcNKtaGUx-kkzBgBo5h3Abm4cd3sUkPY\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div class=\"ipyplot-placeholder-div-iAzhHrFen7R3WYcNKtaGUx\"&gt;\n    &lt;div class=\"ipyplot-content-div-iAzhHrFen7R3WYcNKtaGUx\" id=\"ipyplot-content-div-iAzhHrFen7R3WYcNKtaGUx-aTMfHNqQMNBftKrmyBHTyD\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;6&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/S6ylG61p0T0.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-iAzhHrFen7R3WYcNKtaGUx-aTMfHNqQMNBftKrmyBHTyD\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div class=\"ipyplot-placeholder-div-iAzhHrFen7R3WYcNKtaGUx\"&gt;\n    &lt;div class=\"ipyplot-content-div-iAzhHrFen7R3WYcNKtaGUx\" id=\"ipyplot-content-div-iAzhHrFen7R3WYcNKtaGUx-25xgFMx6iNkg2iLBp4xQoD\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;7&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/3eq4ZKzGiQM.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-iAzhHrFen7R3WYcNKtaGUx-25xgFMx6iNkg2iLBp4xQoD\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n    &lt;/textarea&gt;\n</code></pre> <p> </p> <p> </p> <pre><code>car = 'docs/notebooks/examples/images/car.jpg'\nsearch(car, k=10, is_image=True)\n</code></pre> <pre>\n<code>Query:\nphotos/\n</code>\n</pre> show html <pre><code>&lt;div class=\"ipyplot-placeholder-div-o4RNnDdb3HPmuYBbP8C2tm\"&gt;\n    &lt;div class=\"ipyplot-content-div-o4RNnDdb3HPmuYBbP8C2tm\" id=\"ipyplot-content-div-o4RNnDdb3HPmuYBbP8C2tm-Z2PkjUzjmNe7mYBWhZPXCF\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;1&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/I1sF8NVAtf8.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-o4RNnDdb3HPmuYBbP8C2tm-Z2PkjUzjmNe7mYBWhZPXCF\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n</code></pre> <pre><code>\n</code></pre> <pre><code>&lt;div class=\"ipyplot-placeholder-div-o4RNnDdb3HPmuYBbP8C2tm\"&gt;\n    &lt;div class=\"ipyplot-content-div-o4RNnDdb3HPmuYBbP8C2tm\" id=\"ipyplot-content-div-o4RNnDdb3HPmuYBbP8C2tm-NPWfPDJCxK34GkuMxZmKEb\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;2&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/5Uvy1WMaUHw.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-o4RNnDdb3HPmuYBbP8C2tm-NPWfPDJCxK34GkuMxZmKEb\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n</code></pre> <pre><code>\n</code></pre> <pre><code>&lt;div class=\"ipyplot-placeholder-div-o4RNnDdb3HPmuYBbP8C2tm\"&gt;\n    &lt;div class=\"ipyplot-content-div-o4RNnDdb3HPmuYBbP8C2tm\" id=\"ipyplot-content-div-o4RNnDdb3HPmuYBbP8C2tm-8cQ4QsYCWe7rEZNFv3ZSo3\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;3&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/YBEyahCAcHU.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-o4RNnDdb3HPmuYBbP8C2tm-8cQ4QsYCWe7rEZNFv3ZSo3\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div class=\"ipyplot-placeholder-div-o4RNnDdb3HPmuYBbP8C2tm\"&gt;\n    &lt;div class=\"ipyplot-content-div-o4RNnDdb3HPmuYBbP8C2tm\" id=\"ipyplot-content-div-o4RNnDdb3HPmuYBbP8C2tm-ktQ9ze8wWR2HU4eKx4eGaF\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;4&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/xWeSCy5BdfI.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-o4RNnDdb3HPmuYBbP8C2tm-ktQ9ze8wWR2HU4eKx4eGaF\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div class=\"ipyplot-placeholder-div-o4RNnDdb3HPmuYBbP8C2tm\"&gt;\n    &lt;div class=\"ipyplot-content-div-o4RNnDdb3HPmuYBbP8C2tm\" id=\"ipyplot-content-div-o4RNnDdb3HPmuYBbP8C2tm-mAAQkKpE3LYgB9vSES96Kg\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;5&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/qLnrOTpo5bA.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-o4RNnDdb3HPmuYBbP8C2tm-mAAQkKpE3LYgB9vSES96Kg\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div class=\"ipyplot-placeholder-div-o4RNnDdb3HPmuYBbP8C2tm\"&gt;\n    &lt;div class=\"ipyplot-content-div-o4RNnDdb3HPmuYBbP8C2tm\" id=\"ipyplot-content-div-o4RNnDdb3HPmuYBbP8C2tm-f9eGzrGyV47QxBGwDR2U9q\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;6&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/UyjP9vIVPnk.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-o4RNnDdb3HPmuYBbP8C2tm-f9eGzrGyV47QxBGwDR2U9q\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div class=\"ipyplot-placeholder-div-o4RNnDdb3HPmuYBbP8C2tm\"&gt;\n    &lt;div class=\"ipyplot-content-div-o4RNnDdb3HPmuYBbP8C2tm\" id=\"ipyplot-content-div-o4RNnDdb3HPmuYBbP8C2tm-HpkwXjSeUFa4UVq8jQTxje\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;7&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/PkXHRgGSw4o.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-o4RNnDdb3HPmuYBbP8C2tm-HpkwXjSeUFa4UVq8jQTxje\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div class=\"ipyplot-placeholder-div-o4RNnDdb3HPmuYBbP8C2tm\"&gt;\n    &lt;div class=\"ipyplot-content-div-o4RNnDdb3HPmuYBbP8C2tm\" id=\"ipyplot-content-div-o4RNnDdb3HPmuYBbP8C2tm-96AYNSpJHfXrSEjnv5xQXc\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;8&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/7FY-hkN1TYo.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-o4RNnDdb3HPmuYBbP8C2tm-96AYNSpJHfXrSEjnv5xQXc\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div class=\"ipyplot-placeholder-div-o4RNnDdb3HPmuYBbP8C2tm\"&gt;\n    &lt;div class=\"ipyplot-content-div-o4RNnDdb3HPmuYBbP8C2tm\" id=\"ipyplot-content-div-o4RNnDdb3HPmuYBbP8C2tm-eSPq3HHsmB4e3zTeizbcPa\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;9&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/65SjWi7gTao.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-o4RNnDdb3HPmuYBbP8C2tm-eSPq3HHsmB4e3zTeizbcPa\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n    &lt;/textarea&gt;\n</code></pre> <p> </p> <p> </p> <pre><code>search(\"serenity\")\n</code></pre> <pre>\n<code>Query:\nphotos/\n</code>\n</pre> <pre>\n<code>'serenity'</code>\n</pre> show html <pre><code>&lt;div class=\"ipyplot-placeholder-div-dLbxDpeDsicCpudJ7Q3iDX\"&gt;\n    &lt;div class=\"ipyplot-content-div-dLbxDpeDsicCpudJ7Q3iDX\" id=\"ipyplot-content-div-dLbxDpeDsicCpudJ7Q3iDX-kBbcEsiX5TgKnxBESAg3t6\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;1&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/5wFcCUT9THY.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-dLbxDpeDsicCpudJ7Q3iDX-kBbcEsiX5TgKnxBESAg3t6\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n</code></pre> <pre><code>\n</code></pre> <pre><code>&lt;div class=\"ipyplot-placeholder-div-dLbxDpeDsicCpudJ7Q3iDX\"&gt;\n    &lt;div class=\"ipyplot-content-div-dLbxDpeDsicCpudJ7Q3iDX\" id=\"ipyplot-content-div-dLbxDpeDsicCpudJ7Q3iDX-3DDMwGXjvWDUM9phxLnP5f\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;2&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/jCL98LGaeoE.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-dLbxDpeDsicCpudJ7Q3iDX-3DDMwGXjvWDUM9phxLnP5f\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n</code></pre> <pre><code>\n</code></pre> <pre><code>&lt;div class=\"ipyplot-placeholder-div-dLbxDpeDsicCpudJ7Q3iDX\"&gt;\n    &lt;div class=\"ipyplot-content-div-dLbxDpeDsicCpudJ7Q3iDX\" id=\"ipyplot-content-div-dLbxDpeDsicCpudJ7Q3iDX-YigFjw6P6jZx8rdhkQaJ9U\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;3&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/vKQgcBsmFLQ.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-dLbxDpeDsicCpudJ7Q3iDX-YigFjw6P6jZx8rdhkQaJ9U\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div class=\"ipyplot-placeholder-div-dLbxDpeDsicCpudJ7Q3iDX\"&gt;\n    &lt;div class=\"ipyplot-content-div-dLbxDpeDsicCpudJ7Q3iDX\" id=\"ipyplot-content-div-dLbxDpeDsicCpudJ7Q3iDX-AMoHZShxaByCkZXVndXXwG\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;4&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/SmDX0AClqMU.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-dLbxDpeDsicCpudJ7Q3iDX-AMoHZShxaByCkZXVndXXwG\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div class=\"ipyplot-placeholder-div-dLbxDpeDsicCpudJ7Q3iDX\"&gt;\n    &lt;div class=\"ipyplot-content-div-dLbxDpeDsicCpudJ7Q3iDX\" id=\"ipyplot-content-div-dLbxDpeDsicCpudJ7Q3iDX-d6fAuNe57cuyA2jdLVq3ke\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;5&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/FuysnB0hYg4.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-dLbxDpeDsicCpudJ7Q3iDX-d6fAuNe57cuyA2jdLVq3ke\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div class=\"ipyplot-placeholder-div-dLbxDpeDsicCpudJ7Q3iDX\"&gt;\n    &lt;div class=\"ipyplot-content-div-dLbxDpeDsicCpudJ7Q3iDX\" id=\"ipyplot-content-div-dLbxDpeDsicCpudJ7Q3iDX-S3BgJD3X7VdC9rCDDgbYKY\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;6&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/9XRpNnTqdJE.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-dLbxDpeDsicCpudJ7Q3iDX-S3BgJD3X7VdC9rCDDgbYKY\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div class=\"ipyplot-placeholder-div-dLbxDpeDsicCpudJ7Q3iDX\"&gt;\n    &lt;div class=\"ipyplot-content-div-dLbxDpeDsicCpudJ7Q3iDX\" id=\"ipyplot-content-div-dLbxDpeDsicCpudJ7Q3iDX-dYQrJvbRXEqdotpdjGxuaj\"&gt;\n        &lt;h4 style=\"font-size: 12px; word-wrap: break-word;\"&gt;7&lt;/h4&gt;\n        &lt;img alt=\"No description has been provided for this image\" src=\"photos/JINHNZ9d9Nc.jpg\"/&gt;\n        &lt;a href=\"#!\"&gt;\n            &lt;span class=\"ipyplot-img-close\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n        &lt;a href=\"#ipyplot-content-div-dLbxDpeDsicCpudJ7Q3iDX-dYQrJvbRXEqdotpdjGxuaj\"&gt;\n            &lt;span class=\"ipyplot-img-expand\"&gt;&lt;/span&gt;\n        &lt;/a&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n    &lt;/textarea&gt;\n</code></pre> <p> </p> <p> </p> <pre><code>\n</code></pre>"},{"location":"notebooks/examples/semantic-search/#similarity-measures","title":"Similarity measures","text":"<p>The sentence embedding vectors typically exist in very large dimensional space (e.g., 300 dimensions). In such large dimensional spaces, the notion of euclidean distance is not as effective. Therefore, it is far more common to use one of the two below measures for vector similarity:</p> <ul> <li>dot-product, the (inner) dot-product between the embedding vectors.</li> </ul> \\[\\begin{equation} \\text{dot-similarity} = \\langle X_i, X_j \\rangle \\end{equation}\\] <ul> <li>cosine-similarity, the \\(\\cos \\left(\\theta_{ij}\\right)\\) gives degree of directional alignment between the vectors, but ignores their magnitudes. Here, \\(\\theta_{ij}\\) is the angle between \\(X_i\\) and \\(X_j\\) (embedding) vectors.</li> </ul> \\[\\begin{equation}  \\text{cosine-similarity} = \\frac{\\langle X_i, X_j \\rangle} {\\| X_i \\| \\| X_j \\|} \\end{equation}\\]   **Important**  &gt;  Sentence transformer models trained with cosine-similarity tend to favor the shorter document texts in the search results, whereas the models trained on the dot-product similarity tend to favor longer texts.  <p></p>"},{"location":"notebooks/examples/semantic-search/#symmetric-vs-asymmetric-search","title":"Symmetric vs asymmetric search","text":"<p>One of the technical aspects to be careful of is the relative textual length of the query sentence compared to the actual documents. Different sentence-transformer models have been trained specifically for each of these use-cases. </p> <ul> <li> <p>symmetric search when we expect the query-sentence to be approximately the same length as the document sentences.</p> </li> <li> <p>asymmetric search when we expect the document texts to be significantly larger in length to the query sentence.</p> </li> </ul>"},{"location":"notebooks/examples/semantic-search/#load-an-appropriate-model","title":"Load an appropriate model","text":"<p>Let us consider the use-case where we are searching through some reasonably large documents. In such a case, it would be appropriate to use an asymmetric-search model. </p> <p>Let us consider an asymmetric model trained with cosine-similarity as the distance measure. In particular, let us use one of the below models:</p> <ul> <li>`</li> </ul> <p>We load the model with the following code:</p>"},{"location":"notebooks/examples/semantic-search/#load-a-toy-corpus","title":"Load a toy corpus","text":"<p>Let us now load a toy corpus of some simple, long texts.</p>"},{"location":"notebooks/examples/semantic-search/#search-index-of-sentence-embeddings","title":"Search index of sentence embeddings","text":"<p>Let us now create the search index of sentence embeddings.</p>"},{"location":"notebooks/examples/semantic-search/#now-search-for-something","title":"Now, search for something!","text":"<p>Let us find the closest match to the the query: \"a friendship with animals\"</p>"},{"location":"notebooks/examples/semantic-search/#visual-search","title":"Visual Search","text":"<p>Let us now search by giving it an image of what we are looking for. How can we do this?</p> <p>We need to translate an image into an embedding vector, in a semantically relevant manner. If we were to be able to do it, we can then search through our document embeddings in essentially  the same manner as we did for textual search.</p> <p>We start by getting an image from the web:</p>  A golden retriever image from wikipedia"},{"location":"notebooks/examples/semantic-search/#image-as-query","title":"Image as query","text":""},{"location":"notebooks/examples/semantic-search/#text-as-query","title":"Text as query","text":"<p>We can also do the converse: give a text query, and retrieve all images that match. </p>   **Attribution**  &gt;  The following example is derived from, and inspired by, the sample jupyter notebook posted at:  https://github.com/UKPLab/sentence-transformers/blob/master/examples/applications/image-search/Image_Search.ipynb  <p>Let us first download a collection of photos from the Unsplash website of free available photos.</p>"},{"location":"notebooks/examples/semantic-search/#create-the-search-index-of-these-images","title":"Create the search index of these images","text":"<p>Let us now create a search index of these images as a collection of sentence embeddings. Since it is rather computationally expensive and time-consuming to create these embeddings, let us also store it for repeated use. </p> <p>Of-course, this implies that the next time you run this cell, it will retrieve the pre-computed embeddings, rather than recreate them.</p>"},{"location":"notebooks/examples/semantic-search/#image-search-with-prompts","title":"Image search with prompts","text":"<p>Now we can search in a manner exactly the same as before.</p>"},{"location":"notebooks/examples/semantic-search/#0","title":"0","text":""},{"location":"notebooks/examples/semantic-search/#1","title":"1","text":""},{"location":"notebooks/examples/semantic-search/#2","title":"2","text":""},{"location":"notebooks/examples/semantic-search/#3","title":"3","text":""},{"location":"notebooks/examples/semantic-search/#4","title":"4","text":""},{"location":"notebooks/examples/semantic-search/#5","title":"5","text":""},{"location":"notebooks/examples/semantic-search/#6","title":"6","text":""},{"location":"notebooks/examples/semantic-search/#7","title":"7","text":""},{"location":"notebooks/examples/semantic-search/#0_1","title":"0","text":""},{"location":"notebooks/examples/semantic-search/#1_1","title":"1","text":""},{"location":"notebooks/examples/semantic-search/#2_1","title":"2","text":""},{"location":"notebooks/examples/semantic-search/#3_1","title":"3","text":""},{"location":"notebooks/examples/semantic-search/#4_1","title":"4","text":""},{"location":"notebooks/examples/semantic-search/#5_1","title":"5","text":""},{"location":"notebooks/examples/semantic-search/#6_1","title":"6","text":""},{"location":"notebooks/examples/semantic-search/#7_1","title":"7","text":""},{"location":"notebooks/examples/semantic-search/#0_2","title":"0","text":""},{"location":"notebooks/examples/semantic-search/#1_2","title":"1","text":""},{"location":"notebooks/examples/semantic-search/#2_2","title":"2","text":""},{"location":"notebooks/examples/semantic-search/#3_2","title":"3","text":""},{"location":"notebooks/examples/semantic-search/#4_2","title":"4","text":""},{"location":"notebooks/examples/semantic-search/#5_2","title":"5","text":""},{"location":"notebooks/examples/semantic-search/#6_2","title":"6","text":""},{"location":"notebooks/examples/semantic-search/#7_2","title":"7","text":""},{"location":"notebooks/examples/semantic-search/#0_3","title":"0","text":""},{"location":"notebooks/examples/semantic-search/#1_3","title":"1","text":""},{"location":"notebooks/examples/semantic-search/#2_3","title":"2","text":""},{"location":"notebooks/examples/semantic-search/#3_3","title":"3","text":""},{"location":"notebooks/examples/semantic-search/#4_3","title":"4","text":""},{"location":"notebooks/examples/semantic-search/#5_3","title":"5","text":""},{"location":"notebooks/examples/semantic-search/#6_3","title":"6","text":""},{"location":"notebooks/examples/semantic-search/#7_3","title":"7","text":""},{"location":"notebooks/examples/semantic-search/#homework","title":"Homework","text":"<p>Perform a search, where the query is an image, and the results are images.</p>"},{"location":"notebooks/examples/semantic-search/#0_4","title":"0","text":""},{"location":"notebooks/examples/semantic-search/#1_4","title":"1","text":""},{"location":"notebooks/examples/semantic-search/#2_4","title":"2","text":""},{"location":"notebooks/examples/semantic-search/#3_4","title":"3","text":""},{"location":"notebooks/examples/semantic-search/#4_4","title":"4","text":""},{"location":"notebooks/examples/semantic-search/#5_4","title":"5","text":""},{"location":"notebooks/examples/semantic-search/#6_4","title":"6","text":""},{"location":"notebooks/examples/semantic-search/#7_4","title":"7","text":""},{"location":"notebooks/examples/semantic-search/#8","title":"8","text":""},{"location":"notebooks/examples/semantic-search/#9","title":"9","text":""},{"location":"notebooks/examples/semantic-search/#0_5","title":"0","text":""},{"location":"notebooks/examples/semantic-search/#1_5","title":"1","text":""},{"location":"notebooks/examples/semantic-search/#2_5","title":"2","text":""},{"location":"notebooks/examples/semantic-search/#3_5","title":"3","text":""},{"location":"notebooks/examples/semantic-search/#4_5","title":"4","text":""},{"location":"notebooks/examples/semantic-search/#5_5","title":"5","text":""},{"location":"notebooks/examples/semantic-search/#6_5","title":"6","text":""},{"location":"notebooks/examples/semantic-search/#7_5","title":"7","text":""},{"location":"notebooks/examples/semantic-search/#references","title":"References","text":"<p>Further reading resources associated with the two topics: sentence-transformers and approximate nearest neighbor searches.</p> <p>  * Sentence Transformers   * The original paper that introduced sentence-transformers: Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks  * Faiss blog at facebook  Faiss: A library for efficient similarity search   * A gentler introduction to Faiss:  Faiss wiki   * Faiss The Faiss github repository   * Approximate nearest neighbor search with ScaNN  Scann github repository  * Scann research paper:   Accelerating Large-Scale Inference with Anisotropic Vector Quantization   * Topic modeling: Topic modeling with BERT   * To2Vec research paper: Top2Vec: Distributed Representations of Topics </p>"},{"location":"notebooks/examples/supportvectors-common/","title":"Supportvectors common","text":"<pre><code>%%html\n\n&lt;!-- Many of the styles here are inspired by: \n    https://towardsdatascience.com/10-practical-tips-you-need-to-know-to-personalize-jupyter-notebook-fbd202777e20 \n\n\n    On the author's local machine, these exist in the custom.css file. However, in order to keep uniform look and feel, \n    and at the request of participants, I have added it to this common import-file here.\n\n    --&gt;\n&lt;link href=\"https://fonts.googleapis.com/css?family=Lora:400,700|Montserrat:300\" rel=\"stylesheet\"/&gt;\n&lt;link href=\"https://fonts.googleapis.com/css2?family=Crimson+Pro&amp;amp;family=Literata&amp;amp;display=swap\" rel=\"stylesheet\"/&gt;\n&lt;style&gt;\n\n\n#ipython_notebook::before{\n content:\"Rag to Riches\";\n        color: white;\n        font-weight: bold;\n        text-transform: uppercase;\n        font-family: 'Lora',serif;\n        font-size:16pt;\n        margin-bottom:15px;\n        margin-top:15px;\n\n}\nbody &gt; #header {\n    #background: #D15555;\n    background: linear-gradient(to bottom, indianred 0%, #fff 100%);\n    opacity: 0.8;\n\n}\n\n\n.navbar-default .navbar-nav &gt; li &gt; a, #kernel_indicator {\n    color: white;\n    transition: all 0.25s;\n    font-size:10pt;\n    font-family: sans-serif;\n    font-weight:normal;\n}\n.navbar-default {\n    padding-left:100px;\n    background: none;\n    border: none;\n}\n\n\nbody &gt; menubar-container {\n    background-color: wheat;\n}\n#ipython_notebook img{                                                                                        \n    display:block; \n\n    background: url(\"images/logo-poster-transparent.png\") no-repeat;\n    background-size: contain;\n\n    padding-left: 600px;\n    padding-right: 100px;\n\n    -moz-box-sizing: border-box;\n    box-sizing: border-box;\n}\n\n\n\nbody {\n #font-family:  'Literata', serif;\n    font-family:'Lora', san-serif;\n    text-align: justify;\n    font-weight: 400;\n    font-size: 12pt;\n}\n\niframe{\n    width:100%;\n    min-height:600px;\n}\n\nh1, h2, h3, h4, h5, h6 {\n# font-family: 'Montserrat', sans-serif;\n font-family:'Lora', serif;\n font-weight: 200;\n text-transform: uppercase;\n color: #EC7063 ;\n}\n\nh2 {\n    color: #000080;\n}\n\n.checkpoint_status, .autosave_status {\n    color:wheat;\n}\n\n#notebook_name {\n    font-weight: 600;\n    font-size:20pt;\n    text-variant:uppercase;\n    color: wheat; \n    margin-right:20px;\n    margin-left:-500px;\n}\n#notebook_name:hover {\nbackground-color: salmon;\n}\n\n\n.dataframe { /* dataframe atau table */\n    background: white;\n    box-shadow: 0px 1px 2px #bbb;\n}\n.dataframe thead th, .dataframe tbody td {\n    text-align: center;\n    padding: 1em;\n}\n\n.checkpoint_status, .autosave_status {\n    color:wheat;\n}\n\n.output {\n    align-items: center;\n}\n\ndiv.cell {\n    transition: all 0.25s;\n    border: none;\n    position: relative;\n    top: 0;\n}\ndiv.cell.selected, div.cell.selected.jupyter-soft-selected {\n    border: none;\n    background: transparent;\n    box-shadow: 0 6px 18px #aaa;\n    z-index: 10;\n    top: -10px;\n}\n.CodeMirror pre, .CodeMirror-dialog, .CodeMirror-dialog .CodeMirror-search-field, .terminal-app .terminal {\n    font-family: 'Hack' , serif; \n    font-weight: 500;\n    font-size: 14pt;\n}\n\n\n\n&lt;/style&gt;    \n</code></pre> <pre><code># Starting with the standard imports\nimport numpy as np\nimport pandas as pd\n\n\n\nimport warnings\nwarnings.filterwarnings ('ignore')  # suppress warning\n</code></pre> <pre><code>message = \"\"\"\n\n&lt;center&gt;&lt;img alt=\"No description has been provided for this image\" src=\"images/logo-poster-transparent.png\" width=\"400\"/&gt; &lt;/center&gt;\n&lt;div style=\"color:#aaa;font-size:8pt\"&gt;\n&lt;hr/&gt;\n\u00a9 SupportVectors. All rights reserved. &lt;blockquote&gt;This notebook is the intellectual property of SupportVectors, and part of its training material. \nOnly the participants in SupportVectors workshops are allowed to study the notebooks for educational purposes currently, but is prohibited from copying or using it for any other purposes without written permission.\n\n&lt;b&gt; These notebooks are chapters and sections from Asif Qamar's textbook that he is writing on Data Science. So we request you to not circulate the material to others.&lt;/b&gt;\n&lt;/blockquote&gt;\n&lt;hr/&gt;\n&lt;/div&gt;\n\n\"\"\"\nfrom IPython.display import Markdown\n\ndef copyrights() -&amp;gt; None:\n     display (Markdown(message))\n</code></pre> <pre><code>copyrights()\n</code></pre>    \u00a9 SupportVectors. All rights reserved. This notebook is the intellectual property of SupportVectors, and part of its training material.  Only the participants in SupportVectors workshops are allowed to study the notebooks for educational purposes currently, but is prohibited from copying or using it for any other purposes without written permission.  <p> These notebooks are chapters and sections from Asif Qamar's textbook that he is writing on Data Science. So we request you to not circulate the material to others.</p> <pre><code># Project Setup Cell - Run this first\nimport os\nimport sys\nfrom pathlib import Path\n\n# Ensure we're in the project root\nPROJECT_NAME = \"rag_to_riches\"\ncurrent = Path.cwd()\n\n# Navigate up until we find the project root\nwhile current.name != PROJECT_NAME and current != current.parent:\n    current = current.parent\n\nif current.name == PROJECT_NAME:\n    os.chdir(current)\n    sys.path.insert(0, str(current / 'src'))\n    print(f\"\ud83c\udfaf Project root: {current}\")\n    print(f\"\ud83d\udcc1 Working directory: {os.getcwd()}\")\n    print(\"\u2705 Ready to import rag_to_riches modules!\")\nelse:\n    print(f\"\u274c Could not find {PROJECT_NAME} project root\")\n</code></pre> <pre>\n<code>\ud83c\udfaf Project root: /Users/asifqamar/github/rag_to_riches\n\ud83d\udcc1 Working directory: /Users/asifqamar/github/rag_to_riches\n\u2705 Ready to import rag_to_riches modules!\n</code>\n</pre>"},{"location":"notebooks/examples/supportvectors-common/#importing-the-necessary-libraries","title":"IMPORTING THE NECESSARY LIBRARIES\u00b6","text":""},{"location":"project-guide/tips-and-tricks/cuda-hell/","title":"Some tips and tricks to deal with the CUDA hell","text":"<p>These are some tips and tricks that may be helpful while dealing with CUDA.</p>"},{"location":"project-guide/tips-and-tricks/cuda-hell/#install-the-cuda-toolkit","title":"Install the cuda-toolkit","text":"<p>It is important to remember that one must install the cuda-toolkit, and set the CUDA_HOME environment variable, in order for some critical tools, such as <code>vLLM</code> to work. To do this, follow the instructions at: CUDA installation guide on Linux</p>"},{"location":"project-guide/tips-and-tricks/cuda-hell/#flush-cuda-memory-from-python-code","title":"Flush cuda memory from Python code","text":"<p>It is helpful to start all Python code that uses CUDA with the following mantra invocation:</p> <pre><code>import torch, gc\ngc.collect()\ntorch.cuda.empty_cache()\n</code></pre> <p>Despite this invocation, quite often it will not completely flush the cuda memory. In that case, a better invocation at the level of the Linux shell is:</p> <p><pre><code>nvidia-smi | grep 'python' | awk '{ print $5 }' | xargs -n1 kill -9\n</code></pre> This pearl of wisdom is gleaned from: How to flush GPU memory using CUDA </p> <p>If you're still hitting unexpected memory errors or similar problems then try:</p> <pre><code>sudo fuser -v /dev/nvidia* | cut -d' ' -f2- | sudo xargs -n1 kill -9\n</code></pre>"},{"location":"project-guide/tips-and-tricks/cuda-hell/#nvtop-is-your-friend","title":"<code>nvtop</code> is your friend!","text":"<p>A very useful and visual tool to see what is happening in CUDA is to use the tool <code>nvtop</code>. Install it with the mantra:</p> <p><pre><code>sudo dnf install nvtop\n</code></pre> (or its equivalent if you foolishly use anything other than redhat/centos/rocky-linux).</p>"},{"location":"search/","title":"Search Package","text":""},{"location":"search/#overview","title":"Overview","text":"<p>The <code>search</code> package provides advanced semantic search functionality for the RAG to Riches framework. This package implements intelligent retrieval capabilities that go beyond simple keyword matching to understand the semantic meaning of queries and documents.</p>"},{"location":"search/#key-components","title":"Key Components","text":""},{"location":"search/#semanticsearch-class","title":"SemanticSearch Class","text":"<p>File: <code>semantic_search.py</code></p> <p>The <code>SemanticSearch</code> class is the core component that provides sophisticated semantic search capabilities using vector embeddings and similarity matching.</p>"},{"location":"search/#features","title":"Features","text":"<ul> <li>Vector-based Search: Uses sentence transformer embeddings for semantic understanding</li> <li>Flexible Filtering: Supports metadata-based filtering of search results</li> <li>Batch Processing: Efficient handling of multiple search queries</li> <li>Rich Result Display: Beautiful formatted output using the Rich library</li> <li>Performance Optimization: Optimized for speed and accuracy</li> </ul>"},{"location":"search/#key-methods","title":"Key Methods","text":"<ul> <li><code>search()</code>: Performs semantic search with optional filtering</li> <li><code>batch_search()</code>: Handles multiple queries efficiently</li> <li><code>get_similar_documents()</code>: Retrieves documents based on similarity scores</li> <li><code>display_results()</code>: Rich-formatted result presentation</li> </ul>"},{"location":"search/#architecture","title":"Architecture","text":"graph TB     subgraph \"Search Package\"         SS[SemanticSearch] --&gt; VDB[Vector Database]         SS --&gt; EMB[Text Embedder]         SS --&gt; FIL[Metadata Filters]     end      subgraph \"Search Process\"         Query[User Query] --&gt; EMB         EMB --&gt; Vectors[Query Vectors]         Vectors --&gt; VDB         VDB --&gt; Results[Search Results]         Results --&gt; Display[Rich Display]     end      style SS fill:#e1f5fe     style VDB fill:#e8f5e8     style EMB fill:#f3e5f5"},{"location":"search/#usage-examples","title":"Usage Examples","text":""},{"location":"search/#basic-semantic-search","title":"Basic Semantic Search","text":"<pre><code>from rag_to_riches.search.semantic_search import SemanticSearch\nfrom rag_to_riches.vectordb.embedded_vectordb import EmbeddedVectorDB\n\n# Initialize components\nvector_db = EmbeddedVectorDB()\nsearch_engine = SemanticSearch(vector_db, collection_name=\"my_collection\")\n\n# Perform semantic search\nresults = search_engine.search(\n    query=\"wisdom about friendship\",\n    limit=5,\n    score_threshold=0.7\n)\n\n# Display results\nsearch_engine.display_results(results, \"Friendship Search\")\n</code></pre>"},{"location":"search/#advanced-search-with-filtering","title":"Advanced Search with Filtering","text":"<pre><code># Search with metadata filtering\nfiltered_results = search_engine.search(\n    query=\"animal behavior\",\n    limit=10,\n    metadata_filter={\"category\": \"wildlife\", \"rating\": {\"$gte\": 4.0}}\n)\n</code></pre>"},{"location":"search/#batch-search-processing","title":"Batch Search Processing","text":"<pre><code># Process multiple queries efficiently\nqueries = [\n    \"leadership lessons\",\n    \"courage in adversity\", \n    \"wisdom about patience\"\n]\n\nbatch_results = search_engine.batch_search(queries, limit=3)\n</code></pre>"},{"location":"search/#integration","title":"Integration","text":"<p>The search package integrates seamlessly with other RAG to Riches components:</p> <ul> <li>Vector Database: Works with <code>EmbeddedVectorDB</code> for efficient vector storage and retrieval</li> <li>Corpus Management: Integrates with corpus packages for domain-specific search</li> <li>RAG Pipeline: Serves as the retrieval component in complete RAG workflows</li> </ul>"},{"location":"search/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Vector Indexing: Optimized vector storage for fast similarity search</li> <li>Caching: Intelligent caching of embeddings and search results</li> <li>Batch Processing: Efficient handling of multiple search operations</li> <li>Memory Management: Optimized memory usage for large document collections</li> </ul>"},{"location":"search/#related-components","title":"Related Components","text":"<ul> <li><code>vectordb/</code>: Vector database operations</li> <li><code>corpus/</code>: Data models and corpus management</li> <li><code>start_simply/</code>: Basic RAG implementations using search</li> </ul> <p>Part of the RAG to Riches framework - building intelligent search from the ground up. </p>"},{"location":"search_basics/","title":"Search Basics Package","text":""},{"location":"search_basics/#overview","title":"Overview","text":"<p>The <code>search_basics</code> package provides fundamental search implementations for the RAG to Riches framework. This package offers simple, educational implementations of both text-only and multimodal search capabilities, serving as building blocks for more complex search systems.</p>"},{"location":"search_basics/#key-components","title":"Key Components","text":""},{"location":"search_basics/#text-only-search","title":"Text-Only Search","text":"<p>File: <code>text_only_search.py</code></p> <p>A straightforward implementation of text-based semantic search that demonstrates core vector search concepts without additional complexity.</p>"},{"location":"search_basics/#features","title":"Features","text":"<ul> <li>Pure Text Search: Focuses solely on textual content without multimedia elements</li> <li>Vector Embeddings: Uses sentence transformers for semantic understanding</li> <li>Simple Interface: Easy-to-understand API for learning and prototyping</li> <li>Educational Value: Clear code structure for understanding search fundamentals</li> </ul>"},{"location":"search_basics/#multimodal-search","title":"Multimodal Search","text":"<p>File: <code>multimodal_search.py</code></p> <p>An advanced implementation that combines text and image search capabilities, demonstrating how modern RAG systems can work with multiple data types.</p>"},{"location":"search_basics/#features_1","title":"Features","text":"<ul> <li>Text + Image Search: Combines textual and visual information</li> <li>Cross-Modal Retrieval: Find images using text queries and vice versa</li> <li>Unified Embeddings: Single vector space for multiple modalities</li> <li>Rich Media Support: Handles various image formats and text combinations</li> </ul>"},{"location":"search_basics/#architecture","title":"Architecture","text":"graph TB     subgraph \"Text-Only Search\"         TextQuery[Text Query] --&gt; TextEmbed[Text Embedding]         TextEmbed --&gt; TextVector[Vector Search]         TextVector --&gt; TextResults[Text Results]     end      subgraph \"Multimodal Search\"         MMQuery[QueryText/Image] --&gt; MMEmbed[MultimodalEmbedding]         MMEmbed --&gt; MMVector[Vector Search]         MMVector --&gt; MMResults[Mixed ResultsText + Images]     end      subgraph \"Shared Components\"         VectorDB[Vector Database]         TextVector --&gt; VectorDB         MMVector --&gt; VectorDB     end      style TextQuery fill:#e1f5fe     style MMQuery fill:#f3e5f5     style VectorDB fill:#e8f5e8"},{"location":"search_basics/#getting-started","title":"Getting Started","text":""},{"location":"search_basics/#text-only-search-example","title":"Text-Only Search Example","text":"<pre><code>from rag_to_riches.search_basics.text_only_search import TextOnlySearch\nfrom pathlib import Path\n\n# Initialize text search\nsearch_engine = TextOnlySearch(collection_name=\"simple_text_search\")\n\n# Add some documents\ndocuments = [\n    \"The quick brown fox jumps over the lazy dog.\",\n    \"Python is a powerful programming language for data science.\",\n    \"Machine learning models require large amounts of training data.\",\n    \"Natural language processing helps computers understand human language.\"\n]\n\n# Index the documents\nsearch_engine.add_documents(documents)\n\n# Perform searches\nresults = search_engine.search(\"programming languages\", limit=2)\nfor idx, result in enumerate(results):\n    print(f\"{idx + 1}. {result['text']} (Score: {result['score']:.3f})\")\n\n# Output:\n# 1. Python is a powerful programming language for data science. (Score: 0.845)\n# 2. Natural language processing helps computers understand human language. (Score: 0.672)\n</code></pre>"},{"location":"search_basics/#multimodal-search-example","title":"Multimodal Search Example","text":"<pre><code>from rag_to_riches.search_basics.multimodal_search import MultimodalSearch\nfrom pathlib import Path\n\n# Initialize multimodal search\nmm_search = MultimodalSearch(collection_name=\"multimodal_demo\")\n\n# Add text documents\ntext_docs = [\n    \"A beautiful sunset over the ocean with orange and pink colors.\",\n    \"A cute puppy playing in a green park with children.\",\n    \"Modern architecture featuring glass and steel buildings.\"\n]\nmm_search.add_text_documents(text_docs)\n\n# Add images with descriptions\nimage_paths = [\n    Path(\"images/sunset.jpg\"),\n    Path(\"images/puppy.jpg\"),\n    Path(\"images/building.jpg\")\n]\nmm_search.add_images(image_paths)\n\n# Search with text to find related images and text\nresults = mm_search.search(\"cute animals\", limit=5)\nfor result in results:\n    if result['type'] == 'text':\n        print(f\"Text: {result['content']}\")\n    elif result['type'] == 'image':\n        print(f\"Image: {result['path']} - {result['description']}\")\n\n# Search with an image to find similar content\nquery_image = Path(\"query_images/dog.jpg\")\nvisual_results = mm_search.search_by_image(query_image, limit=3)\n</code></pre>"},{"location":"search_basics/#text-only-search-deep-dive","title":"Text-Only Search Deep Dive","text":""},{"location":"search_basics/#basic-setup","title":"Basic Setup","text":"<pre><code>from rag_to_riches.search_basics.text_only_search import TextOnlySearch\n\n# Create a search instance\nsearch = TextOnlySearch(\n    collection_name=\"my_documents\",\n    embedding_model=\"all-MiniLM-L6-v2\"  # Lightweight, fast model\n)\n</code></pre>"},{"location":"search_basics/#adding-documents","title":"Adding Documents","text":"<pre><code># Method 1: Add documents as a list\ndocuments = [\n    \"Document 1 content here...\",\n    \"Document 2 content here...\",\n    \"Document 3 content here...\"\n]\nsearch.add_documents(documents)\n\n# Method 2: Add documents with metadata\ndocs_with_metadata = [\n    {\"text\": \"Content 1\", \"title\": \"Doc 1\", \"category\": \"science\"},\n    {\"text\": \"Content 2\", \"title\": \"Doc 2\", \"category\": \"history\"},\n    {\"text\": \"Content 3\", \"title\": \"Doc 3\", \"category\": \"literature\"}\n]\nsearch.add_documents_with_metadata(docs_with_metadata)\n\n# Method 3: Add single document\nsearch.add_document(\"Single document content\", metadata={\"source\": \"manual\"})\n</code></pre>"},{"location":"search_basics/#searching-and-filtering","title":"Searching and Filtering","text":"<pre><code># Basic search\nresults = search.search(\"machine learning\", limit=5)\n\n# Search with score threshold\nhigh_quality_results = search.search(\n    \"artificial intelligence\",\n    limit=10,\n    score_threshold=0.7  # Only return highly relevant results\n)\n\n# Search with metadata filtering\nfiltered_results = search.search(\n    \"scientific discovery\",\n    limit=5,\n    metadata_filter={\"category\": \"science\"}\n)\n\n# Advanced search with multiple filters\ncomplex_results = search.search(\n    \"historical events\",\n    limit=7,\n    metadata_filter={\n        \"category\": \"history\",\n        \"year\": {\"$gte\": 1900}  # Published after 1900\n    }\n)\n</code></pre>"},{"location":"search_basics/#result-processing","title":"Result Processing","text":"<pre><code># Process search results\nresults = search.search(\"climate change\", limit=5)\n\nfor i, result in enumerate(results):\n    print(f\"Result {i+1}:\")\n    print(f\"  Text: {result['text'][:100]}...\")  # First 100 chars\n    print(f\"  Score: {result['score']:.3f}\")\n    print(f\"  Metadata: {result.get('metadata', {})}\")\n    print()\n\n# Extract just the text content\ntext_content = [result['text'] for result in results]\n\n# Get average relevance score\navg_score = sum(result['score'] for result in results) / len(results)\nprint(f\"Average relevance: {avg_score:.3f}\")\n</code></pre>"},{"location":"search_basics/#multimodal-search-deep-dive","title":"Multimodal Search Deep Dive","text":""},{"location":"search_basics/#setup-and-configuration","title":"Setup and Configuration","text":"<pre><code>from rag_to_riches.search_basics.multimodal_search import MultimodalSearch\n\n# Initialize with custom models\nmm_search = MultimodalSearch(\n    collection_name=\"multimodal_content\",\n    text_model=\"all-MiniLM-L6-v2\",\n    image_model=\"clip-ViT-B-32\",  # CLIP model for image understanding\n    device=\"cuda\"  # Use GPU if available\n)\n</code></pre>"},{"location":"search_basics/#adding-mixed-content","title":"Adding Mixed Content","text":"<pre><code># Add text documents\ntext_documents = [\n    \"A serene landscape with mountains and lakes.\",\n    \"Urban photography capturing city life and architecture.\",\n    \"Portrait photography with natural lighting techniques.\"\n]\nmm_search.add_text_documents(text_documents)\n\n# Add images with automatic description generation\nimage_files = [\n    Path(\"photos/landscape1.jpg\"),\n    Path(\"photos/city_scene.jpg\"),\n    Path(\"photos/portrait.jpg\")\n]\nmm_search.add_images(image_files, auto_describe=True)\n\n# Add images with custom descriptions\nimage_data = [\n    {\n        \"path\": Path(\"photos/sunset.jpg\"),\n        \"description\": \"Beautiful golden hour sunset over a calm ocean\",\n        \"metadata\": {\"location\": \"California\", \"time\": \"evening\"}\n    },\n    {\n        \"path\": Path(\"photos/forest.jpg\"),\n        \"description\": \"Dense forest with tall pine trees and morning mist\",\n        \"metadata\": {\"location\": \"Pacific Northwest\", \"time\": \"morning\"}\n    }\n]\nmm_search.add_images_with_metadata(image_data)\n</code></pre>"},{"location":"search_basics/#cross-modal-search","title":"Cross-Modal Search","text":"<pre><code># Text query to find both text and images\nmixed_results = mm_search.search(\n    \"peaceful nature scenes\",\n    limit=8,\n    include_text=True,\n    include_images=True\n)\n\n# Separate results by type\ntext_results = [r for r in mixed_results if r['type'] == 'text']\nimage_results = [r for r in mixed_results if r['type'] == 'image']\n\nprint(f\"Found {len(text_results)} text matches and {len(image_results)} image matches\")\n\n# Image query to find similar images and related text\nquery_image = Path(\"query/example.jpg\")\nvisual_matches = mm_search.search_by_image(\n    query_image,\n    limit=5,\n    include_similar_text=True  # Also find related text descriptions\n)\n</code></pre>"},{"location":"search_basics/#advanced-multimodal-features","title":"Advanced Multimodal Features","text":"<pre><code># Search with multiple query types\ncompound_results = mm_search.compound_search(\n    text_query=\"mountain hiking\",\n    image_query=Path(\"query/hiking.jpg\"),\n    weight_text=0.6,  # 60% weight to text similarity\n    weight_image=0.4,  # 40% weight to image similarity\n    limit=10\n)\n\n# Filter by content type and metadata\nfiltered_mm_results = mm_search.search(\n    \"architectural photography\",\n    content_type=\"image\",  # Only return images\n    metadata_filter={\"style\": \"modern\"},\n    limit=5\n)\n\n# Get embeddings for custom processing\ntext_embedding = mm_search.get_text_embedding(\"beautiful landscape\")\nimage_embedding = mm_search.get_image_embedding(Path(\"test_image.jpg\"))\n\n# Calculate custom similarity\nsimilarity = mm_search.calculate_similarity(text_embedding, image_embedding)\nprint(f\"Cross-modal similarity: {similarity:.3f}\")\n</code></pre>"},{"location":"search_basics/#performance-optimization","title":"Performance Optimization","text":""},{"location":"search_basics/#text-only-search-optimization","title":"Text-Only Search Optimization","text":"<pre><code># Optimize for speed\nfast_search = TextOnlySearch(\n    collection_name=\"speed_optimized\",\n    embedding_model=\"all-MiniLM-L6-v2\",  # Faster, smaller model\n    batch_size=64,  # Process documents in batches\n    max_doc_length=512  # Limit document length\n)\n\n# Pre-compute embeddings for static content\nfast_search.precompute_embeddings()\n\n# Use approximate search for very large collections\napprox_results = fast_search.search(\n    \"query text\",\n    limit=10,\n    approximate=True,  # Faster but slightly less accurate\n    search_ef=100  # HNSW parameter for speed/accuracy tradeoff\n)\n</code></pre>"},{"location":"search_basics/#multimodal-search-optimization","title":"Multimodal Search Optimization","text":"<pre><code># Memory-efficient multimodal search\nefficient_mm = MultimodalSearch(\n    collection_name=\"memory_optimized\",\n    text_model=\"all-MiniLM-L6-v2\",\n    image_model=\"clip-ViT-B-32\",\n    device=\"cpu\",  # Use CPU to save GPU memory\n    precision=\"float16\",  # Use half precision for memory savings\n    batch_size=16  # Smaller batches for memory efficiency\n)\n\n# Cache frequently used embeddings\nefficient_mm.enable_embedding_cache(max_size=1000)\n\n# Lazy loading for large image collections\nefficient_mm.enable_lazy_loading()\n</code></pre>"},{"location":"search_basics/#educational-features","title":"Educational Features","text":""},{"location":"search_basics/#learning-progression","title":"Learning Progression","text":"<ol> <li>Start with Text-Only: Understand basic vector search concepts</li> <li>Add Metadata: Learn about filtering and structured search</li> <li>Explore Multimodal: Understand cross-modal retrieval</li> <li>Optimize Performance: Learn about production considerations</li> </ol>"},{"location":"search_basics/#code-examples-for-learning","title":"Code Examples for Learning","text":"<p>Each component includes extensive documentation and examples to help understand:</p> <ul> <li>How vector embeddings work</li> <li>The relationship between queries and results</li> <li>Performance vs. accuracy tradeoffs</li> <li>Memory and computational considerations</li> </ul>"},{"location":"search_basics/#common-use-cases","title":"Common Use Cases","text":""},{"location":"search_basics/#document-search-system","title":"Document Search System","text":"<pre><code># Build a simple document search for a knowledge base\ndoc_search = TextOnlySearch(\"company_docs\")\n\n# Load company documents\ndocuments = load_company_documents()  # Your document loading function\ndoc_search.add_documents(documents)\n\n# Employee searches for information\nresults = doc_search.search(\"vacation policy\", limit=3)\ndisplay_search_results(results)\n</code></pre>"},{"location":"search_basics/#media-asset-management","title":"Media Asset Management","text":"<pre><code># Create a searchable media library\nmedia_search = MultimodalSearch(\"media_assets\")\n\n# Index your media collection\nmedia_search.add_images(Path(\"media_library\").glob(\"*.jpg\"))\nmedia_search.add_text_documents(load_media_descriptions())\n\n# Search for specific content\nvacation_photos = media_search.search(\"beach vacation photos\", limit=20)\n</code></pre>"},{"location":"search_basics/#related-components","title":"Related Components","text":"<ul> <li><code>start_simply/</code>: Basic RAG implementation using these search components</li> <li><code>search/</code>: Advanced semantic search capabilities</li> <li><code>vectordb/</code>: Understanding the underlying vector storage</li> <li><code>examples/</code>: Complete applications using search basics</li> </ul> <p>Part of the RAG to Riches framework - fundamental search capabilities for intelligent applications. </p>"},{"location":"start_simply/","title":"Start Simply Package","text":""},{"location":"start_simply/#overview","title":"Overview","text":"<p>The <code>start_simply</code> package provides a streamlined entry point into the RAG to Riches framework. This package offers simplified, beginner-friendly implementations that demonstrate core RAG concepts without overwhelming complexity, making it perfect for getting started quickly.</p>"},{"location":"start_simply/#key-components","title":"Key Components","text":""},{"location":"start_simply/#basicrag-class","title":"BasicRAG Class","text":"<p>File: <code>basic_rag.py</code></p> <p>The <code>BasicRAG</code> class provides a minimal, easy-to-understand implementation of a complete RAG (Retrieval-Augmented Generation) pipeline. This class abstracts away complexity while maintaining the core functionality needed for effective question-answering systems.</p>"},{"location":"start_simply/#features","title":"Features","text":"<ul> <li>Simple Interface: Minimal setup required to get started</li> <li>Complete Pipeline: Full RAG functionality in a single class</li> <li>Educational Focus: Clear, well-documented code for learning</li> <li>Quick Prototyping: Ideal for rapid prototyping and experimentation</li> <li>Foundation Building: Serves as a foundation for more complex implementations</li> </ul>"},{"location":"start_simply/#core-functionality","title":"Core Functionality","text":"<ul> <li>Document Ingestion: Easy loading and indexing of text documents</li> <li>Semantic Retrieval: Vector-based document retrieval</li> <li>Answer Generation: LLM-powered response generation</li> <li>Context Integration: Seamless integration of retrieved context with queries</li> </ul>"},{"location":"start_simply/#architecture","title":"Architecture","text":"graph LR     subgraph \"BasicRAG Pipeline\"         Query[User Query] --&gt; Retrieve[Document Retrieval]         Retrieve --&gt; Context[Context Assembly]         Context --&gt; Generate[Answer Generation]         Generate --&gt; Response[Final Response]     end      subgraph \"Components\"         Docs[Documents] --&gt; VectorDB[Vector Storage]         VectorDB --&gt; Retrieve         LLM[Language Model] --&gt; Generate     end      style Query fill:#e1f5fe     style Response fill:#e8f5e8     style Retrieve fill:#f3e5f5     style Generate fill:#fff3e0"},{"location":"start_simply/#getting-started","title":"Getting Started","text":""},{"location":"start_simply/#quick-start-example","title":"Quick Start Example","text":"<pre><code>from rag_to_riches.start_simply.basic_rag import BasicRAG\nfrom pathlib import Path\n\n# Initialize BasicRAG\nrag = BasicRAG()\n\n# Load documents (supports various formats)\ndocuments = [\n    \"The cat sat on the mat and purred contentedly.\",\n    \"Dogs are loyal companions who love to play fetch.\",\n    \"Birds can fly high in the sky using their wings.\"\n]\n\n# Index the documents\nrag.add_documents(documents)\n\n# Ask questions\nresponse = rag.ask(\"What do cats do?\")\nprint(response)\n# Output: Based on the provided context, cats sit on mats and purr contentedly.\n\nresponse = rag.ask(\"Tell me about loyal animals\")\nprint(response)\n# Output: Dogs are described as loyal companions who enjoy playing fetch.\n</code></pre>"},{"location":"start_simply/#step-by-step-usage","title":"Step-by-Step Usage","text":""},{"location":"start_simply/#1-initialize-the-system","title":"1. Initialize the System","text":"<pre><code>from rag_to_riches.start_simply.basic_rag import BasicRAG\n\n# Create a BasicRAG instance\nrag = BasicRAG(\n    collection_name=\"my_first_rag\",\n    model_name=\"gpt-3.5-turbo\"  # or your preferred model\n)\n</code></pre>"},{"location":"start_simply/#2-add-your-documents","title":"2. Add Your Documents","text":"<pre><code># Option 1: Add documents directly\ndocuments = [\n    \"Your first document content here...\",\n    \"Your second document content here...\",\n    \"More documents...\"\n]\nrag.add_documents(documents)\n\n# Option 2: Load from file\nfrom pathlib import Path\ntext_file = Path(\"my_documents.txt\")\nrag.load_from_file(text_file)\n\n# Option 3: Add one document at a time\nrag.add_document(\"A single document to add to the collection\")\n</code></pre>"},{"location":"start_simply/#3-start-asking-questions","title":"3. Start Asking Questions","text":"<pre><code># Simple question-answering\nanswer = rag.ask(\"What is the main topic of the documents?\")\nprint(f\"Answer: {answer}\")\n\n# Get more detailed responses\ndetailed_answer = rag.ask(\n    \"Explain the key concepts mentioned in the documents\",\n    max_context_length=1000\n)\nprint(f\"Detailed Answer: {detailed_answer}\")\n</code></pre>"},{"location":"start_simply/#4-inspect-retrieved-context","title":"4. Inspect Retrieved Context","text":"<pre><code># See what documents were retrieved for a query\nquery = \"machine learning applications\"\ncontext = rag.get_context(query, num_results=3)\nprint(f\"Retrieved context: {context}\")\n\n# Ask with visible context\nanswer_with_context = rag.ask_with_context(query)\nprint(f\"Answer: {answer_with_context['answer']}\")\nprint(f\"Sources: {answer_with_context['sources']}\")\n</code></pre>"},{"location":"start_simply/#educational-features","title":"Educational Features","text":""},{"location":"start_simply/#learning-progression","title":"Learning Progression","text":"<p>The <code>start_simply</code> package is designed for progressive learning:</p> <ol> <li>Start Here: Begin with <code>BasicRAG</code> for fundamental concepts</li> <li>Understand Components: Learn how retrieval and generation work together</li> <li>Explore Configuration: Experiment with different settings and parameters</li> <li>Move Forward: Graduate to more advanced packages as understanding grows</li> </ol>"},{"location":"start_simply/#code-clarity","title":"Code Clarity","text":"<ul> <li>Minimal Dependencies: Uses only essential components</li> <li>Clear Naming: Intuitive method and variable names</li> <li>Comprehensive Comments: Detailed explanations throughout the code</li> <li>Simple Examples: Easy-to-follow usage patterns</li> </ul>"},{"location":"start_simply/#common-use-cases","title":"Common Use Cases","text":""},{"location":"start_simply/#document-qa-system","title":"Document Q&amp;A System","text":"<pre><code># Perfect for building a simple document Q&amp;A system\nrag = BasicRAG()\n\n# Load your knowledge base\nknowledge_base = [\n    \"Company policy: All employees must wear safety equipment in the lab.\",\n    \"Office hours: Monday to Friday, 9 AM to 5 PM.\",\n    \"Remote work: Available on Tuesdays and Thursdays.\"\n]\nrag.add_documents(knowledge_base)\n\n# Answer questions about your documents\nanswer = rag.ask(\"What are the office hours?\")\nprint(answer)  # \"Office hours are Monday to Friday, 9 AM to 5 PM.\"\n</code></pre>"},{"location":"start_simply/#personal-knowledge-assistant","title":"Personal Knowledge Assistant","text":"<pre><code># Create a personal knowledge assistant\npersonal_rag = BasicRAG(collection_name=\"personal_notes\")\n\n# Add your notes and research\nnotes = [\n    \"Python best practices: Use type hints and docstrings.\",\n    \"Meeting notes: Project deadline is next Friday.\",\n    \"Research: RAG systems combine retrieval with generation.\"\n]\npersonal_rag.add_documents(notes)\n\n# Query your personal knowledge\ninsight = personal_rag.ask(\"What did I learn about Python?\")\nprint(insight)\n</code></pre>"},{"location":"start_simply/#configuration-options","title":"Configuration Options","text":""},{"location":"start_simply/#basic-configuration","title":"Basic Configuration","text":"<pre><code># Customize BasicRAG behavior\nrag = BasicRAG(\n    collection_name=\"custom_collection\",\n    model_name=\"gpt-4\",  # Use different LLM\n    embedding_model=\"all-MiniLM-L6-v2\",  # Custom embeddings\n    max_context_length=500,  # Limit context size\n    temperature=0.7  # Control response creativity\n)\n</code></pre>"},{"location":"start_simply/#performance-tuning","title":"Performance Tuning","text":"<pre><code># Optimize for your use case\nrag = BasicRAG()\n\n# Adjust retrieval settings\nrag.set_retrieval_params(\n    num_results=5,  # Number of documents to retrieve\n    score_threshold=0.7,  # Minimum similarity score\n    max_tokens_per_doc=200  # Limit document length\n)\n\n# Configure generation settings\nrag.set_generation_params(\n    max_tokens=150,  # Limit response length\n    temperature=0.3,  # More focused responses\n    top_p=0.9  # Nucleus sampling parameter\n)\n</code></pre>"},{"location":"start_simply/#progression-path","title":"Progression Path","text":""},{"location":"start_simply/#from-basic-to-advanced","title":"From Basic to Advanced","text":"<ol> <li>Master BasicRAG: Understand the fundamental pipeline</li> <li>Explore <code>search_basics/</code>: Learn about different search strategies</li> <li>Study <code>corpus/</code>: Understand data modeling and management</li> <li>Use <code>search/</code>: Implement advanced semantic search</li> <li>Build Custom Solutions: Combine components for specialized applications</li> </ol>"},{"location":"start_simply/#next-steps","title":"Next Steps","text":"<p>After mastering <code>BasicRAG</code>, consider exploring:</p> <ul> <li>Custom Embeddings: Experiment with different embedding models</li> <li>Advanced Retrieval: Implement hybrid search strategies</li> <li>Domain Specialization: Create domain-specific RAG systems</li> <li>Performance Optimization: Scale for larger document collections</li> </ul>"},{"location":"start_simply/#troubleshooting","title":"Troubleshooting","text":""},{"location":"start_simply/#common-issues","title":"Common Issues","text":""},{"location":"start_simply/#no-results-returned","title":"No Results Returned","text":"<pre><code># Check if documents were indexed properly\nprint(f\"Number of documents: {len(rag.get_all_documents())}\")\n\n# Verify embedding generation\ntest_embedding = rag.embed_text(\"test query\")\nprint(f\"Embedding dimensions: {len(test_embedding)}\")\n</code></pre>"},{"location":"start_simply/#poor-answer-quality","title":"Poor Answer Quality","text":"<pre><code># Increase context length\nrag.set_retrieval_params(\n    num_results=10,  # Retrieve more documents\n    max_tokens_per_doc=300  # Include more text per document\n)\n\n# Adjust generation parameters\nrag.set_generation_params(\n    temperature=0.1,  # More deterministic responses\n    max_tokens=200  # Longer responses\n)\n</code></pre>"},{"location":"start_simply/#memory-or-performance-issues","title":"Memory or Performance Issues","text":"<pre><code># Optimize for performance\nrag.set_retrieval_params(\n    num_results=3,  # Fewer results\n    max_tokens_per_doc=100  # Shorter documents\n)\n\n# Clear cache periodically\nrag.clear_cache()\n</code></pre>"},{"location":"start_simply/#related-components","title":"Related Components","text":"<ul> <li><code>search_basics/</code>: Simple search implementations</li> <li><code>examples/</code>: Complete usage examples</li> <li><code>vectordb/</code>: Understanding the underlying vector database</li> <li><code>corpus/</code>: Advanced data modeling for specialized domains</li> </ul> <p>Part of the RAG to Riches framework - your first step into the world of intelligent document retrieval. </p>"},{"location":"utils/","title":"Utils Package","text":""},{"location":"utils/#overview","title":"Overview","text":"<p>The <code>utils</code> package provides essential utility functions and configurations that support the entire RAG to Riches framework. This package focuses on cross-cutting concerns like logging, configuration management, and shared utilities that enhance the development and operational experience.</p>"},{"location":"utils/#key-components","title":"Key Components","text":""},{"location":"utils/#logging-configuration","title":"Logging Configuration","text":"<p>File: <code>logging_config.py</code></p> <p>A comprehensive logging system designed for both development and production environments, providing structured, configurable logging throughout the RAG pipeline.</p>"},{"location":"utils/#features","title":"Features","text":"<ul> <li>Structured Logging: Consistent log format across all components</li> <li>Multiple Output Formats: Console, file, and structured JSON logging</li> <li>Log Level Management: Configurable verbosity for different environments</li> <li>Performance Monitoring: Built-in timing and performance metrics</li> <li>Error Tracking: Enhanced error logging with context and stack traces</li> <li>Rich Console Output: Beautiful, colored console logs for development</li> </ul>"},{"location":"utils/#architecture","title":"Architecture","text":"graph TB     subgraph \"Logging System\"         Config[Logging Config] --&gt; Console[Console Handler]         Config --&gt; File[File Handler]         Config --&gt; JSON[JSON Handler]         Config --&gt; Metrics[Metrics Handler]     end      subgraph \"Log Levels\"         DEBUG[DEBUGDevelopment]         INFO[INFOGeneral Info]         WARNING[WARNINGWarnings]         ERROR[ERRORErrors]         CRITICAL[CRITICALCritical Issues]     end      subgraph \"Components Using Logging\"         VectorDB[Vector Database]         Search[Semantic Search]         Corpus[Corpus Management]         Examples[Example Scripts]     end      Console --&gt; DEBUG     Console --&gt; INFO     File --&gt; WARNING     File --&gt; ERROR     JSON --&gt; CRITICAL      VectorDB --&gt; Config     Search --&gt; Config     Corpus --&gt; Config     Examples --&gt; Config      style Config fill:#e1f5fe     style Console fill:#e8f5e8     style File fill:#f3e5f5     style JSON fill:#fff3e0"},{"location":"utils/#getting-started","title":"Getting Started","text":""},{"location":"utils/#basic-logging-setup","title":"Basic Logging Setup","text":"<pre><code>from rag_to_riches.utils.logging_config import setup_logging\nimport logging\n\n# Initialize logging system\nsetup_logging()\n\n# Get a logger for your module\nlogger = logging.getLogger(__name__)\n\n# Use structured logging\nlogger.info(\"Starting RAG pipeline\", extra={\n    \"operation\": \"initialization\",\n    \"component\": \"rag_system\",\n    \"collection_name\": \"my_collection\"\n})\n\nlogger.debug(\"Processing document\", extra={\n    \"document_id\": \"doc_123\",\n    \"document_length\": 1500,\n    \"processing_stage\": \"embedding\"\n})\n\nlogger.error(\"Failed to connect to vector database\", extra={\n    \"error_type\": \"connection_error\",\n    \"database_url\": \"localhost:6333\",\n    \"retry_count\": 3\n})\n</code></pre>"},{"location":"utils/#environment-specific-configuration","title":"Environment-Specific Configuration","text":"<pre><code>from rag_to_riches.utils.logging_config import setup_logging\n\n# Development environment - verbose console logging\nsetup_logging(\n    level=\"DEBUG\",\n    format_style=\"rich\",  # Colored, formatted console output\n    enable_file_logging=False,\n    enable_metrics=True\n)\n\n# Production environment - structured file logging\nsetup_logging(\n    level=\"INFO\",\n    format_style=\"json\",  # Structured JSON for log aggregation\n    enable_file_logging=True,\n    log_file=\"rag_system.log\",\n    enable_metrics=True,\n    enable_error_tracking=True\n)\n\n# Testing environment - minimal logging\nsetup_logging(\n    level=\"WARNING\",\n    format_style=\"simple\",\n    enable_file_logging=False,\n    enable_metrics=False\n)\n</code></pre>"},{"location":"utils/#logging-configuration-features","title":"Logging Configuration Features","text":""},{"location":"utils/#rich-console-logging","title":"Rich Console Logging","text":"<p>Perfect for development and debugging:</p> <pre><code>from rag_to_riches.utils.logging_config import setup_rich_logging\n\n# Enable beautiful console logging\nsetup_rich_logging()\n\nlogger = logging.getLogger(__name__)\n\n# Rich formatting automatically handles complex data\nlogger.info(\"Search results\", extra={\n    \"query\": \"machine learning\",\n    \"results_count\": 15,\n    \"avg_score\": 0.847,\n    \"processing_time\": 0.245,\n    \"metadata\": {\n        \"collection\": \"research_papers\",\n        \"embedding_model\": \"all-MiniLM-L6-v2\"\n    }\n})\n\n# Output will be beautifully formatted with:\n# - Color coding by log level\n# - Structured display of complex data\n# - Timestamps and context information\n# - Easy-to-read hierarchical data\n</code></pre>"},{"location":"utils/#structured-json-logging","title":"Structured JSON Logging","text":"<p>Ideal for production systems and log aggregation:</p> <pre><code>from rag_to_riches.utils.logging_config import setup_json_logging\n\n# Enable JSON structured logging\nsetup_json_logging(log_file=\"rag_system.jsonl\")\n\nlogger = logging.getLogger(__name__)\n\nlogger.info(\"Document indexed successfully\", extra={\n    \"event_type\": \"document_indexed\",\n    \"document_id\": \"doc_456\",\n    \"collection_name\": \"knowledge_base\",\n    \"vector_dimensions\": 384,\n    \"indexing_time_ms\": 125,\n    \"success\": True\n})\n\n# JSON output:\n# {\n#   \"timestamp\": \"2024-01-15T10:30:45.123Z\",\n#   \"level\": \"INFO\",\n#   \"logger\": \"rag_to_riches.corpus.animals\",\n#   \"message\": \"Document indexed successfully\",\n#   \"event_type\": \"document_indexed\",\n#   \"document_id\": \"doc_456\",\n#   \"collection_name\": \"knowledge_base\",\n#   \"vector_dimensions\": 384,\n#   \"indexing_time_ms\": 125,\n#   \"success\": true\n# }\n</code></pre>"},{"location":"utils/#performance-monitoring","title":"Performance Monitoring","text":"<p>Built-in performance tracking and metrics:</p> <pre><code>from rag_to_riches.utils.logging_config import get_performance_logger\nimport time\n\nperf_logger = get_performance_logger()\n\n# Method 1: Context manager for timing\nfrom rag_to_riches.utils.logging_config import log_performance\n\n@log_performance(\"embedding_generation\")\ndef generate_embeddings(texts):\n    # Your embedding logic here\n    return embeddings\n\n# Method 2: Manual timing\nstart_time = time.time()\nresults = search_engine.search(\"query\", limit=10)\nduration = time.time() - start_time\n\nperf_logger.info(\"Search completed\", extra={\n    \"operation\": \"semantic_search\",\n    \"query_length\": len(\"query\"),\n    \"results_count\": len(results),\n    \"duration_ms\": duration * 1000,\n    \"avg_score\": sum(r['score'] for r in results) / len(results)\n})\n\n# Method 3: Decorator with context\n@log_performance(\"document_processing\", include_memory=True)\ndef process_documents(documents):\n    # Processing logic\n    return processed_docs\n</code></pre>"},{"location":"utils/#error-tracking-and-context","title":"Error Tracking and Context","text":"<p>Enhanced error logging with full context:</p> <pre><code>from rag_to_riches.utils.logging_config import get_error_logger\n\nerror_logger = get_error_logger()\n\ntry:\n    # Some RAG operation\n    results = vector_db.search(query_vector)\n\nexcept Exception as e:\n    error_logger.error(\n        \"Vector search failed\",\n        extra={\n            \"error_type\": type(e).__name__,\n            \"error_message\": str(e),\n            \"query_dimensions\": len(query_vector),\n            \"collection_name\": \"my_collection\",\n            \"operation_context\": {\n                \"function\": \"semantic_search\",\n                \"step\": \"vector_query\",\n                \"parameters\": {\n                    \"limit\": 10,\n                    \"score_threshold\": 0.7\n                }\n            }\n        },\n        exc_info=True  # Include full stack trace\n    )\n    raise\n</code></pre>"},{"location":"utils/#advanced-logging-patterns","title":"Advanced Logging Patterns","text":""},{"location":"utils/#contextual-logging","title":"Contextual Logging","text":"<p>Maintain context across related operations:</p> <pre><code>from rag_to_riches.utils.logging_config import LoggingContext\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n# Create a logging context for a RAG session\nwith LoggingContext(\n    session_id=\"session_123\",\n    user_id=\"user_456\",\n    operation=\"rag_query\"\n):\n    logger.info(\"Starting RAG query\")\n\n    # All logs within this context will include session info\n    search_results = search_engine.search(query)\n    logger.info(f\"Retrieved {len(search_results)} results\")\n\n    llm_response = llm.generate(query, context=search_results)\n    logger.info(\"Generated LLM response\")\n\n    # Context information is automatically included in all logs\n</code></pre>"},{"location":"utils/#correlation-ids","title":"Correlation IDs","text":"<p>Track operations across the entire pipeline:</p> <pre><code>from rag_to_riches.utils.logging_config import with_correlation_id\nimport uuid\n\n@with_correlation_id\ndef process_rag_request(query: str):\n    \"\"\"Process a RAG request with full traceability.\"\"\"\n\n    correlation_id = str(uuid.uuid4())\n    logger = logging.getLogger(__name__)\n\n    logger.info(\"Processing RAG request\", extra={\n        \"correlation_id\": correlation_id,\n        \"query_preview\": query[:50]\n    })\n\n    # All subsequent operations will include the correlation ID\n    search_results = search_documents(query)\n    llm_response = generate_response(query, search_results)\n\n    logger.info(\"RAG request completed\", extra={\n        \"correlation_id\": correlation_id,\n        \"response_length\": len(llm_response)\n    })\n\n    return llm_response\n</code></pre>"},{"location":"utils/#custom-log-filters","title":"Custom Log Filters","text":"<p>Filter logs based on context or content:</p> <pre><code>from rag_to_riches.utils.logging_config import add_log_filter\n\n# Filter out low-priority debug messages\ndef development_filter(record):\n    if record.levelno == logging.DEBUG:\n        return \"performance\" in record.getMessage()\n    return True\n\nadd_log_filter(\"development_filter\", development_filter)\n\n# Filter sensitive information\ndef security_filter(record):\n    # Remove or mask sensitive data from logs\n    if hasattr(record, 'api_key'):\n        record.api_key = \"***masked***\"\n    if hasattr(record, 'user_email'):\n        record.user_email = record.user_email.replace('@', '@***')\n    return True\n\nadd_log_filter(\"security_filter\", security_filter)\n</code></pre>"},{"location":"utils/#configuration-management","title":"Configuration Management","text":""},{"location":"utils/#log-level-configuration","title":"Log Level Configuration","text":"<pre><code>from rag_to_riches.utils.logging_config import configure_log_levels\n\n# Set different levels for different components\nconfigure_log_levels({\n    \"rag_to_riches.vectordb\": \"DEBUG\",\n    \"rag_to_riches.search\": \"INFO\", \n    \"rag_to_riches.corpus\": \"INFO\",\n    \"rag_to_riches.examples\": \"WARNING\",\n    \"requests\": \"WARNING\",  # Reduce third-party library noise\n    \"urllib3\": \"ERROR\"\n})\n</code></pre>"},{"location":"utils/#dynamic-configuration","title":"Dynamic Configuration","text":"<p>Update logging configuration at runtime:</p> <pre><code>from rag_to_riches.utils.logging_config import update_logging_config\n\n# Switch to debug mode dynamically\nupdate_logging_config({\n    \"level\": \"DEBUG\",\n    \"enable_performance_logging\": True,\n    \"add_memory_metrics\": True\n})\n\n# Switch to production mode\nupdate_logging_config({\n    \"level\": \"INFO\",\n    \"format_style\": \"json\",\n    \"enable_file_logging\": True,\n    \"log_rotation\": True\n})\n</code></pre>"},{"location":"utils/#integration-with-rag-components","title":"Integration with RAG Components","text":""},{"location":"utils/#vector-database-logging","title":"Vector Database Logging","text":"<pre><code>from rag_to_riches.vectordb.embedded_vectordb import EmbeddedVectorDB\nfrom rag_to_riches.utils.logging_config import setup_logging\n\nsetup_logging()\nvector_db = EmbeddedVectorDB()\n\n# Automatic logging of database operations\nvector_db.create_collection(\"my_collection\")  # Logs: Collection created\nvector_db.add_vectors(vectors, metadata)       # Logs: Vectors added (count, dimensions)\nresults = vector_db.search(query_vector)       # Logs: Search completed (results, time)\n</code></pre>"},{"location":"utils/#search-operation-logging","title":"Search Operation Logging","text":"<pre><code>from rag_to_riches.search.semantic_search import SemanticSearch\n\nsearch_engine = SemanticSearch(vector_db, collection_name=\"docs\")\n\n# Automatic logging includes:\n# - Query processing time\n# - Number of results found\n# - Average relevance scores\n# - Performance metrics\nresults = search_engine.search(\"machine learning applications\")\n</code></pre>"},{"location":"utils/#corpus-management-logging","title":"Corpus Management Logging","text":"<pre><code>from rag_to_riches.corpus.animals import Animals\n\nanimals = Animals(vector_db, collection_name=\"animal_wisdom\")\n\n# Comprehensive logging of corpus operations:\n# - Data loading progress\n# - Indexing performance\n# - Search analytics\n# - Error recovery\nwisdom_data, point_ids = animals.load_and_index(data_file)\n</code></pre>"},{"location":"utils/#production-considerations","title":"Production Considerations","text":""},{"location":"utils/#log-rotation-and-management","title":"Log Rotation and Management","text":"<pre><code>from rag_to_riches.utils.logging_config import setup_production_logging\n\nsetup_production_logging(\n    log_file=\"rag_system.log\",\n    max_file_size=\"100MB\",\n    backup_count=5,\n    compression=True,\n    rotation_schedule=\"daily\"\n)\n</code></pre>"},{"location":"utils/#monitoring-and-alerting-integration","title":"Monitoring and Alerting Integration","text":"<pre><code>from rag_to_riches.utils.logging_config import enable_monitoring_hooks\n\n# Integration with monitoring systems\nenable_monitoring_hooks(\n    error_webhook=\"https://alerts.example.com/webhook\",\n    metrics_endpoint=\"https://metrics.example.com/api/logs\",\n    alert_on_error_rate=True,\n    performance_threshold_ms=1000\n)\n</code></pre>"},{"location":"utils/#security-and-compliance","title":"Security and Compliance","text":"<pre><code>from rag_to_riches.utils.logging_config import enable_security_logging\n\nenable_security_logging(\n    mask_sensitive_data=True,\n    audit_access_logs=True,\n    comply_with_gdpr=True,\n    retention_period_days=90\n)\n</code></pre>"},{"location":"utils/#usage-examples","title":"Usage Examples","text":""},{"location":"utils/#development-workflow","title":"Development Workflow","text":"<pre><code>from rag_to_riches.utils.logging_config import setup_development_logging\n\n# Perfect for debugging and development\nsetup_development_logging()\n\n# Your development code here\n# Logs will be colorful, detailed, and easy to read\n</code></pre>"},{"location":"utils/#production-deployment","title":"Production Deployment","text":"<pre><code>from rag_to_riches.utils.logging_config import setup_production_logging\n\n# Optimized for production environments\nsetup_production_logging(\n    log_level=\"INFO\",\n    structured_format=True,\n    enable_metrics=True,\n    enable_alerting=True\n)\n</code></pre>"},{"location":"utils/#testing-environment","title":"Testing Environment","text":"<pre><code>from rag_to_riches.utils.logging_config import setup_testing_logging\n\n# Minimal logging for tests\nsetup_testing_logging(\n    capture_logs=True,  # Capture for test assertions\n    suppress_external_logs=True\n)\n</code></pre>"},{"location":"utils/#related-components","title":"Related Components","text":"<ul> <li><code>exceptions/</code>: Error logging integrates with the exception system</li> <li><code>vectordb/</code>: Database operations are logged for monitoring</li> <li><code>search/</code>: Search performance and results are logged</li> <li><code>corpus/</code>: Corpus operations include comprehensive logging</li> </ul> <p>Part of the RAG to Riches framework - essential utilities for robust, observable applications. </p>"},{"location":"vectordb/","title":"Vector Database Package: Embeddings and Storage","text":""},{"location":"vectordb/#package-overview","title":"\ud83d\udcd6 Package Overview","text":"<p>The <code>vectordb</code> package provides the foundational infrastructure for vector-based semantic search in the RAG to Riches framework. It combines advanced text embedding capabilities with efficient vector storage and retrieval using Qdrant, creating a powerful foundation for similarity search and retrieval-augmented generation.</p>"},{"location":"vectordb/#package-purpose","title":"\ud83c\udfaf Package Purpose","text":"<p>This package transforms text into high-dimensional vector representations and provides persistent storage with lightning-fast similarity search. It handles the complete pipeline from text encoding to vector database operations, making semantic search accessible and efficient for RAG applications.</p>"},{"location":"vectordb/#architecture","title":"\ud83c\udfd7\ufe0f Architecture","text":"classDiagram     class EmbeddedVectorDB {         +QdrantClient client         +create_collection() bool         +upsert_points() None         +search_points() List[ScoredPoint]         +count_points() int         +delete_collection() None         +get_collection_info() dict         +consistency_check() bool     }      class SimpleTextEmbedder {         +SentenceTransformer model         +str model_name         +int vector_size         +str distance_metric         +embed_text() List[float]         +embed_batch() List[List[float]]         +get_vector_size() int         +get_distance_metric() str     }      EmbeddedVectorDB --&gt; QdrantClient : uses     SimpleTextEmbedder --&gt; SentenceTransformer : uses      note for EmbeddedVectorDB \"Local Qdrant database\\nwith CRUD operations\"     note for SimpleTextEmbedder \"Sentence transformer\\nembeddings with caching\""},{"location":"vectordb/#components","title":"\ud83d\udce6 Components","text":""},{"location":"vectordb/#core-components","title":"\ud83c\udfdb\ufe0f Core Components","text":"Component File Purpose <code>EmbeddedVectorDB</code> <code>embedded_vectordb.py</code> Local Qdrant database operations <code>SimpleTextEmbedder</code> <code>embedder.py</code> Text-to-vector transformation"},{"location":"vectordb/#typical-data-flow","title":"\ud83d\udd04 Typical Data Flow","text":"sequenceDiagram     participant Text as \"Text Input\"     participant Embedder as \"SimpleTextEmbedder\"     participant VectorDB as \"EmbeddedVectorDB\"     participant Qdrant as \"Qdrant Storage\"      Text-&gt;&gt;Embedder: \"Dogs are loyal friends\"     Embedder-&gt;&gt;Embedder: Load sentence transformer     Embedder-&gt;&gt;Embedder: Generate 384-dim vector     Embedder--&gt;&gt;VectorDB: [0.1, -0.3, 0.8, ...]      VectorDB-&gt;&gt;VectorDB: Create PointStruct     VectorDB-&gt;&gt;Qdrant: Store vector + metadata     Qdrant--&gt;&gt;VectorDB: Confirmation      Note over VectorDB: Later: Similarity Search     VectorDB-&gt;&gt;Qdrant: Query with vector     Qdrant--&gt;&gt;VectorDB: Similar vectors + scores     VectorDB--&gt;&gt;Text: Relevant results"},{"location":"vectordb/#key-features","title":"\ud83d\udca1 Key Features","text":""},{"location":"vectordb/#advanced-text-embedding","title":"\ud83d\udd0d Advanced Text Embedding","text":"<ul> <li>State-of-the-Art Models: Sentence transformers optimized for semantic understanding</li> <li>Flexible Model Selection: Support for various embedding models and sizes</li> <li>Batch Processing: Efficient handling of large text collections</li> <li>Caching: Intelligent caching to avoid redundant computations</li> </ul>"},{"location":"vectordb/#vector-database-operations","title":"\ud83d\uddc4\ufe0f Vector Database Operations","text":"<ul> <li>Local Storage: Embedded Qdrant for development and production</li> <li>CRUD Operations: Complete create, read, update, delete functionality</li> <li>Collection Management: Flexible collection creation and configuration</li> <li>Health Monitoring: Consistency checks and database statistics</li> </ul>"},{"location":"vectordb/#performance-optimizations","title":"\u26a1 Performance Optimizations","text":"<ul> <li>GPU Acceleration: Automatic GPU usage when available</li> <li>Connection Pooling: Efficient database connection management</li> <li>Batch Operations: Optimized batch insert and search operations</li> <li>Memory Management: Efficient memory usage for large collections</li> </ul>"},{"location":"vectordb/#quick-start-example","title":"\ud83d\ude80 Quick Start Example","text":"<pre><code>from pathlib import Path\nfrom rag_to_riches.vectordb.embedded_vectordb import EmbeddedVectorDB\nfrom rag_to_riches.vectordb.embedder import SimpleTextEmbedder\n\n# Initialize components\nvector_db = EmbeddedVectorDB()\nembedder = SimpleTextEmbedder()\n\n# Create a collection\ncollection_name = \"example_quotes\"\nvector_db.create_collection(\n    collection_name=collection_name,\n    vector_size=embedder.get_vector_size(),\n    distance=embedder.get_distance_metric()\n)\n\n# Embed and store text\ntexts = [\n    \"Dogs are loyal companions who bring joy to our lives.\",\n    \"Cats are independent creatures with mysterious personalities.\",\n    \"Birds teach us about freedom and the beauty of flight.\"\n]\n\n# Generate embeddings\nvectors = embedder.embed_batch(texts)\n\n# Create points for storage\nfrom uuid import uuid4\nfrom qdrant_client import models\n\npoints = []\nfor i, (text, vector) in enumerate(zip(texts, vectors)):\n    point = models.PointStruct(\n        id=str(uuid4()),\n        vector=vector,\n        payload={\"content\": text, \"index\": i}\n    )\n    points.append(point)\n\n# Store in database\nvector_db.upsert_points(collection_name, points)\n\n# Search for similar content\nquery_text = \"loyal pets and friendship\"\nquery_vector = embedder.embed_text(query_text)\nresults = vector_db.search_points(collection_name, query_vector, limit=2)\n\n# Display results\nfor result in results:\n    print(f\"Score: {result.score:.3f}\")\n    print(f\"Text: {result.payload['content']}\")\n    print(\"---\")\n</code></pre>"},{"location":"vectordb/#configuration-options","title":"\ud83d\udee0\ufe0f Configuration Options","text":""},{"location":"vectordb/#embedding-model-selection","title":"Embedding Model Selection","text":"<pre><code># Default model (balanced performance/quality)\nembedder = SimpleTextEmbedder()  # Uses 'sentence-transformers/all-MiniLM-L6-v2'\n\n# High-quality model (larger, slower)\nembedder = SimpleTextEmbedder(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n\n# Fast model (smaller, faster)\nembedder = SimpleTextEmbedder(model_name=\"sentence-transformers/all-MiniLM-L12-v2\")\n\n# Multilingual model\nembedder = SimpleTextEmbedder(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n</code></pre>"},{"location":"vectordb/#vector-database-configuration","title":"Vector Database Configuration","text":"<pre><code># Custom database path (via config)\nconfig = {\n    \"vector_db\": {\n        \"path\": \"/custom/path/to/qdrant\"\n    }\n}\n\n# Different distance metrics\nvector_db.create_collection(\n    collection_name=\"cosine_collection\",\n    vector_size=384,\n    distance=\"Cosine\"  # Options: \"Cosine\", \"Euclid\", \"Dot\"\n)\n</code></pre>"},{"location":"vectordb/#advanced-usage","title":"\ud83d\udd27 Advanced Usage","text":""},{"location":"vectordb/#batch-processing-for-large-collections","title":"Batch Processing for Large Collections","text":"<pre><code># Efficient batch processing\nlarge_text_collection = [...]  # Thousands of texts\n\n# Process in batches to manage memory\nbatch_size = 100\nfor i in range(0, len(large_text_collection), batch_size):\n    batch_texts = large_text_collection[i:i+batch_size]\n    batch_vectors = embedder.embed_batch(batch_texts)\n\n    # Create points\n    batch_points = []\n    for j, (text, vector) in enumerate(zip(batch_texts, batch_vectors)):\n        point = models.PointStruct(\n            id=str(uuid4()),\n            vector=vector,\n            payload={\"content\": text, \"batch\": i//batch_size, \"index\": j}\n        )\n        batch_points.append(point)\n\n    # Store batch\n    vector_db.upsert_points(collection_name, batch_points)\n    print(f\"Processed batch {i//batch_size + 1}\")\n</code></pre>"},{"location":"vectordb/#collection-management","title":"Collection Management","text":"<pre><code># List all collections\ncollections = vector_db.list_collections()\nprint(f\"Available collections: {collections}\")\n\n# Get collection statistics\nstats = vector_db.get_collection_info(\"my_collection\")\nprint(f\"Collection has {stats['points_count']} points\")\n\n# Check collection health\nif vector_db.collection_exists(\"my_collection\"):\n    count = vector_db.count_points(\"my_collection\")\n    print(f\"Collection is healthy with {count} points\")\n</code></pre>"},{"location":"vectordb/#advanced-search-options","title":"Advanced Search Options","text":"<pre><code># Search with score threshold\nresults = vector_db.search_points(\n    collection_name=\"quotes\",\n    query_vector=query_vector,\n    limit=10,\n    score_threshold=0.7  # Only return highly similar results\n)\n\n# Search with metadata filtering (requires Qdrant filters)\nfrom qdrant_client.models import Filter, FieldCondition, MatchValue\n\nfilter_condition = Filter(\n    must=[\n        FieldCondition(\n            key=\"category\",\n            match=MatchValue(value=\"pets\")\n        )\n    ]\n)\n\n# Note: This requires additional implementation in EmbeddedVectorDB\n# filtered_results = vector_db.search_points_with_filter(\n#     collection_name, query_vector, filter_condition\n# )\n</code></pre>"},{"location":"vectordb/#integration-with-other-packages","title":"\ud83d\udd17 Integration with Other Packages","text":"<p>The vectordb package seamlessly integrates with other framework components:</p>"},{"location":"vectordb/#with-corpus-package","title":"With Corpus Package","text":"<pre><code>from rag_to_riches.corpus.animals import Animals\n\n# Animals class uses vectordb internally\nanimals = Animals(vector_db, embedder)\nwisdom = animals.load_from_jsonl(\"quotes.jsonl\")\nanimals.index_all_quotes()  # Uses vectordb for storage\n</code></pre>"},{"location":"vectordb/#with-search-package","title":"With Search Package","text":"<pre><code>from rag_to_riches.search.semantic_search import SemanticSearch\n\n# SemanticSearch combines embedder and vector_db\nsearch = SemanticSearch(\n    embedder=embedder,\n    vector_db=vector_db,\n    collection_name=\"search_collection\"\n)\n</code></pre>"},{"location":"vectordb/#error-handling","title":"\ud83d\udee1\ufe0f Error Handling","text":"<p>The package provides comprehensive error handling with custom exceptions:</p> <pre><code>from rag_to_riches.exceptions import (\n    VectorDatabasePathNotFoundError,\n    CollectionAlreadyExistsError,\n    CollectionNotFoundError,\n    InvalidVectorSizeError,\n    InvalidDistanceMetricError\n)\n\ntry:\n    # This might fail if collection exists\n    vector_db.create_collection(\"existing_collection\", 384, \"Cosine\")\nexcept CollectionAlreadyExistsError as e:\n    print(f\"Collection already exists: {e}\")\n    # Handle gracefully - maybe use existing collection\n\ntry:\n    # This might fail if collection doesn't exist\n    count = vector_db.count_points(\"nonexistent_collection\")\nexcept CollectionNotFoundError as e:\n    print(f\"Collection not found: {e}\")\n    # Create collection or handle error\n</code></pre>"},{"location":"vectordb/#performance-considerations","title":"\ud83d\udcca Performance Considerations","text":""},{"location":"vectordb/#memory-usage","title":"Memory Usage","text":"<ul> <li>Embedding Models: Models are loaded once and cached in memory</li> <li>Batch Size: Optimize batch sizes based on available memory</li> <li>Vector Storage: Qdrant efficiently manages vector storage on disk</li> </ul>"},{"location":"vectordb/#speed-optimization","title":"Speed Optimization","text":"<ul> <li>GPU Acceleration: Automatically uses GPU if available for embeddings</li> <li>Parallel Processing: Sentence transformers support parallel batch processing</li> <li>Connection Reuse: Database connections are reused for efficiency</li> </ul>"},{"location":"vectordb/#scalability","title":"Scalability","text":"<ul> <li>Collection Size: Qdrant can handle millions of vectors efficiently</li> <li>Search Speed: Sub-second search times for most collection sizes</li> <li>Storage: Efficient compression and indexing for large datasets</li> </ul>"},{"location":"vectordb/#use-cases","title":"\ud83c\udfaf Use Cases","text":"<ul> <li>Semantic Search: Find similar documents based on meaning</li> <li>Content Recommendation: Suggest related content to users</li> <li>Duplicate Detection: Identify similar or duplicate content</li> <li>Content Clustering: Group similar content automatically</li> <li>Question Answering: Find relevant context for user questions</li> </ul>"},{"location":"vectordb/#detailed-documentation","title":"\ud83d\udcda Detailed Documentation","text":"<ul> <li>EmbeddedVectorDB Class: Complete database operations</li> <li>SimpleTextEmbedder Class: Text embedding and transformation</li> </ul>"},{"location":"vectordb/#dependencies","title":"\ud83d\udd27 Dependencies","text":"<p>The vectordb package relies on several key technologies:</p> <ul> <li>Qdrant: High-performance vector database</li> <li>Sentence Transformers: State-of-the-art text embeddings</li> <li>PyTorch: Deep learning framework for embeddings</li> <li>Loguru: Comprehensive logging</li> <li>icontract: Design-by-contract validation</li> </ul> <p>The vectordb package provides the essential infrastructure for semantic search - transforming text into meaningful vectors and storing them efficiently for lightning-fast similarity search. Perfect for building intelligent applications that understand content meaning rather than just keywords. </p>"},{"location":"vectordb/EmbeddedVectorDB/","title":"EmbeddedVectorDB Class","text":""},{"location":"vectordb/EmbeddedVectorDB/#overview","title":"Overview","text":"<p>The <code>EmbeddedVectorDB</code> class provides a comprehensive interface to an embedded Qdrant vector database. This class handles all vector database operations including collection management, point storage and retrieval, and search functionality for semantic search applications.</p>"},{"location":"vectordb/EmbeddedVectorDB/#class-definition","title":"Class Definition","text":"<pre><code>from rag_to_riches.vectordb.embedded_vectordb import EmbeddedVectorDB\n\nclass EmbeddedVectorDB:\n    \"\"\"\n    Embedded Qdrant vector database for efficient similarity search.\n\n    Provides a complete interface for vector storage, retrieval, and search\n    operations using a local Qdrant instance.\n    \"\"\"\n</code></pre>"},{"location":"vectordb/EmbeddedVectorDB/#key-features","title":"Key Features","text":"<ul> <li>Local Vector Storage: Embedded Qdrant database for production and development</li> <li>Collection Management: Create, configure, and manage vector collections</li> <li>CRUD Operations: Complete create, read, update, delete functionality</li> <li>Similarity Search: High-performance vector similarity search</li> <li>Health Monitoring: Database health checks and statistics</li> <li>Flexible Configuration: Customizable distance metrics and collection settings</li> </ul>"},{"location":"vectordb/EmbeddedVectorDB/#constructor","title":"Constructor","text":"<pre><code>def __init__(self, config: Optional[Dict[str, Any]] = None):\n    \"\"\"\n    Initialize the embedded vector database.\n\n    Args:\n        config: Optional configuration dictionary\n                Default uses local Qdrant with standard settings\n    \"\"\"\n</code></pre>"},{"location":"vectordb/EmbeddedVectorDB/#configuration-options","title":"Configuration Options","text":"<pre><code># Default configuration\nvector_db = EmbeddedVectorDB()\n\n# Custom configuration\nconfig = {\n    \"host\": \"localhost\",\n    \"port\": 6333,\n    \"grpc_port\": 6334,\n    \"prefer_grpc\": True,\n    \"https\": False,\n    \"api_key\": None,\n    \"path\": \"./qdrant_db\"  # Local storage path\n}\nvector_db = EmbeddedVectorDB(config)\n</code></pre>"},{"location":"vectordb/EmbeddedVectorDB/#core-methods","title":"Core Methods","text":""},{"location":"vectordb/EmbeddedVectorDB/#collection-management","title":"Collection Management","text":""},{"location":"vectordb/EmbeddedVectorDB/#create_collection","title":"create_collection()","text":"<pre><code>def create_collection(\n    self,\n    collection_name: str,\n    vector_size: int,\n    distance: str = \"Cosine\"\n) -&gt; bool:\n    \"\"\"\n    Create a new vector collection.\n\n    Args:\n        collection_name: Name of the collection to create\n        vector_size: Dimension of vectors to store\n        distance: Distance metric (\"Cosine\", \"Euclid\", \"Dot\")\n\n    Returns:\n        bool: True if collection created successfully\n\n    Raises:\n        DatabaseError: If collection creation fails\n    \"\"\"\n</code></pre> <p>Usage Example: <pre><code># Create a collection for 384-dimensional embeddings\nsuccess = vector_db.create_collection(\n    collection_name=\"document_embeddings\",\n    vector_size=384,\n    distance=\"Cosine\"\n)\n\nif success:\n    print(\"Collection created successfully\")\n</code></pre></p>"},{"location":"vectordb/EmbeddedVectorDB/#delete_collection","title":"delete_collection()","text":"<pre><code>def delete_collection(self, collection_name: str) -&gt; bool:\n    \"\"\"\n    Delete an existing collection.\n\n    Args:\n        collection_name: Name of collection to delete\n\n    Returns:\n        bool: True if deletion successful\n    \"\"\"\n</code></pre>"},{"location":"vectordb/EmbeddedVectorDB/#get_collection_info","title":"get_collection_info()","text":"<pre><code>def get_collection_info(self, collection_name: str) -&gt; Dict[str, Any]:\n    \"\"\"\n    Get detailed information about a collection.\n\n    Returns:\n        dict: Collection metadata and statistics\n    \"\"\"\n</code></pre>"},{"location":"vectordb/EmbeddedVectorDB/#point-operations","title":"Point Operations","text":""},{"location":"vectordb/EmbeddedVectorDB/#upsert_points","title":"upsert_points()","text":"<pre><code>def upsert_points(\n    self,\n    collection_name: str,\n    points: List[models.PointStruct]\n) -&gt; None:\n    \"\"\"\n    Insert or update points in the collection.\n\n    Args:\n        collection_name: Target collection name\n        points: List of PointStruct objects to upsert\n\n    Raises:\n        DatabaseError: If upsert operation fails\n    \"\"\"\n</code></pre> <p>Usage Example: <pre><code>from qdrant_client import models\nfrom uuid import uuid4\n\n# Create points\npoints = [\n    models.PointStruct(\n        id=str(uuid4()),\n        vector=[0.1, 0.2, 0.3, ...],  # 384-dimensional vector\n        payload={\n            \"content\": \"Example text content\",\n            \"category\": \"example\",\n            \"timestamp\": \"2024-01-15T10:30:00Z\"\n        }\n    )\n]\n\n# Upsert to collection\nvector_db.upsert_points(\"document_embeddings\", points)\n</code></pre></p>"},{"location":"vectordb/EmbeddedVectorDB/#search_points","title":"search_points()","text":"<pre><code>def search_points(\n    self,\n    collection_name: str,\n    query_vector: List[float],\n    limit: int = 10,\n    score_threshold: Optional[float] = None,\n    filter_conditions: Optional[models.Filter] = None\n) -&gt; List[models.ScoredPoint]:\n    \"\"\"\n    Search for similar vectors in the collection.\n\n    Args:\n        collection_name: Collection to search in\n        query_vector: Vector to find similarities for\n        limit: Maximum number of results to return\n        score_threshold: Minimum similarity score\n        filter_conditions: Optional metadata filters\n\n    Returns:\n        List of ScoredPoint objects with similarity scores\n    \"\"\"\n</code></pre> <p>Usage Example: <pre><code># Search for similar vectors\nquery_vector = embedder.embed_text(\"search query\")\nresults = vector_db.search_points(\n    collection_name=\"document_embeddings\",\n    query_vector=query_vector,\n    limit=5,\n    score_threshold=0.7\n)\n\nfor result in results:\n    print(f\"Score: {result.score:.3f}\")\n    print(f\"Content: {result.payload['content']}\")\n</code></pre></p>"},{"location":"vectordb/EmbeddedVectorDB/#count_points","title":"count_points()","text":"<pre><code>def count_points(self, collection_name: str) -&gt; int:\n    \"\"\"\n    Count the number of points in a collection.\n\n    Returns:\n        int: Number of points in the collection\n    \"\"\"\n</code></pre>"},{"location":"vectordb/EmbeddedVectorDB/#advanced-search","title":"Advanced Search","text":""},{"location":"vectordb/EmbeddedVectorDB/#search_with_filters","title":"search_with_filters()","text":"<pre><code>def search_with_filters(\n    self,\n    collection_name: str,\n    query_vector: List[float],\n    metadata_filter: Dict[str, Any],\n    limit: int = 10\n) -&gt; List[models.ScoredPoint]:\n    \"\"\"\n    Search with metadata filtering.\n\n    Args:\n        metadata_filter: Dictionary of filter conditions\n\n    Example filters:\n        {\"category\": \"science\"}\n        {\"rating\": {\"gte\": 4.0}}\n        {\"tags\": {\"any\": [\"python\", \"ml\"]}}\n    \"\"\"\n</code></pre> <p>Usage Example: <pre><code># Search with category filter\nresults = vector_db.search_with_filters(\n    collection_name=\"document_embeddings\",\n    query_vector=query_vector,\n    metadata_filter={\"category\": \"research\"},\n    limit=10\n)\n\n# Complex filter example\ncomplex_filter = {\n    \"must\": [\n        {\"key\": \"category\", \"match\": {\"value\": \"science\"}},\n        {\"key\": \"rating\", \"range\": {\"gte\": 4.0}}\n    ]\n}\n</code></pre></p>"},{"location":"vectordb/EmbeddedVectorDB/#health-and-monitoring","title":"Health and Monitoring","text":""},{"location":"vectordb/EmbeddedVectorDB/#consistency_check","title":"consistency_check()","text":"<pre><code>def consistency_check(self, collection_name: str) -&gt; Dict[str, Any]:\n    \"\"\"\n    Perform consistency check on collection.\n\n    Returns:\n        dict: Health status and any issues found\n    \"\"\"\n</code></pre>"},{"location":"vectordb/EmbeddedVectorDB/#get_database_stats","title":"get_database_stats()","text":"<pre><code>def get_database_stats(self) -&gt; Dict[str, Any]:\n    \"\"\"\n    Get overall database statistics.\n\n    Returns:\n        dict: Database health, memory usage, collection stats\n    \"\"\"\n</code></pre>"},{"location":"vectordb/EmbeddedVectorDB/#error-handling","title":"Error Handling","text":"<p>The <code>EmbeddedVectorDB</code> class uses the project's exception hierarchy:</p> <pre><code>from rag_to_riches.exceptions import DatabaseError, CollectionNotFoundError\n\ntry:\n    vector_db.create_collection(\"test\", 384)\nexcept DatabaseError as e:\n    print(f\"Database error: {e}\")\nexcept CollectionNotFoundError as e:\n    print(f\"Collection not found: {e}\")\n</code></pre>"},{"location":"vectordb/EmbeddedVectorDB/#performance-considerations","title":"Performance Considerations","text":""},{"location":"vectordb/EmbeddedVectorDB/#batch-operations","title":"Batch Operations","text":"<pre><code># Efficient batch upsert\nlarge_points_batch = [...]  # Many points\n\n# Process in chunks for memory efficiency\nchunk_size = 1000\nfor i in range(0, len(large_points_batch), chunk_size):\n    chunk = large_points_batch[i:i + chunk_size]\n    vector_db.upsert_points(collection_name, chunk)\n</code></pre>"},{"location":"vectordb/EmbeddedVectorDB/#connection-management","title":"Connection Management","text":"<pre><code># The class automatically manages connections\n# Multiple operations reuse the same connection\nvector_db.create_collection(\"col1\", 384)\nvector_db.upsert_points(\"col1\", points1)\nvector_db.search_points(\"col1\", query_vector1)\n# No need to manually manage connections\n</code></pre>"},{"location":"vectordb/EmbeddedVectorDB/#memory-optimization","title":"Memory Optimization","text":"<pre><code># For large collections, consider:\n# 1. Batch processing\n# 2. Appropriate vector dimensions\n# 3. Regular cleanup of unused collections\n\n# Monitor memory usage\nstats = vector_db.get_database_stats()\nprint(f\"Memory usage: {stats['memory_usage_mb']} MB\")\n</code></pre>"},{"location":"vectordb/EmbeddedVectorDB/#integration-examples","title":"Integration Examples","text":""},{"location":"vectordb/EmbeddedVectorDB/#with-simpletextembedder","title":"With SimpleTextEmbedder","text":"<pre><code>from rag_to_riches.vectordb.embedder import SimpleTextEmbedder\n\n# Complete pipeline\nembedder = SimpleTextEmbedder()\nvector_db = EmbeddedVectorDB()\n\n# Setup\ncollection_name = \"documents\"\nvector_db.create_collection(\n    collection_name,\n    embedder.get_vector_size(),\n    embedder.get_distance_metric()\n)\n\n# Add documents\ntexts = [\"Document 1\", \"Document 2\", \"Document 3\"]\nvectors = embedder.embed_batch(texts)\n\npoints = []\nfor i, (text, vector) in enumerate(zip(texts, vectors)):\n    points.append(models.PointStruct(\n        id=f\"doc_{i}\",\n        vector=vector,\n        payload={\"content\": text}\n    ))\n\nvector_db.upsert_points(collection_name, points)\n\n# Search\nquery = \"search terms\"\nquery_vector = embedder.embed_text(query)\nresults = vector_db.search_points(collection_name, query_vector)\n</code></pre>"},{"location":"vectordb/EmbeddedVectorDB/#with-corpus-classes","title":"With Corpus Classes","text":"<pre><code>from rag_to_riches.corpus.animals import Animals\n\n# Used automatically by corpus classes\nanimals = Animals(vector_db, collection_name=\"animal_wisdom\")\n\n# The corpus class handles all vector operations internally\n# vector_db methods are called automatically during:\n# - Data loading and indexing\n# - Search operations\n# - Collection management\n</code></pre>"},{"location":"vectordb/EmbeddedVectorDB/#configuration-and-environment","title":"Configuration and Environment","text":""},{"location":"vectordb/EmbeddedVectorDB/#environment-variables","title":"Environment Variables","text":"<pre><code># Optional environment configuration\nexport QDRANT_HOST=localhost\nexport QDRANT_PORT=6333\nexport QDRANT_API_KEY=your_api_key  # For cloud instances\n</code></pre>"},{"location":"vectordb/EmbeddedVectorDB/#production-configuration","title":"Production Configuration","text":"<pre><code># Production setup with persistence\nproduction_config = {\n    \"path\": \"/data/qdrant_storage\",  # Persistent storage\n    \"host\": \"localhost\",\n    \"port\": 6333,\n    \"grpc_port\": 6334,\n    \"prefer_grpc\": True,  # Better performance\n    \"timeout\": 30.0\n}\n\nvector_db = EmbeddedVectorDB(production_config)\n</code></pre>"},{"location":"vectordb/EmbeddedVectorDB/#troubleshooting","title":"Troubleshooting","text":""},{"location":"vectordb/EmbeddedVectorDB/#common-issues","title":"Common Issues","text":"<ol> <li> <p>Collection Already Exists <pre><code>try:\n    vector_db.create_collection(\"existing\", 384)\nexcept DatabaseError as e:\n    if \"already exists\" in str(e):\n        print(\"Collection exists, using existing collection\")\n</code></pre></p> </li> <li> <p>Dimension Mismatch <pre><code># Ensure vector dimensions match collection\ncollection_info = vector_db.get_collection_info(\"my_collection\")\nexpected_size = collection_info[\"config\"][\"params\"][\"vectors\"][\"size\"]\n\nif len(query_vector) != expected_size:\n    raise ValueError(f\"Vector size mismatch: {len(query_vector)} != {expected_size}\")\n</code></pre></p> </li> <li> <p>Database Connection Issues <pre><code># Check database health\ntry:\n    stats = vector_db.get_database_stats()\n    print(\"Database is healthy\")\nexcept Exception as e:\n    print(f\"Database connection issue: {e}\")\n</code></pre></p> </li> </ol>"},{"location":"vectordb/EmbeddedVectorDB/#related-components","title":"Related Components","text":"<ul> <li><code>SimpleTextEmbedder</code>: Text embedding component</li> <li><code>SemanticSearch</code>: High-level search interface</li> <li><code>Animals</code>: Domain-specific corpus using this database</li> <li><code>Exceptions</code>: Error handling for database operations</li> </ul> <p>Part of the RAG to Riches framework - reliable vector storage for intelligent applications. </p>"},{"location":"vectordb/SimpleTextEmbedder/","title":"SimpleTextEmbedder Class","text":""},{"location":"vectordb/SimpleTextEmbedder/#overview","title":"Overview","text":"<p>The <code>SimpleTextEmbedder</code> class provides an easy-to-use interface for converting text into high-dimensional vector embeddings using state-of-the-art sentence transformer models. This class handles the complex process of text encoding, making semantic search accessible through simple method calls.</p>"},{"location":"vectordb/SimpleTextEmbedder/#class-definition","title":"Class Definition","text":"<pre><code>from rag_to_riches.vectordb.embedder import SimpleTextEmbedder\n\nclass SimpleTextEmbedder:\n    \"\"\"\n    Text-to-vector embedding using sentence transformers.\n\n    Provides efficient text embedding with automatic model management,\n    caching, and batch processing capabilities.\n    \"\"\"\n</code></pre>"},{"location":"vectordb/SimpleTextEmbedder/#key-features","title":"Key Features","text":"<ul> <li>State-of-the-Art Models: Uses sentence transformer models optimized for semantic understanding</li> <li>Automatic Model Management: Downloads and caches models automatically</li> <li>Batch Processing: Efficient processing of multiple texts</li> <li>GPU Acceleration: Automatic GPU usage when available</li> <li>Consistent Outputs: Deterministic embeddings for the same input</li> <li>Flexible Model Selection: Support for various embedding models</li> </ul>"},{"location":"vectordb/SimpleTextEmbedder/#constructor","title":"Constructor","text":"<pre><code>def __init__(\n    self,\n    model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\",\n    device: Optional[str] = None,\n    cache_folder: Optional[str] = None\n):\n    \"\"\"\n    Initialize the text embedder.\n\n    Args:\n        model_name: HuggingFace model identifier\n        device: Device to use (\"cpu\", \"cuda\", \"auto\")\n        cache_folder: Custom cache directory for models\n    \"\"\"\n</code></pre>"},{"location":"vectordb/SimpleTextEmbedder/#model-selection","title":"Model Selection","text":"<pre><code># Default model - balanced performance and quality\nembedder = SimpleTextEmbedder()\n\n# High-quality model (larger, slower)\nembedder = SimpleTextEmbedder(\"sentence-transformers/all-mpnet-base-v2\")\n\n# Fast model (smaller, faster)\nembedder = SimpleTextEmbedder(\"sentence-transformers/all-MiniLM-L12-v2\")\n\n# Multilingual model\nembedder = SimpleTextEmbedder(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n\n# Domain-specific models\nembedder = SimpleTextEmbedder(\"sentence-transformers/all-distilroberta-v1\")  # General\nembedder = SimpleTextEmbedder(\"sentence-transformers/msmarco-distilbert-base-v4\")  # Search\n</code></pre>"},{"location":"vectordb/SimpleTextEmbedder/#device-configuration","title":"Device Configuration","text":"<pre><code># Automatic device selection (recommended)\nembedder = SimpleTextEmbedder(device=\"auto\")\n\n# Force CPU usage\nembedder = SimpleTextEmbedder(device=\"cpu\")\n\n# Force GPU usage (if available)\nembedder = SimpleTextEmbedder(device=\"cuda\")\n\n# Specific GPU device\nembedder = SimpleTextEmbedder(device=\"cuda:0\")\n</code></pre>"},{"location":"vectordb/SimpleTextEmbedder/#core-methods","title":"Core Methods","text":""},{"location":"vectordb/SimpleTextEmbedder/#single-text-embedding","title":"Single Text Embedding","text":""},{"location":"vectordb/SimpleTextEmbedder/#embed_text","title":"embed_text()","text":"<pre><code>def embed_text(self, text: str) -&gt; List[float]:\n    \"\"\"\n    Generate embedding for a single text.\n\n    Args:\n        text: Input text to embed\n\n    Returns:\n        List[float]: Vector embedding of the text\n\n    Raises:\n        EmbeddingError: If embedding generation fails\n    \"\"\"\n</code></pre> <p>Usage Example: <pre><code># Simple text embedding\ntext = \"Dogs are loyal companions who bring joy to our lives.\"\nembedding = embedder.embed_text(text)\n\nprint(f\"Text: {text}\")\nprint(f\"Embedding dimensions: {len(embedding)}\")\nprint(f\"First 5 values: {embedding[:5]}\")\n\n# Output:\n# Text: Dogs are loyal companions who bring joy to our lives.\n# Embedding dimensions: 384\n# First 5 values: [0.123, -0.456, 0.789, 0.321, -0.654]\n</code></pre></p>"},{"location":"vectordb/SimpleTextEmbedder/#batch-text-embedding","title":"Batch Text Embedding","text":""},{"location":"vectordb/SimpleTextEmbedder/#embed_batch","title":"embed_batch()","text":"<pre><code>def embed_batch(\n    self,\n    texts: List[str],\n    batch_size: int = 32,\n    show_progress: bool = False\n) -&gt; List[List[float]]:\n    \"\"\"\n    Generate embeddings for multiple texts efficiently.\n\n    Args:\n        texts: List of texts to embed\n        batch_size: Number of texts to process at once\n        show_progress: Whether to show progress bar\n\n    Returns:\n        List[List[float]]: List of vector embeddings\n    \"\"\"\n</code></pre> <p>Usage Example: <pre><code># Batch embedding for efficiency\ntexts = [\n    \"Cats are independent creatures with mysterious personalities.\",\n    \"Birds teach us about freedom and the beauty of flight.\",\n    \"Elephants demonstrate wisdom and strong family bonds.\",\n    \"Dolphins show intelligence and playful social behavior.\"\n]\n\n# Process all texts in batches\nembeddings = embedder.embed_batch(texts, show_progress=True)\n\nprint(f\"Processed {len(texts)} texts\")\nprint(f\"Each embedding has {len(embeddings[0])} dimensions\")\n\n# Use the embeddings\nfor i, (text, embedding) in enumerate(zip(texts, embeddings)):\n    print(f\"Text {i+1}: {text[:50]}...\")\n    print(f\"Embedding magnitude: {sum(x*x for x in embedding)**0.5:.3f}\")\n</code></pre></p>"},{"location":"vectordb/SimpleTextEmbedder/#model-information","title":"Model Information","text":""},{"location":"vectordb/SimpleTextEmbedder/#get_vector_size","title":"get_vector_size()","text":"<pre><code>def get_vector_size(self) -&gt; int:\n    \"\"\"\n    Get the dimensionality of the embeddings.\n\n    Returns:\n        int: Number of dimensions in the embedding vectors\n    \"\"\"\n</code></pre>"},{"location":"vectordb/SimpleTextEmbedder/#get_distance_metric","title":"get_distance_metric()","text":"<pre><code>def get_distance_metric(self) -&gt; str:\n    \"\"\"\n    Get the recommended distance metric for this model.\n\n    Returns:\n        str: Distance metric (\"Cosine\", \"Euclid\", \"Dot\")\n    \"\"\"\n</code></pre>"},{"location":"vectordb/SimpleTextEmbedder/#get_model_info","title":"get_model_info()","text":"<pre><code>def get_model_info(self) -&gt; Dict[str, Any]:\n    \"\"\"\n    Get comprehensive model information.\n\n    Returns:\n        dict: Model metadata including size, capabilities, performance\n    \"\"\"\n</code></pre> <p>Usage Example: <pre><code># Get model specifications\nprint(f\"Vector size: {embedder.get_vector_size()}\")\nprint(f\"Distance metric: {embedder.get_distance_metric()}\")\n\nmodel_info = embedder.get_model_info()\nprint(f\"Model name: {model_info['name']}\")\nprint(f\"Max sequence length: {model_info['max_seq_length']}\")\nprint(f\"Model size: {model_info['model_size_mb']} MB\")\n</code></pre></p>"},{"location":"vectordb/SimpleTextEmbedder/#advanced-features","title":"Advanced Features","text":""},{"location":"vectordb/SimpleTextEmbedder/#text-preprocessing","title":"Text Preprocessing","text":"<pre><code>def embed_text_with_preprocessing(\n    self,\n    text: str,\n    normalize: bool = True,\n    remove_special_chars: bool = False,\n    max_length: Optional[int] = None\n) -&gt; List[float]:\n    \"\"\"\n    Embed text with preprocessing options.\n\n    Args:\n        normalize: Whether to normalize text casing and whitespace\n        remove_special_chars: Remove special characters\n        max_length: Truncate text to maximum length\n    \"\"\"\n</code></pre> <p>Usage Example: <pre><code># Text with preprocessing\nraw_text = \"  Hello!!! This is a TEST with WEIRD formatting...  \"\n\n# Clean and embed\nembedding = embedder.embed_text_with_preprocessing(\n    raw_text,\n    normalize=True,\n    remove_special_chars=True,\n    max_length=100\n)\n</code></pre></p>"},{"location":"vectordb/SimpleTextEmbedder/#similarity-calculation","title":"Similarity Calculation","text":"<pre><code>def calculate_similarity(\n    self,\n    embedding1: List[float],\n    embedding2: List[float],\n    metric: str = \"cosine\"\n) -&gt; float:\n    \"\"\"\n    Calculate similarity between two embeddings.\n\n    Args:\n        embedding1, embedding2: Vector embeddings to compare\n        metric: Similarity metric (\"cosine\", \"euclidean\", \"dot\")\n\n    Returns:\n        float: Similarity score\n    \"\"\"\n</code></pre> <p>Usage Example: <pre><code># Compare text similarity\ntext1 = \"Dogs are loyal friends\"\ntext2 = \"Canines are faithful companions\"\ntext3 = \"I like pizza\"\n\nemb1 = embedder.embed_text(text1)\nemb2 = embedder.embed_text(text2)\nemb3 = embedder.embed_text(text3)\n\n# Calculate similarities\nsim_1_2 = embedder.calculate_similarity(emb1, emb2)\nsim_1_3 = embedder.calculate_similarity(emb1, emb3)\n\nprint(f\"Similarity between '{text1}' and '{text2}': {sim_1_2:.3f}\")\nprint(f\"Similarity between '{text1}' and '{text3}': {sim_1_3:.3f}\")\n\n# Output:\n# Similarity between 'Dogs are loyal friends' and 'Canines are faithful companions': 0.847\n# Similarity between 'Dogs are loyal friends' and 'I like pizza': 0.123\n</code></pre></p>"},{"location":"vectordb/SimpleTextEmbedder/#performance-optimization","title":"Performance Optimization","text":""},{"location":"vectordb/SimpleTextEmbedder/#caching","title":"Caching","text":"<pre><code># Enable embedding caching for repeated texts\nembedder.enable_cache(max_size=1000)\n\n# First call - computes embedding\nembedding1 = embedder.embed_text(\"This text will be cached\")\n\n# Second call - retrieves from cache (much faster)\nembedding2 = embedder.embed_text(\"This text will be cached\")\n\n# Cache statistics\ncache_stats = embedder.get_cache_stats()\nprint(f\"Cache hits: {cache_stats['hits']}\")\nprint(f\"Cache size: {cache_stats['size']}\")\n</code></pre>"},{"location":"vectordb/SimpleTextEmbedder/#batch-size-optimization","title":"Batch Size Optimization","text":"<pre><code># Optimize batch size for your hardware\ntexts = [\"Text {}\".format(i) for i in range(1000)]\n\n# Small batches for limited memory\nembeddings = embedder.embed_batch(texts, batch_size=16)\n\n# Large batches for high-memory systems\nembeddings = embedder.embed_batch(texts, batch_size=128)\n\n# Automatic batch size selection\nembeddings = embedder.embed_batch(texts, batch_size=\"auto\")\n</code></pre>"},{"location":"vectordb/SimpleTextEmbedder/#memory-management","title":"Memory Management","text":"<pre><code># For large-scale processing\ndef process_large_text_collection(texts, embedder):\n    \"\"\"Process large collections efficiently.\"\"\"\n\n    embeddings = []\n    batch_size = 64\n\n    for i in range(0, len(texts), batch_size):\n        batch = texts[i:i + batch_size]\n        batch_embeddings = embedder.embed_batch(batch)\n        embeddings.extend(batch_embeddings)\n\n        # Clear GPU cache periodically\n        if i % 1000 == 0:\n            embedder.clear_gpu_cache()\n\n    return embeddings\n</code></pre>"},{"location":"vectordb/SimpleTextEmbedder/#integration-examples","title":"Integration Examples","text":""},{"location":"vectordb/SimpleTextEmbedder/#with-embeddedvectordb","title":"With EmbeddedVectorDB","text":"<pre><code>from rag_to_riches.vectordb.embedded_vectordb import EmbeddedVectorDB\n\n# Complete embedding and storage pipeline\nembedder = SimpleTextEmbedder()\nvector_db = EmbeddedVectorDB()\n\n# Create collection with correct dimensions\ncollection_name = \"documents\"\nvector_db.create_collection(\n    collection_name,\n    vector_size=embedder.get_vector_size(),\n    distance=embedder.get_distance_metric()\n)\n\n# Embed and store documents\ndocuments = [\"Document 1\", \"Document 2\", \"Document 3\"]\nembeddings = embedder.embed_batch(documents)\n\n# Store in vector database\n# (see EmbeddedVectorDB documentation for storage details)\n</code></pre>"},{"location":"vectordb/SimpleTextEmbedder/#with-search-operations","title":"With Search Operations","text":"<pre><code>from rag_to_riches.search.semantic_search import SemanticSearch\n\n# Initialize search with embedder\nsearch_engine = SemanticSearch(\n    vector_db=vector_db,\n    embedder=embedder,\n    collection_name=\"documents\"\n)\n\n# The search engine uses the embedder automatically\nresults = search_engine.search(\"query text\")\n</code></pre>"},{"location":"vectordb/SimpleTextEmbedder/#with-corpus-classes","title":"With Corpus Classes","text":"<pre><code>from rag_to_riches.corpus.animals import Animals\n\n# Custom embedder for animals corpus\ncustom_embedder = SimpleTextEmbedder(\"sentence-transformers/all-mpnet-base-v2\")\n\nanimals = Animals(\n    vector_db,\n    collection_name=\"animal_wisdom\",\n    embedder=custom_embedder\n)\n\n# The corpus uses the custom embedder for all operations\n</code></pre>"},{"location":"vectordb/SimpleTextEmbedder/#model-comparison","title":"Model Comparison","text":""},{"location":"vectordb/SimpleTextEmbedder/#performance-vs-quality-trade-offs","title":"Performance vs Quality Trade-offs","text":"Model Size Speed Quality Use Case <code>all-MiniLM-L6-v2</code> 80MB Fast Good General purpose, development <code>all-MiniLM-L12-v2</code> 120MB Medium Better Balanced performance/quality <code>all-mpnet-base-v2</code> 420MB Slow Best High-quality production <code>all-distilroberta-v1</code> 290MB Medium Very Good General text understanding"},{"location":"vectordb/SimpleTextEmbedder/#specialized-models","title":"Specialized Models","text":"<pre><code># For specific domains\nscientific_embedder = SimpleTextEmbedder(\"allenai/scibert_scivocab_uncased\")\nlegal_embedder = SimpleTextEmbedder(\"nlpaueb/legal-bert-base-uncased\")\n\n# For multilingual content\nmultilingual_embedder = SimpleTextEmbedder(\n    \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n)\n\n# For code and technical content\ncode_embedder = SimpleTextEmbedder(\"microsoft/codebert-base\")\n</code></pre>"},{"location":"vectordb/SimpleTextEmbedder/#error-handling","title":"Error Handling","text":"<pre><code>from rag_to_riches.exceptions import EmbeddingError\n\ntry:\n    embedding = embedder.embed_text(\"Some text\")\nexcept EmbeddingError as e:\n    print(f\"Embedding failed: {e}\")\n    # Handle the error (retry, fallback model, etc.)\n</code></pre>"},{"location":"vectordb/SimpleTextEmbedder/#configuration-and-environment","title":"Configuration and Environment","text":""},{"location":"vectordb/SimpleTextEmbedder/#environment-variables","title":"Environment Variables","text":"<pre><code># Set cache directory\nexport SENTENCE_TRANSFORMERS_HOME=/custom/cache/path\n\n# Set device preference\nexport CUDA_VISIBLE_DEVICES=0\n\n# Control memory usage\nexport PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128\n</code></pre>"},{"location":"vectordb/SimpleTextEmbedder/#production-configuration","title":"Production Configuration","text":"<pre><code># Production embedder setup\nproduction_embedder = SimpleTextEmbedder(\n    model_name=\"sentence-transformers/all-mpnet-base-v2\",\n    device=\"auto\",  # Use best available device\n    cache_folder=\"/data/model_cache\"\n)\n\n# Enable optimizations\nproduction_embedder.enable_cache(max_size=10000)\nproduction_embedder.set_batch_size_auto()\n</code></pre>"},{"location":"vectordb/SimpleTextEmbedder/#troubleshooting","title":"Troubleshooting","text":""},{"location":"vectordb/SimpleTextEmbedder/#common-issues","title":"Common Issues","text":"<ol> <li> <p>Model Download Issues <pre><code># Manual model download\ntry:\n    embedder = SimpleTextEmbedder(\"model-name\")\nexcept Exception as e:\n    print(f\"Download failed: {e}\")\n    # Use offline mode or alternative model\n</code></pre></p> </li> <li> <p>Memory Issues <pre><code># Reduce batch size for large models\nembedder = SimpleTextEmbedder(\n    \"sentence-transformers/all-mpnet-base-v2\"\n)\n\n# Process in smaller batches\nembeddings = embedder.embed_batch(texts, batch_size=8)\n</code></pre></p> </li> <li> <p>GPU Out of Memory <pre><code># Force CPU usage\nembedder = SimpleTextEmbedder(device=\"cpu\")\n\n# Or clear GPU cache\nembedder.clear_gpu_cache()\n</code></pre></p> </li> </ol>"},{"location":"vectordb/SimpleTextEmbedder/#performance-monitoring","title":"Performance Monitoring","text":"<pre><code>import time\n\n# Measure embedding performance\nstart_time = time.time()\nembeddings = embedder.embed_batch(test_texts)\nduration = time.time() - start_time\n\nprint(f\"Processed {len(test_texts)} texts in {duration:.2f} seconds\")\nprint(f\"Rate: {len(test_texts)/duration:.1f} texts/second\")\n</code></pre>"},{"location":"vectordb/SimpleTextEmbedder/#related-components","title":"Related Components","text":"<ul> <li><code>EmbeddedVectorDB</code>: Vector storage component that uses embeddings</li> <li><code>SemanticSearch</code>: High-level search interface using embeddings</li> <li><code>Animals</code>: Domain-specific corpus that uses text embeddings</li> <li><code>Exceptions</code>: Error handling for embedding operations</li> </ul> <p>Part of the RAG to Riches framework - transforming text into intelligent vector representations. </p>"}]}