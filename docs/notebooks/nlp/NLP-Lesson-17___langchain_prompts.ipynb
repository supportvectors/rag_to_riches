{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa2f8212",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-08T08:19:49.294037Z",
     "start_time": "2023-04-08T08:19:47.533476Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<!-- Many of the styles here are inspired by: \n",
       "    https://towardsdatascience.com/10-practical-tips-you-need-to-know-to-personalize-jupyter-notebook-fbd202777e20 \n",
       "       \n",
       "    \n",
       "    On the author's local machine, these exist in the custom.css file. However, in order to keep uniform look and feel, \n",
       "    and at the request of participants, I have added it to this common import-file here.\n",
       "\n",
       "    -->\n",
       "\n",
       "<link href=\"https://fonts.googleapis.com/css?family=Lora:400,700|Montserrat:300\" rel=\"stylesheet\">\n",
       "\n",
       "<link href=\"https://fonts.googleapis.com/css2?family=Crimson+Pro&family=Literata&display=swap\" rel=\"stylesheet\">\n",
       "<style>\n",
       "\n",
       "\n",
       "#ipython_notebook::before{\n",
       " content:\"NLP with Transformers\";\n",
       "        color: white;\n",
       "        font-weight: bold;\n",
       "        text-transform: uppercase;\n",
       "        font-family: 'Lora',serif;\n",
       "        font-size:16pt;\n",
       "        margin-bottom:15px;\n",
       "        margin-top:15px;\n",
       "           \n",
       "}\n",
       "body > #header {\n",
       "    #background: #D15555;\n",
       "    background: linear-gradient(to bottom, indianred 0%, #fff 100%);\n",
       "    opacity: 0.8;\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       ".navbar-default .navbar-nav > li > a, #kernel_indicator {\n",
       "    color: white;\n",
       "    transition: all 0.25s;\n",
       "    font-size:10pt;\n",
       "    font-family: sans-serif;\n",
       "    font-weight:normal;\n",
       "}\n",
       ".navbar-default {\n",
       "    padding-left:100px;\n",
       "    background: none;\n",
       "    border: none;\n",
       "}\n",
       "\n",
       "\n",
       "body > menubar-container {\n",
       "    background-color: wheat;\n",
       "}\n",
       "#ipython_notebook img{                                                                                        \n",
       "    display:block; \n",
       "    \n",
       "    background: url(\"https://www.supportvectors.com/wp-content/uploads/2016/03/logo-poster-smaller.png\") no-repeat;\n",
       "    background-size: contain;\n",
       "   \n",
       "    padding-left: 600px;\n",
       "    padding-right: 100px;\n",
       "    \n",
       "    -moz-box-sizing: border-box;\n",
       "    box-sizing: border-box;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "body {\n",
       " #font-family:  'Literata', serif;\n",
       "    font-family:'Lora', san-serif;\n",
       "    text-align: justify;\n",
       "    font-weight: 400;\n",
       "    font-size: 12pt;\n",
       "}\n",
       "\n",
       "iframe{\n",
       "    width:100%;\n",
       "    min-height:600px;\n",
       "}\n",
       "\n",
       "h1, h2, h3, h4, h5, h6 {\n",
       "# font-family: 'Montserrat', sans-serif;\n",
       " font-family:'Lora', serif;\n",
       " font-weight: 200;\n",
       " text-transform: uppercase;\n",
       " color: #EC7063 ;\n",
       "}\n",
       "\n",
       "h2 {\n",
       "    color: #000080;\n",
       "}\n",
       "\n",
       ".checkpoint_status, .autosave_status {\n",
       "    color:wheat;\n",
       "}\n",
       "\n",
       "#notebook_name {\n",
       "    font-weight: 600;\n",
       "    font-size:20pt;\n",
       "    text-variant:uppercase;\n",
       "    color: wheat; \n",
       "    margin-right:20px;\n",
       "    margin-left:-500px;\n",
       "}\n",
       "#notebook_name:hover {\n",
       "background-color: salmon;\n",
       "}\n",
       "\n",
       "\n",
       ".dataframe { /* dataframe atau table */\n",
       "    background: white;\n",
       "    box-shadow: 0px 1px 2px #bbb;\n",
       "}\n",
       ".dataframe thead th, .dataframe tbody td {\n",
       "    text-align: center;\n",
       "    padding: 1em;\n",
       "}\n",
       "\n",
       ".checkpoint_status, .autosave_status {\n",
       "    color:wheat;\n",
       "}\n",
       "\n",
       ".output {\n",
       "    align-items: center;\n",
       "}\n",
       "\n",
       "div.cell {\n",
       "    transition: all 0.25s;\n",
       "    border: none;\n",
       "    position: relative;\n",
       "    top: 0;\n",
       "}\n",
       "div.cell.selected, div.cell.selected.jupyter-soft-selected {\n",
       "    border: none;\n",
       "    background: transparent;\n",
       "    box-shadow: 0 6px 18px #aaa;\n",
       "    z-index: 10;\n",
       "    top: -10px;\n",
       "}\n",
       ".CodeMirror pre, .CodeMirror-dialog, .CodeMirror-dialog .CodeMirror-search-field, .terminal-app .terminal {\n",
       "    font-family: 'Hack' , serif; \n",
       "    font-weight: 500;\n",
       "    font-size: 14pt;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "</style>    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "<center><img src=\"https://d4x5p7s4.rocketcdn.me/wp-content/uploads/2016/03/logo-poster-smaller.png\"/> </center>\n",
       "<div style=\"color:#aaa;font-size:8pt\">\n",
       "<hr/>\n",
       "&copy; SupportVectors. All rights reserved. <blockquote>This notebook is the intellectual property of SupportVectors, and part of its training material. \n",
       "Only the participants in SupportVectors workshops are allowed to study the notebooks for educational purposes currently, but is prohibited from copying or using it for any other purposes without written permission.\n",
       "\n",
       "<b> These notebooks are chapters and sections from Asif Qamar's textbook that he is writing on Data Science. So we request you to not circulate the material to others.</b>\n",
       " </blockquote>\n",
       " <hr/>\n",
       "</div>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run supportvectors-common.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc25b9ff",
   "metadata": {},
   "source": [
    "# LangChain Prompts\n",
    "\n",
    "Good prompts have an overwhelming influence on the quality of the inferences from a large language model. Indeed, over the last few months, there is an increasing realization that the LLMs could potentially start to take over tasks traditionally accomplished through programming -- assuming we can give it well thought out prompts.\n",
    "\n",
    "<div class=\"alert-box alert-warning\" style=\"padding-top:30px\">\n",
    "   \n",
    "<b >Caveat Emptor</b>\n",
    "\n",
    "> A word of caution is necessary: programming is inherently deterministic, and comprises a clear set of instructions, that yield  -- within certain tolerances -- repeatable results.  </p> On the other hand, large language models are probabilistic machines, and depending on such hyper-parameters as the `temperature`, tend to yield different results on eahc invocation. Here, the value of `temperature` controls the output variations, with `temperature=0` producing close to repeatable results (one reason that this setting is often the default in many situations). On the other hand, higher value, say `temperature=0.9` will tend to produce different results each time.\n",
    ">\n",
    "> From our last week's session (our exploration of softmax-temperature), we recall that the temperature is a hyperparameter of the softmax classifier. In other words, when determining the probability of the next word $x_i$ from a vocabulary, the large language models use $$\\mathbf{softmax}(x_i/T) = \\frac{e^{x_i/T}}{\\sum_j e^{x_j/T}}$$ Therefore, the higher the temperature, the more the probability distribution is flattened, and thus a generative model is more likely to sample and pick not necessarily the most likely word, but the next ones in probability. In effect, this leads to a higher variation in the generated text.\n",
    "<p>\n",
    "</div>\n",
    "\n",
    "\n",
    "<hr/>\n",
    "\n",
    "A `langchain.PromptTemplate` contains two components:\n",
    "\n",
    "* a template text, with zero or more input-variables embedded in it\n",
    "* a list of these input variables\n",
    "\n",
    "Let us now explore a few examples of prompts to develop fluency with them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91275b98",
   "metadata": {},
   "source": [
    "### Imports needed for this lab\n",
    "\n",
    "Let us now import all the components we will need for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3785d1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate, FewShotPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from IPython.display import Markdown, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc50763f",
   "metadata": {},
   "source": [
    "Consider a prompt that we may want to give a large language model:\n",
    "\n",
    "<div class=\"alert-box alert-info\" style=\"padding-top:30px\">\n",
    "    \n",
    "> Imagine that there is a story about cats. They like to drink milk and prawl in the neighborhood. Write a short story where some cats show these behaviors.\n",
    ">\n",
    "> Give the story a catchy, humorous title. Write it in the format:\n",
    ">        \n",
    ">        <h3> [Title] </h3>\n",
    ">        \n",
    ">        [Body of the story]\n",
    "    \n",
    "</div>\n",
    "As we learned earlier, we can easily do this with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6c47de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "        Imagine that there is a story about cats. \n",
    "        They like to drink milk and prawl in the neighborhood. \n",
    "        Write a short story where some cats show these behaviors.\n",
    "        \n",
    "        Give the story a catchy, humorous title. Write it in the format:\n",
    "        \n",
    "        <h3> [Title] </h3>\n",
    "        \n",
    "        [Body of the story]\n",
    "        \"\"\"\n",
    "\n",
    "llm = OpenAI(temperature=0.9)\n",
    "story = llm(prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51e20120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<blockquote>\n",
       "        <h3>The Milk-Sipping, Prowling Adventures of the Cat Gang</h3>\n",
       "\n",
       "It all began one sunny summer day in the city. The Cat Gang, a group of four feline friends, sat together on a park bench, dreaming of a day full of adventure. \n",
       "\n",
       "The Cat Gang decided to start their day off with a light snack. And what better snack than with a little bit of milk? After a quick stop at the local grocery store, the cats were off, sipping their freshly purchased milk as they strutted down the street. \n",
       "\n",
       "The Cat Gang, with their bellies full of milk, decided it was time to explore. They weaved their way through backyards and alleyways, sniffing and meowing as they went. Curiosity and excitement filled the air as they were eager to discover new places. \n",
       "\n",
       "By the end of their journey, the Cat Gang was exhausted, but they'd had a great day. They had found some cozy spots to nap, and even made a few new furry friends. As the sun set, they made their way home, content with their day of milk-sipping and prowling.</blockquote>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown('<blockquote>' + story + '</blockquote>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fcdcac",
   "metadata": {},
   "source": [
    "#### Generate variations\n",
    "\n",
    "Since we set the temperature to `temperature=0.9`, we should expect a different story to emerge the next time we call invoke the model with the same input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c93db667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<blockquote>\n",
       "        <h3>Boozy Felines: A Milk-Drinking Adventure</h3>\n",
       "\n",
       "Once upon a time, there lived a group of cats who loved nothing more than drinking milk and exploring their neighborhood.\n",
       "\n",
       "Every day, they could be found lounging around the local milk parlor, indulging in luxurious glasses of creamy white goodness. But when it came time to start investigating the neighborhood, they always looked to the one cat who led them all: Captain Meowser.\n",
       "\n",
       "Captain Meowser was an experienced explorer, having been all around the block and back. With a purr and a meow, he'd lead his feline companions on an adventure, a journey of discovery and excitement. \n",
       "\n",
       "As they prowled from street to street, they encountered sights, smells and tastes that left a lasting impression. From the fish market to the local candy shop, no stone was left unturned.\n",
       "\n",
       "But no matter how far their voyage took them, by nightfall, the cats always had one thing on their minds: milk. Whether it was store-bought or hand-delivered, they couldn't resist a good glass of creamy white liquid, and it was their favorite way to end the evening.</blockquote>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "story = llm(prompt)\n",
    "display(Markdown('<blockquote>' + story + '</blockquote>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce499a3",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "* Note how different the two stories about the cats are. This points to the non-determinism of the results.\n",
    "\n",
    "* We could have set the temperature to `temperature=0`, and seen results that were a bit more similar, yet not identical. We do that below to verify.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1083c809",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Story of cats: Version 1 </h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<blockquote>\n",
       "        <h3>The Milk-Loving Cat Posse</h3>\n",
       "\n",
       "Once upon a time, there lived a group of cats who loved nothing more than relaxing and enjoying a good bowl of milk. Every morning they would all congregate in the alleyway behind the local pet store, each of them chirping and meowing with glee as they waited for their breakfast.\n",
       "\n",
       "The store owner, an elderly lady by the name of Mrs. Johnson, was happy to oblige. She would let the cats wander inside after each of them had taken their turn lapping up the delicious milk. From there, the cats would often wander through the neighborhood, their bellies full and their spirits high.\n",
       "\n",
       "They would stop in local gardens, napping in the shade and chasing each other through the tall blades of grass. They darted between the shadows of streetlights and parked cars, often leaping onto car hoods to get a better view of their surroundings.\n",
       "\n",
       "The cats were happy, and their presence made the neighborhood a little brighter. Everyone who encountered them was charmed, and the cats seemed to know it. \n",
       "\n",
       "The cats were known locally as 'The Milk-Loving Cat Posse', and with that,</blockquote>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4> Story of cats: Version 2 </h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<blockquote>\n",
       "<h3>Cats Go Moo-lking Around the Town</h3>\n",
       "\n",
       "One warm summer night, a group of cats gathered together to go on an adventure. They wanted to explore the neighborhood and find some delicious milk. They put on their matching green collars and set off. \n",
       "\n",
       "The cats slipped out of their homes and silently made their way through the streets. They soon spotted a small grocery store with its lights still on, and knew that was their destination. They meowed in triumph, and with one big jump, they were inside the store. \n",
       "\n",
       "The cats were amazed at the selection of milk. There was regular milk, almond milk, and even cat milk with extra vitamins. Delighted, the cats started drinking their milk from the cartons. They lapped it up until the cartons were empty. The cats were so full that they just lay down and purred contentedly. \n",
       "\n",
       "The cats continued on their adventure, and soon they had explored the entire neighborhood. They found a nearby park and ran around, playing and chasing each other in the grass. As they watched the sun set, they felt fulfilled by the night's adventures. \n",
       "\n",
       "The group of cats returned home, bell</blockquote>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zero_llm = OpenAI(temperature=0.0)\n",
    "\n",
    "# The first version\n",
    "display (HTML('<h4>Story of cats: Version 1 </h4>'))\n",
    "story = llm(prompt)\n",
    "display(Markdown('<blockquote>' + story + '</blockquote>'))\n",
    "\n",
    "# The second version\n",
    "display (HTML('<h4> Story of cats: Version 2 </h4>'))\n",
    "story = llm(prompt)\n",
    "display(Markdown('<blockquote>' + story + '</blockquote>'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0982422d",
   "metadata": {},
   "source": [
    "## From prompts to templates\n",
    "\n",
    "Instead of cats, what if we wanted a story about dogs, or about squirrels? A moment of reflection would show that we could have done it with minor variations to our prompt:\n",
    "\n",
    "**For dogs **\n",
    "\n",
    "<div class=\"alert-box alert-info\" style=\"padding-top:30px\">   \n",
    "\n",
    "> Imagine that there is a story about dogs. They like to chew on toys, play fetch and run around the park. Write a short story where some dogs show these behaviors.\n",
    ">\n",
    "> Give the story a catchy, humorous title. Write it in the format:\n",
    ">        \n",
    ">        <h3> [Title] </h3>\n",
    ">        \n",
    ">        [Body of the story]\n",
    "    \n",
    "</div>\n",
    "\n",
    "**For squirrels **\n",
    "\n",
    "<div class=\"alert-box alert-info\" style=\"padding-top:30px\">   \n",
    "\n",
    "> Imagine that there is a story about squirrels. They like to eat nuts and fruits, climb up and down trees and run around the glassy meadows. Write a short story where some squirrels show these behaviors.\n",
    ">\n",
    "> Give the story a catchy, humorous title. Write it in the format:\n",
    ">        \n",
    ">        <h3> [Title] </h3>\n",
    ">        \n",
    ">        [Body of the story]\n",
    "    \n",
    "</div>\n",
    "\n",
    "### Capture commonality in templates\n",
    "\n",
    "Do we see the close similarity between the prompts? Perhaps we would like a lot of stories about animals, and we need to simply give a few descriptive behaviors so the large language models can weave a story around them.\n",
    "\n",
    "Let us make the above prompts into a template, with two inputs:\n",
    "\n",
    "* name of the animal\n",
    "* some characteristic behaviors of the animal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea33ee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "\n",
    "        Imagine that there is a story about {animal}. \n",
    "        They like to {behaviors}. \n",
    "        Write a short story where some {animal} show these behaviors.\n",
    "        \n",
    "        Give the story a catchy, humorous title. Write it in the format:\n",
    "        \n",
    "        <h4> [Title] </h4>\n",
    "        \n",
    "        [Body of the story]\n",
    "\n",
    "        \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f163273a",
   "metadata": {},
   "source": [
    "Then we can generate our prompt for a story about dogs with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "381ee515",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "            input_variables = ['animal', 'behaviors'],\n",
    "            template        = template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a4fe60",
   "metadata": {},
   "source": [
    "Then, for a story about dogs, we can generate the prompt text as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9789a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "        Imagine that there is a story about dogs. \n",
      "        They like to chew on toys, play fetch and run around the park. \n",
      "        Write a short story where some dogs show these behaviors.\n",
      "        \n",
      "        Give the story a catchy, humorous title. Write it in the format:\n",
      "        \n",
      "        <h4> [Title] </h4>\n",
      "        \n",
      "        [Body of the story]\n",
      "\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "dogs = 'dogs'\n",
    "dog_behaviors = 'chew on toys, play fetch and run around the park'\n",
    "\n",
    "for_dogs = prompt.format(animal = dogs, behaviors = dog_behaviors)\n",
    "print(for_dogs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3027731",
   "metadata": {},
   "source": [
    "Likewise, for squirrels, we could get the prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "742b1f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "        Imagine that there is a story about squirrels. \n",
      "        They like to eat nuts and fruits, \n",
      "        climb up and down trees and run around the glassy meadows. \n",
      "        Write a short story where some squirrels show these behaviors.\n",
      "        \n",
      "        Give the story a catchy, humorous title. Write it in the format:\n",
      "        \n",
      "        <h4> [Title] </h4>\n",
      "        \n",
      "        [Body of the story]\n",
      "\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "squirrels = 'squirrels'\n",
    "squirrel_behaviors = \"\"\"eat nuts and fruits, \n",
    "        climb up and down trees and run around the glassy meadows\"\"\"\n",
    "\n",
    "for_squirrels = prompt.format(animal = squirrels, behaviors = squirrel_behaviors)\n",
    "print (for_squirrels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534b5bbb",
   "metadata": {},
   "source": [
    "#### A simple LangChain \n",
    "\n",
    "Let us concatenate the `promptTemplate` and the `llm` into a single chain, so we can invoke it with needing to invoke each component, and feeding its output to the next component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b7db5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f29b947",
   "metadata": {},
   "source": [
    "And now we can invoke it to, say, get a story about dogs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f89321d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<blockquote>\n",
       "        <h4>The Adventures of Fetch and Chew</h4>\n",
       "\n",
       "Once upon a time, there were two dogs named Fetch and Chew. Both were full of energy, and they spent their days playing together in the park.\n",
       "\n",
       "Fetch loved nothing more than chasing a stick and bringing it back to his master. He could run around the park for hours, racing from one side to the other, and always coming back with a smile on his face. \n",
       "\n",
       "Chew, on the other hand, loved nothing more than playing with his favorite toys. He would carry them around in his mouth, shaking his head and growling whenever someone tried to take them away. No matter how many times he chomped down on them, they were never too worse for wear. \n",
       "\n",
       "On this particular day, the two dogs were happily playing together in the park. Fetch would race around, looking for the perfect stick, while Chew chased around his favorite toys. They were both having a great time, and the sun was shining brightly. \n",
       "\n",
       "The two dogs were so engaged in their play that they didn't notice the time slipping away. Soon, it was time to go home, but Fetch and Che</blockquote>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "story = chain.run (animal=dogs, behaviors=dog_behaviors)\n",
    "display(Markdown('<blockquote>' + story + '</blockquote>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dec13ec",
   "metadata": {},
   "source": [
    "Likewise, a story about squirrels with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e15b8477",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<blockquote>\n",
       "        <h4> Nut-tastic Adventures of the Squirrels </h4>\n",
       "\n",
       "It was a beautiful day and the squirrels were out in full force. There were little furry bodies darting around in the trees and racing across the meadows.\n",
       "\n",
       "The most daring squirrels were out in search of food. They were up in the trees, collecting nuts and fruits and eating them with gusto. Some of them were so daring they would climb to dizzying heights and then jump down to the ground, barely missing the nearby bushes.\n",
       "\n",
       "Others were up and down the trees like a yo-yo, scurrying up and down the trunk and swaying from branch to branch. The trees seemed to shudder in delight as the squirrels navigated their barky surfaces.\n",
       "\n",
       "Meanwhile, some of the squirrels were running across the glassy meadows, kicking up clouds of dust and making their tails dance. The wind seemed to whistle with joy as the squirrels raced each other and chased invisible foes across the meadow.\n",
       "\n",
       "All in all, it was a nut-tastic day for the squirrels, with plenty of daring adventures, enjoyable goodies, and lots of fun.</blockquote>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "story = chain.run (animal=squirrels, behaviors=squirrel_behaviors)\n",
    "display(Markdown('<blockquote>' + story + '</blockquote>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771a57e7",
   "metadata": {},
   "source": [
    "**Note**\n",
    "While a `LLMChain` will take a prompt-template as an argument, it is not necessary to provide a user input. For example, the following prompt template does not take any user input, and still forms a part of the chain, that we can invoke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68b519cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A witty quote on everyday life in contemporary times.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<blockquote>\n",
       "\n",
       "\"Life moves pretty fast. If you don't stop and look around once in a while, you might miss it.\" - Ferris Bueller</blockquote>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simple_prompt = PromptTemplate(\n",
    "    template=\"A witty quote on everyday life in contemporary times.\",\n",
    "    input_variables=[] # we cannot omit this argument, even if empty\n",
    ")\n",
    "print (simple_prompt.format())\n",
    "\n",
    "quote = llm(simple_prompt.format())\n",
    "display(Markdown('<blockquote>' + quote + '</blockquote>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dd7a8d",
   "metadata": {},
   "source": [
    "#### Chain with a simple prompt\n",
    "\n",
    "We can run the chain with a simple prompt that needs no user input as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "859ee2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "“Life is 10% what happens to us and 90% how we react to it.” — Charles R. Swindoll\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=simple_prompt)\n",
    "witty_quote = chain.run (input=\"\")\n",
    "print(witty_quote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be9b0f2",
   "metadata": {},
   "source": [
    "## Few shot examples\n",
    "\n",
    "It is often the case that we want to give the large language models a few exemplars, so that it can infer the relationships. Let us illustrate it with an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8191ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Animal: {animal}\n",
    "Likes to: {likes_to}\n",
    "\"\"\"\n",
    "\n",
    "examples = [\n",
    "    {'animal': 'dog', 'likes_to': 'play fetch!'},\n",
    "    {'animal': 'cat', 'likes_to': 'prawl around the neighborhood'},\n",
    "    {'animal': 'squirrel', 'likes_to': 'eat nuts and climb trees'}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f7ee6b",
   "metadata": {},
   "source": [
    "Let us now create an example prompt from this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edb66b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = PromptTemplate(\n",
    "    input_variables=['animal', 'likes_to'],\n",
    "    template = template)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfb2ac8",
   "metadata": {},
   "source": [
    "Now, let's create the `FewShotPromptTemplate` with these two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b344772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt       = FewShotPromptTemplate(\n",
    "    examples          = examples,\n",
    "    example_prompt    = example_prompt,\n",
    "    prefix            = 'Describe the behavior of every animal input',\n",
    "    suffix            = 'Animal: {input}\\nLikes to:',\n",
    "    input_variables   = ['input'],\n",
    "    example_separator = '\\n\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf5229d",
   "metadata": {},
   "source": [
    "We can generate the prompt text from the above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a31517a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe the behavior of every animal input\n",
      "\n",
      "\n",
      "Animal: dog\n",
      "Likes to: play fetch!\n",
      "\n",
      "\n",
      "\n",
      "Animal: cat\n",
      "Likes to: prawl around the neighborhood\n",
      "\n",
      "\n",
      "\n",
      "Animal: squirrel\n",
      "Likes to: eat nuts and climb trees\n",
      "\n",
      "\n",
      "Animal: horse\n",
      "Likes to:\n"
     ]
    }
   ],
   "source": [
    "text = few_shot_prompt.format(input='horse')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11a41062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' eat hay and run around in pastures'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=few_shot_prompt)\n",
    "chain.run('horse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112dd1f1",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "We have learned so far that a `prompt` in `langchain` is the input that goes into a large language model. As we will learn later, there are prompts for other things too, such as chat models, and so forth.\n",
    "\n",
    "In general, a `prompt` is not necessarily a pre-determined string, but can comprise:\n",
    "\n",
    "* a template (`PromptTemplate`), with  user input variables embedded\n",
    "* user inputs for each these variables\n",
    "* and also some examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4d89ad",
   "metadata": {},
   "source": [
    "## Partial Prompt Template\n",
    "\n",
    "Sometimes, we can construct a simpler prompt template by taking one that needs multiple user inputs, but hardwiring some (but not all) of these. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98eb60e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Name three historically significant events in England around the year 1800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "    Name three historically significant events in {country} around the year {year}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate (\n",
    "            input_variables = ['country', 'year'],\n",
    "            template        = template,\n",
    ")\n",
    "\n",
    "print(prompt.format(country='England', year='1800'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8731397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. The Battle of Trafalgar (October 21, 1805): British naval victory under Admiral Lord Nelson against the combined forces of the French and Spanish fleets during the Napoleonic Wars.\n",
      "\n",
      "2. The Industrial Revolution (1760-1830): This period of time saw the introduction of new technologies and an increase in the production of goods, the large-scale investment in new forms of manufacturing and the growth of the British Empire.\n",
      "\n",
      "3. The Great Reform Act of 1832: This act represented a major shift in the British political landscape, introducing large-scale changes to the electorate and House of Commons. It was a major step in the evolution of the modern parliamentary system in the United Kingdom.\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "history = chain.run(country='England', year='1800')\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56fdc34",
   "metadata": {},
   "source": [
    "Let us now suppose that we are particularly interested in the French history.\n",
    "Then, we can create a simpler, partial prompt out of the above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41b4cb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Name three historically significant events in France around the year 1789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "partial_prompt = prompt.partial(country='France')\n",
    "print(partial_prompt.format(year='1789'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4f927b",
   "metadata": {},
   "source": [
    "And we can feed it into a language chain as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c72bd897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Storming of the Bastille on July 14, 1789\n",
      "2. Estates-General Becomes the National Assembly on June 17, 1789\n",
      "3. Declaration of the Rights of Man and of the Citizen on August 26, 1789\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(\n",
    "            llm     = llm,\n",
    "            prompt  = partial_prompt\n",
    ")\n",
    "\n",
    "events = chain.run(year='1789')\n",
    "print(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972be26b",
   "metadata": {},
   "source": [
    "## What we have learned?\n",
    "\n",
    "In this lab, we learned about:\n",
    "\n",
    "* what is a `langchain.PromptTemplate`, and what purpose it serves\n",
    "* many illustrations of constructing the prompt templates\n",
    "* using prompt templates with few shot examples\n",
    "* judicious choice of prompt template\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
